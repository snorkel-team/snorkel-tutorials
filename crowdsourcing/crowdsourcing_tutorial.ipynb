{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Crowdsourcing Tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this tutorial, we'll provide a simple walkthrough of how to use Snorkel in conjunction with crowdsourcing to create a training set for a sentiment analysis task.\n",
    "We already have crowdsourced labels for about half of the training dataset.\n",
    "The crowdsourced labels are fairly accurate, but do not cover the entire training dataset, nor are they available for the test set or during inference.\n",
    "To make up for their lack of training set coverage, we combine crowdsourced labels with heuristic labeling functions to increase the number of training labels we have.\n",
    "Like most Snorkel labeling pipelines, we'll use the denoised labels to train a deep learning\n",
    "model which can be applied to new, unseen data to automatically make predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Details"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this tutorial, we'll use the [Weather Sentiment](https://data.world/crowdflower/weather-sentiment) dataset from Figure Eight.\n",
    "Our goal is to train a classifier that can label new tweets as expressing either a positive or negative sentiment.\n",
    "\n",
    "Crowdworkers were asked to label the sentiment of a particular tweet relating to the weather.\n",
    "The catch is that 20 crowdworkers graded each tweet, and in many cases crowdworkers assigned conflicting sentiment labels to the same tweet.\n",
    "This is a common issue when dealing with crowdsourced labeling workloads.\n",
    "\n",
    "Label options were positive, negative, or one of three other options saying they weren't sure if it was positive or negative; we use only the positive/negative labels.\n",
    "We've also altered the dataset to reflect a realistic crowdsourcing pipeline where only a subset of our available training set has received crowd labels.\n",
    "\n",
    "We will treat each crowdworker's labels as coming from a single labeling function (LF).\n",
    "This will allow us to learn a weight for how much to trust the labels from each crowdworker.\n",
    "We will also write a few heuristic labeling functions to cover the data points without crowd labels.\n",
    "Snorkel's ability to build high-quality datasets from multiple noisy labeling signals makes it an ideal framework to approach this problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Crowdsourcing Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start by loading our data which has 287 data points in total.\n",
    "We take 50 for our development set and 50 for our test set.\n",
    "The remaining 187 data points form our training set.\n",
    "Since the dataset is already small, we skip using a validation set.\n",
    "Note that this very small dataset is primarily used for demonstration purposes here.\n",
    "In a real setting, we would expect to have access to many more unlabeled tweets, which could help us to train a higher quality model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": [
     "md-exclude"
    ]
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Make sure we're in the right directory\n",
    "if os.path.basename(os.getcwd()) == \"snorkel-tutorials\":\n",
    "    os.chdir(\"crowdsourcing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data import load_data\n",
    "\n",
    "crowd_labels, df_train, df_dev, df_test = load_data()\n",
    "Y_dev = df_dev.sentiment.values\n",
    "Y_test = df_test.sentiment.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "md-exclude"
    ]
   },
   "source": [
    "First, let's take a look at our development set to get a sense of what the tweets look like.\n",
    "We use the following label convention: 0 = Negative, 1 = Positive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": [
     "md-exclude"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tweet_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>79197834</th>\n",
       "      <td>79197834</td>\n",
       "      <td>@mention not in sunny dover! haha</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80059939</th>\n",
       "      <td>80059939</td>\n",
       "      <td>It is literally pissing it down in sideways rain. I have nothing to protect me from this monstrous weather.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79196441</th>\n",
       "      <td>79196441</td>\n",
       "      <td>Dear perfect weather, thanks for the vest lunch hour of all time. (@ Lady Bird Lake Trail w/ 2 others) {link}</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84047300</th>\n",
       "      <td>84047300</td>\n",
       "      <td>RT @mention: I can't wait for the storm tonight :)</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83255121</th>\n",
       "      <td>83255121</td>\n",
       "      <td>60 degrees. And its almost the end of may. Wisconsin... I hate you.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          tweet_id  \\\n",
       "tweet_id             \n",
       "79197834  79197834   \n",
       "80059939  80059939   \n",
       "79196441  79196441   \n",
       "84047300  84047300   \n",
       "83255121  83255121   \n",
       "\n",
       "                                                                                                             tweet_text  \\\n",
       "tweet_id                                                                                                                  \n",
       "79197834  @mention not in sunny dover! haha                                                                               \n",
       "80059939  It is literally pissing it down in sideways rain. I have nothing to protect me from this monstrous weather.     \n",
       "79196441  Dear perfect weather, thanks for the vest lunch hour of all time. (@ Lady Bird Lake Trail w/ 2 others) {link}   \n",
       "84047300  RT @mention: I can't wait for the storm tonight :)                                                              \n",
       "83255121  60 degrees. And its almost the end of may. Wisconsin... I hate you.                                             \n",
       "\n",
       "          sentiment  \n",
       "tweet_id             \n",
       "79197834  1          \n",
       "80059939  0          \n",
       "79196441  1          \n",
       "84047300  1          \n",
       "83255121  0          "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Don't truncate text fields in the display\n",
    "pd.set_option(\"display.max_colwidth\", 0)\n",
    "\n",
    "df_dev.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "md-exclude"
    ]
   },
   "source": [
    "Now let's take a look at the crowd labels.\n",
    "We'll convert these into labeling functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": [
     "md-exclude"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>worker_id</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tweet_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>82510997</th>\n",
       "      <td>18034918</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82510997</th>\n",
       "      <td>7450342</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82510997</th>\n",
       "      <td>18465660</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82510997</th>\n",
       "      <td>17475684</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82510997</th>\n",
       "      <td>14472526</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          worker_id  label\n",
       "tweet_id                  \n",
       "82510997  18034918   1    \n",
       "82510997  7450342    1    \n",
       "82510997  18465660   1    \n",
       "82510997  17475684   0    \n",
       "82510997  14472526   1    "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crowd_labels.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Writing Labeling Functions\n",
    "Each crowdworker can be thought of as a single labeling function,\n",
    "as each worker labels a subset of data points,\n",
    "and may have errors or conflicting labels with other workers / labeling functions.\n",
    "So we create one labeling function per worker.\n",
    "We'll simply return the label the worker submitted for a given tweet, and abstain\n",
    "if they didn't submit a label for it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Crowdworker labeling functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of workers: 100\n"
     ]
    }
   ],
   "source": [
    "labels_by_annotator = crowd_labels.groupby(\"worker_id\")\n",
    "worker_dicts = {}\n",
    "for worker_id in labels_by_annotator.groups:\n",
    "    worker_df = labels_by_annotator.get_group(worker_id)[[\"label\"]]\n",
    "    worker_dicts[worker_id] = dict(zip(worker_df.index, worker_df.label))\n",
    "\n",
    "print(\"Number of workers:\", len(worker_dicts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from snorkel.labeling import LabelingFunction\n",
    "\n",
    "ABSTAIN = -1\n",
    "\n",
    "\n",
    "def worker_lf(x, worker_dict):\n",
    "    return worker_dict.get(x.tweet_id, ABSTAIN)\n",
    "\n",
    "\n",
    "def make_worker_lf(worker_id):\n",
    "    worker_dict = worker_dicts[worker_id]\n",
    "    name = f\"worker_{worker_id}\"\n",
    "    return LabelingFunction(name, f=worker_lf, resources={\"worker_dict\": worker_dict})\n",
    "\n",
    "\n",
    "worker_lfs = [make_worker_lf(worker_id) for worker_id in worker_dicts]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a quick look at how well they do on the development set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": [
     "md-exclude-output"
    ]
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/187 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 56%|█████▌    | 104/187 [00:00<00:00, 1031.43it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "100%|██████████| 187/187 [00:00<00:00, 1031.16it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\r",
      "  0%|          | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "100%|██████████| 50/50 [00:00<00:00, 1021.63it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from snorkel.labeling import PandasLFApplier\n",
    "\n",
    "applier = PandasLFApplier(worker_lfs)\n",
    "L_train = applier.apply(df_train)\n",
    "L_dev = applier.apply(df_dev)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that because our dev set is so small and our LFs are relatively sparse, many LFs will appear to have zero coverage.\n",
    "Fortunately, our label model learns weights for LFs based on their outputs on the training set, which is generally much larger."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>j</th>\n",
       "      <th>Polarity</th>\n",
       "      <th>Coverage</th>\n",
       "      <th>Overlaps</th>\n",
       "      <th>Conflicts</th>\n",
       "      <th>Correct</th>\n",
       "      <th>Incorrect</th>\n",
       "      <th>Emp. Acc.</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>worker_17652569</th>\n",
       "      <td>70</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>worker_16498372</th>\n",
       "      <td>58</td>\n",
       "      <td>[0, 1]</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.04</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>worker_18465660</th>\n",
       "      <td>80</td>\n",
       "      <td>[0, 1]</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>worker_12572470</th>\n",
       "      <td>38</td>\n",
       "      <td>[0, 1]</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.04</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>worker_18975312</th>\n",
       "      <td>88</td>\n",
       "      <td>[0, 1]</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.02</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  j Polarity  Coverage  Overlaps  Conflicts  Correct  \\\n",
       "worker_17652569  70  []       0.00      0.00      0.00       0         \n",
       "worker_16498372  58  [0, 1]   0.06      0.06      0.04       3         \n",
       "worker_18465660  80  [0, 1]   0.06      0.06      0.06       3         \n",
       "worker_12572470  38  [0, 1]   0.04      0.04      0.04       2         \n",
       "worker_18975312  88  [0, 1]   0.04      0.04      0.02       2         \n",
       "\n",
       "                 Incorrect  Emp. Acc.  \n",
       "worker_17652569  0          0.0        \n",
       "worker_16498372  0          1.0        \n",
       "worker_18465660  0          1.0        \n",
       "worker_12572470  0          1.0        \n",
       "worker_18975312  0          1.0        "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from snorkel.labeling import LFAnalysis\n",
    "\n",
    "LFAnalysis(L_dev, worker_lfs).lf_summary(Y_dev).sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So the crowd labels in general are quite good! But how much of our dev and training\n",
    "sets do they cover?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set coverage:  50.3%\n",
      "Dev set coverage:  50.0%\n"
     ]
    }
   ],
   "source": [
    "print(f\"Training set coverage: {100 * LFAnalysis(L_train).label_coverage(): 0.1f}%\")\n",
    "print(f\"Dev set coverage: {100 * LFAnalysis(L_dev).label_coverage(): 0.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Additional labeling functions\n",
    "\n",
    "To improve coverage of the training set, we can mix the crowdworker labeling functions with labeling\n",
    "functions of other types.\n",
    "For example, we can use [TextBlob](https://textblob.readthedocs.io/en/dev/index.html), a tool that provides a pretrained sentiment analyzer. We run TextBlob on our tweets and create some simple LFs that threshold its polarity score, similar to what we did in the spam_tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from snorkel.labeling import labeling_function\n",
    "from snorkel.preprocess import preprocessor\n",
    "from textblob import TextBlob\n",
    "\n",
    "\n",
    "@preprocessor(memoize=True)\n",
    "def textblob_polarity(x):\n",
    "    scores = TextBlob(x.tweet_text)\n",
    "    x.polarity = scores.polarity\n",
    "    return x\n",
    "\n",
    "\n",
    "# Label high polarity tweets as positive.\n",
    "@labeling_function(pre=[textblob_polarity])\n",
    "def polarity_positive(x):\n",
    "    return 1 if x.polarity > 0.3 else -1\n",
    "\n",
    "\n",
    "# Label low polarity tweets as negative.\n",
    "@labeling_function(pre=[textblob_polarity])\n",
    "def polarity_negative(x):\n",
    "    return 0 if x.polarity < -0.25 else -1\n",
    "\n",
    "\n",
    "# Similar to polarity_negative, but with higher coverage and lower precision.\n",
    "@labeling_function(pre=[textblob_polarity])\n",
    "def polarity_negative_2(x):\n",
    "    return 0 if x.polarity <= 0.3 else -1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Applying labeling functions to the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": [
     "md-exclude-output"
    ]
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/187 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 18%|█▊        | 34/187 [00:00<00:00, 336.60it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 46%|████▌     | 86/187 [00:00<00:00, 376.05it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 74%|███████▍  | 139/187 [00:00<00:00, 410.40it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "100%|██████████| 187/187 [00:00<00:00, 469.41it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\r",
      "  0%|          | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "100%|██████████| 50/50 [00:00<00:00, 515.15it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "text_lfs = [polarity_positive, polarity_negative, polarity_negative_2]\n",
    "lfs = text_lfs + worker_lfs\n",
    "\n",
    "applier = PandasLFApplier(lfs)\n",
    "L_train = applier.apply(df_train)\n",
    "L_dev = applier.apply(df_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>j</th>\n",
       "      <th>Polarity</th>\n",
       "      <th>Coverage</th>\n",
       "      <th>Overlaps</th>\n",
       "      <th>Conflicts</th>\n",
       "      <th>Correct</th>\n",
       "      <th>Incorrect</th>\n",
       "      <th>Emp. Acc.</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>polarity_positive</th>\n",
       "      <td>0</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.12</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>polarity_negative</th>\n",
       "      <td>1</td>\n",
       "      <td>[0]</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.04</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>polarity_negative_2</th>\n",
       "      <td>2</td>\n",
       "      <td>[0]</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.32</td>\n",
       "      <td>26</td>\n",
       "      <td>9</td>\n",
       "      <td>0.742857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>worker_6332651</th>\n",
       "      <td>3</td>\n",
       "      <td>[0, 1]</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>worker_6336109</th>\n",
       "      <td>4</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     j Polarity  Coverage  Overlaps  Conflicts  Correct  \\\n",
       "polarity_positive    0  [1]      0.30      0.16      0.12       15        \n",
       "polarity_negative    1  [0]      0.10      0.10      0.04       5         \n",
       "polarity_negative_2  2  [0]      0.70      0.40      0.32       26        \n",
       "worker_6332651       3  [0, 1]   0.06      0.06      0.06       1         \n",
       "worker_6336109       4  []       0.00      0.00      0.00       0         \n",
       "\n",
       "                     Incorrect  Emp. Acc.  \n",
       "polarity_positive    0          1.000000   \n",
       "polarity_negative    0          1.000000   \n",
       "polarity_negative_2  9          0.742857   \n",
       "worker_6332651       2          0.333333   \n",
       "worker_6336109       0          0.000000   "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LFAnalysis(L_dev, lfs).lf_summary(Y_dev).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the text-based LFs, we've expanded coverage on both our training set\n",
    "and dev set to 100%.\n",
    "We'll now take these noisy and conflicting labels, and use the LabelModel\n",
    "to denoise and combine them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set coverage:  100.0%\n",
      "Dev set coverage:  100.0%\n"
     ]
    }
   ],
   "source": [
    "print(f\"Training set coverage: {100 * LFAnalysis(L_train).label_coverage(): 0.1f}%\")\n",
    "print(f\"Dev set coverage: {100 * LFAnalysis(L_dev).label_coverage(): 0.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train LabelModel And Generate Probabilistic Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": [
     "md-exclude-output"
    ]
   },
   "outputs": [],
   "source": [
    "from snorkel.labeling import LabelModel\n",
    "\n",
    "# Train LabelModel.\n",
    "label_model = LabelModel(cardinality=2, verbose=True)\n",
    "label_model.fit(L_train, n_epochs=100, seed=123, log_freq=20, l2=0.1, lr=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a spot-check for the quality of our LabelModel, we'll score it on the dev set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LabelModel Accuracy: 0.920\n"
     ]
    }
   ],
   "source": [
    "from snorkel.analysis import metric_score\n",
    "\n",
    "preds_dev = label_model.predict(L_dev)\n",
    "\n",
    "acc = metric_score(Y_dev, preds_dev, probs=None, metric=\"accuracy\")\n",
    "print(f\"LabelModel Accuracy: {acc:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that we get very high accuracy on the development set.\n",
    "This is due to the abundance of high quality crowdworker labels.\n",
    "**Since we don't have these high quality crowdsourcing labels for the\n",
    "test set or new incoming data points, we can't use the LabelModel reliably\n",
    "at inference time.**\n",
    "In order to run inference on new incoming data points, we need to train a\n",
    "discriminative model over the tweets themselves.\n",
    "Let's generate a set of labels for that training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_train = label_model.predict(L_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use Soft Labels to Train End Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting features from BERT\n",
    "Since we have very limited training data, we cannot train a complex model like an LSTM with a lot of parameters.\n",
    "Instead, we use a pre-trained model, [BERT](https://github.com/google-research/bert), to generate embeddings for each our tweets, and treat the embedding values as features.\n",
    "This may take 5-10 minutes on a CPU, as the BERT model is very large."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": [
     "md-exclude-output"
    ]
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from pytorch_transformers import BertModel, BertTokenizer\n",
    "\n",
    "model = BertModel.from_pretrained(\"bert-base-uncased\")\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "\n",
    "def encode_text(text):\n",
    "    input_ids = torch.tensor([tokenizer.encode(text)])\n",
    "    return model(input_ids)[0].mean(1)[0].detach().numpy()\n",
    "\n",
    "\n",
    "X_train = np.array(list(df_train.tweet_text.apply(encode_text).values))\n",
    "X_test = np.array(list(df_test.tweet_text.apply(encode_text).values))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model on labels\n",
    "Now, we train a simple logistic regression model on the BERT features, using labels\n",
    "obtained from our LabelModel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": [
     "md-exclude-output"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='liblinear', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "sklearn_model = LogisticRegression(solver=\"liblinear\")\n",
    "sklearn_model.fit(X_train, preds_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of trained model: 0.86\n"
     ]
    }
   ],
   "source": [
    "print(f\"Accuracy of trained model: {sklearn_model.score(X_test, Y_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have a trained model that can be applied to future data points without requiring crowdsourced labels, and with accuracy not much lower than the `LabelModel` that _does_ have access to crowdsourced labels!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this tutorial, we accomplished the following:\n",
    "* We demonstrated how to combine crowdsourced labels with other programmatic LFs to improve coverage.\n",
    "* We used the `LabelModel` to combine inputs from crowdworkers and other LFs to generate high quality probabilistic labels.\n",
    "* We used our labels to train a classifier for making predictions on new, unseen data points."
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "tags,-all"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
