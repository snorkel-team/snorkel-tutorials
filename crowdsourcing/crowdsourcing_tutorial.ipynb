{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Crowdsourcing tutorial\n",
    "In this tutorial, we'll provide a simple walkthrough of how to use Snorkel to resolve conflicts\n",
    "in a noisy, hybrid dataset for a sentiment analysis task.\n",
    "We have crowdsourced labels for a portion of the training dataset, and combine these\n",
    "with heuristic labeling functions to increase the number of training labels we have.\n",
    "Like most Snorkel labeling pipelines, we'll use the denoised labels to train a deep learning\n",
    "model which can be applied to new, unseen data to automatically make predictions!\n",
    "\n",
    "In this tutorial, we're using the\n",
    "[Weather Sentiment](https://data.world/crowdflower/weather-sentiment)\n",
    "dataset from Figure Eight.\n",
    "Our goal is to label each tweet as either positive or negative so that\n",
    "we can train a language model over the tweets themselves that can be applied\n",
    "to new, unseen data points.\n",
    "Crowd workers were asked to grade the sentiment of a\n",
    "particular tweet relating to the weather.\n",
    "Crowd workers could choose among the following categories:\n",
    "\n",
    "* Positive\n",
    "* Negative\n",
    "* I can't tell\n",
    "* Neutral / author is just sharing information\n",
    "* Tweet not related to weather condition\n",
    "\n",
    "The catch is that 20 crowd workers graded each tweet, and in many cases\n",
    "crowd workers assigned conflicting sentiment labels to the same tweet.\n",
    "This is a common issue when dealing with crowdsourced labeling workloads.\n",
    "\n",
    "We've also altered the data set to reflect a realistic crowdsourcing pipeline\n",
    "where only a subset of our full training set have recieved crowd labels.\n",
    "We'll encode the crowd labels themselves as labeling functions in order\n",
    "to learn trust weights for each crowd worker, and write a few heuristic\n",
    "labeling functions to cover the data points without crowd labels.\n",
    "Snorkel's ability to build high-quality datasets from multiple noisy labeling\n",
    "signals makes it an ideal framework to approach this problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start by loading our data which has 287 examples in total.\n",
    "We take 50 for our development set and 50 for our test set.\n",
    "The remaining 187 examples form our training set.\n",
    "This data set is very small, and we're primarily using it for demonstration purposes.\n",
    "In particular, we'd expect to have access to many more unlabeled tweets in order to\n",
    "train a high performance text model.\n",
    "\n",
    "The labels above have been mapped to integers, which we show here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Crowdsourcing Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "if os.path.basename(os.getcwd()) == \"snorkel-tutorials\":\n",
    "    os.chdir(\"crowdsourcing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer to int mapping:\n",
      "I can't tell                                      -1\n",
      "Negative                                          0\n",
      "Positive                                          1\n",
      "Neutral / author is just sharing information      2\n",
      "Tweet not related to weather condition            3\n"
     ]
    }
   ],
   "source": [
    "from data import load_data, answer_mapping\n",
    "\n",
    "crowd_answers, df_train, df_dev, df_test = load_data()\n",
    "Y_dev = df_dev.sentiment.values\n",
    "Y_test = df_test.sentiment.values\n",
    "\n",
    "print(\"Answer to int mapping:\")\n",
    "for k, v in sorted(answer_mapping.items(), key=lambda kv: kv[1]):\n",
    "    print(f\"{k:<50}{v}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's take a look at our development set to get a sense of\n",
    "what the tweets look like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tweet_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>79197834</th>\n",
       "      <td>79197834</td>\n",
       "      <td>@mention not in sunny dover! haha</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80059939</th>\n",
       "      <td>80059939</td>\n",
       "      <td>It is literally pissing it down in sideways ra...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79196441</th>\n",
       "      <td>79196441</td>\n",
       "      <td>Dear perfect weather, thanks for the vest lunc...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84047300</th>\n",
       "      <td>84047300</td>\n",
       "      <td>RT @mention: I can't wait for the storm tonigh...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83255121</th>\n",
       "      <td>83255121</td>\n",
       "      <td>60 degrees. And its almost the end of may. Wis...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          tweet_id                                         tweet_text  \\\n",
       "tweet_id                                                                \n",
       "79197834  79197834                  @mention not in sunny dover! haha   \n",
       "80059939  80059939  It is literally pissing it down in sideways ra...   \n",
       "79196441  79196441  Dear perfect weather, thanks for the vest lunc...   \n",
       "84047300  84047300  RT @mention: I can't wait for the storm tonigh...   \n",
       "83255121  83255121  60 degrees. And its almost the end of may. Wis...   \n",
       "\n",
       "          sentiment  \n",
       "tweet_id             \n",
       "79197834          1  \n",
       "80059939          0  \n",
       "79196441          1  \n",
       "84047300          1  \n",
       "83255121          0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dev.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's take a look at the crowd labels.\n",
    "We'll convert these into labeling functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>worker_id</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tweet_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>82510997</th>\n",
       "      <td>18034918</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82510997</th>\n",
       "      <td>7450342</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82510997</th>\n",
       "      <td>18465660</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82510997</th>\n",
       "      <td>17475684</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82510997</th>\n",
       "      <td>14472526</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          worker_id  answer\n",
       "tweet_id                   \n",
       "82510997   18034918       1\n",
       "82510997    7450342       1\n",
       "82510997   18465660       1\n",
       "82510997   17475684       0\n",
       "82510997   14472526       1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crowd_answers.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Writing Labeling Functions\n",
    "Each crowd worker can be thought of as a single labeling function,\n",
    "as each worker labels a subset of examples,\n",
    "and may have errors or conflicting answers with other workers / labeling functions.\n",
    "So we create one labeling function per worker.\n",
    "We'll simply return the label the worker submitted for a given tweet, and abstain\n",
    "if they didn't submit an answer for it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Crowd worker labeling functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of workers: 68\n"
     ]
    }
   ],
   "source": [
    "labels_by_annotator = crowd_answers.groupby(\"worker_id\")\n",
    "worker_dicts = {}\n",
    "for worker_id in labels_by_annotator.groups:\n",
    "    worker_df = labels_by_annotator.get_group(worker_id)[[\"answer\"]]\n",
    "    if len(worker_df) > 10:\n",
    "        worker_dicts[worker_id] = dict(zip(worker_df.index, worker_df.answer))\n",
    "\n",
    "print(\"Number of workers:\", len(worker_dicts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from snorkel.labeling.lf import LabelingFunction\n",
    "\n",
    "\n",
    "def f_pos(x, worker_dict):\n",
    "    label = worker_dict.get(x.tweet_id)\n",
    "    return 1 if label == 1 else -1\n",
    "\n",
    "\n",
    "def f_neg(x, worker_dict):\n",
    "    label = worker_dict.get(x.tweet_id)\n",
    "    return 0 if label == 0 else -1\n",
    "\n",
    "\n",
    "def get_worker_labeling_function(worker_id, f):\n",
    "    worker_dict = worker_dicts[worker_id]\n",
    "    name = f\"worker_{worker_id}\"\n",
    "    return LabelingFunction(name, f=f, resources={\"worker_dict\": worker_dict})\n",
    "\n",
    "\n",
    "worker_lfs_pos = [\n",
    "    get_worker_labeling_function(worker_id, f_pos) for worker_id in worker_dicts\n",
    "]\n",
    "worker_lfs_neg = [\n",
    "    get_worker_labeling_function(worker_id, f_neg) for worker_id in worker_dicts\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a quick look at how well they do on the development set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/187 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 44%|████▍     | 83/187 [00:00<00:00, 827.50it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 89%|████████▉ | 166/187 [00:00<00:00, 827.03it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "100%|██████████| 187/187 [00:00<00:00, 816.35it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\r",
      "  0%|          | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "100%|██████████| 50/50 [00:00<00:00, 813.10it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from snorkel.labeling.apply import PandasLFApplier\n",
    "\n",
    "lfs = worker_lfs_pos + worker_lfs_neg\n",
    "lf_names = [lf.name for lf in lfs]\n",
    "\n",
    "applier = PandasLFApplier(lfs)\n",
    "L_train = applier.apply(df_train)\n",
    "L_dev = applier.apply(df_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/snorkel-tutorials/.tox/crowdsourcing/lib/python3.6/site-packages/snorkel/labeling/analysis.py:268: RuntimeWarning: invalid value encountered in true_divide\n",
      "  return np.nan_to_num(0.5 * (X.sum(axis=0) / (self.L != -1).sum(axis=0) + 1))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>j</th>\n",
       "      <th>Polarity</th>\n",
       "      <th>Coverage</th>\n",
       "      <th>Overlaps</th>\n",
       "      <th>Conflicts</th>\n",
       "      <th>Correct</th>\n",
       "      <th>Incorrect</th>\n",
       "      <th>Emp. Acc.</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>worker_6340330</th>\n",
       "      <td>0</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.04</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>worker_6344001</th>\n",
       "      <td>1</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.04</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>worker_6346694</th>\n",
       "      <td>2</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.10</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.833333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>worker_6363996</th>\n",
       "      <td>3</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.02</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>worker_6371053</th>\n",
       "      <td>4</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>worker_6453108</th>\n",
       "      <td>5</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.02</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>worker_6737418</th>\n",
       "      <td>6</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>worker_7325249</th>\n",
       "      <td>7</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.10</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>worker_7450342</th>\n",
       "      <td>8</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>worker_7860247</th>\n",
       "      <td>9</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.14</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                j Polarity  Coverage  Overlaps  Conflicts  Correct  Incorrect  \\\n",
       "worker_6340330  0      [1]      0.04      0.04       0.04        2          0   \n",
       "worker_6344001  1      [1]      0.04      0.04       0.04        2          0   \n",
       "worker_6346694  2      [1]      0.12      0.12       0.10        5          1   \n",
       "worker_6363996  3      [1]      0.04      0.04       0.02        2          0   \n",
       "worker_6371053  4      [1]      0.06      0.06       0.06        2          1   \n",
       "worker_6453108  5      [1]      0.04      0.04       0.02        2          0   \n",
       "worker_6737418  6      [1]      0.06      0.06       0.06        2          1   \n",
       "worker_7325249  7      [1]      0.10      0.10       0.10        4          1   \n",
       "worker_7450342  8       []      0.00      0.00       0.00        0          0   \n",
       "worker_7860247  9      [1]      0.16      0.16       0.14        8          0   \n",
       "\n",
       "                Emp. Acc.  \n",
       "worker_6340330   1.000000  \n",
       "worker_6344001   1.000000  \n",
       "worker_6346694   0.833333  \n",
       "worker_6363996   1.000000  \n",
       "worker_6371053   0.666667  \n",
       "worker_6453108   1.000000  \n",
       "worker_6737418   0.666667  \n",
       "worker_7325249   0.800000  \n",
       "worker_7450342   0.000000  \n",
       "worker_7860247   1.000000  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from snorkel.labeling.analysis import LFAnalysis\n",
    "\n",
    "LFAnalysis(L_dev).lf_summary(Y_dev, lf_names=lf_names).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So the crowd labels are quite good! But how much of our dev and training\n",
    "sets do they cover?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set coverge: 0.5026737967914439\n",
      "Dev set coverge: 0.5\n"
     ]
    }
   ],
   "source": [
    "print(\"Training set coverge:\", LFAnalysis(L_train).label_coverage())\n",
    "print(\"Dev set coverge:\", LFAnalysis(L_dev).label_coverage())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Additional labeling functions\n",
    "\n",
    "We can mix the crowd worker labeling functions with labeling\n",
    "functions of other types.\n",
    "We'll use a few varied approaches and use the label model learn\n",
    "how to combine their values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from snorkel.labeling.lf import labeling_function\n",
    "from snorkel.labeling.preprocess import preprocessor\n",
    "from textblob import TextBlob\n",
    "\n",
    "\n",
    "@preprocessor()\n",
    "def textblob_polarity(x):\n",
    "    scores = TextBlob(x.tweet_text)\n",
    "    x.polarity = scores.polarity\n",
    "    return x\n",
    "\n",
    "\n",
    "textblob_polarity.memoize = True\n",
    "\n",
    "\n",
    "@labeling_function(preprocessors=[textblob_polarity])\n",
    "def polarity_positive(x):\n",
    "    return 1 if x.polarity > 0.3 else -1\n",
    "\n",
    "\n",
    "@labeling_function(preprocessors=[textblob_polarity])\n",
    "def polarity_negative(x):\n",
    "    return 0 if x.polarity < -0.25 else -1\n",
    "\n",
    "\n",
    "@labeling_function(preprocessors=[textblob_polarity])\n",
    "def polarity_negative_2(x):\n",
    "    return 0 if x.polarity <= 0.3 else -1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Applying labeling functions to the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/187 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 16%|█▌        | 30/187 [00:00<00:00, 299.30it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 41%|████      | 76/187 [00:00<00:00, 333.55it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 65%|██████▌   | 122/187 [00:00<00:00, 363.28it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 90%|████████▉ | 168/187 [00:00<00:00, 386.50it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "100%|██████████| 187/187 [00:00<00:00, 417.34it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\r",
      "  0%|          | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 92%|█████████▏| 46/50 [00:00<00:00, 458.93it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "100%|██████████| 50/50 [00:00<00:00, 444.55it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from snorkel.labeling.apply import PandasLFApplier\n",
    "\n",
    "text_lfs = [polarity_positive, polarity_negative, polarity_negative_2]\n",
    "lfs = text_lfs + worker_lfs_pos + worker_lfs_neg\n",
    "lf_names = [lf.name for lf in lfs]\n",
    "\n",
    "applier = PandasLFApplier(lfs)\n",
    "L_train = applier.apply(df_train)\n",
    "L_dev = applier.apply(df_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/snorkel-tutorials/.tox/crowdsourcing/lib/python3.6/site-packages/snorkel/labeling/analysis.py:268: RuntimeWarning: invalid value encountered in true_divide\n",
      "  return np.nan_to_num(0.5 * (X.sum(axis=0) / (self.L != -1).sum(axis=0) + 1))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>j</th>\n",
       "      <th>Polarity</th>\n",
       "      <th>Coverage</th>\n",
       "      <th>Overlaps</th>\n",
       "      <th>Conflicts</th>\n",
       "      <th>Correct</th>\n",
       "      <th>Incorrect</th>\n",
       "      <th>Emp. Acc.</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>polarity_positive</th>\n",
       "      <td>0</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.12</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>polarity_negative</th>\n",
       "      <td>1</td>\n",
       "      <td>[0]</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.04</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>polarity_negative_2</th>\n",
       "      <td>2</td>\n",
       "      <td>[0]</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.32</td>\n",
       "      <td>26</td>\n",
       "      <td>9</td>\n",
       "      <td>0.742857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>worker_6340330</th>\n",
       "      <td>3</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.04</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>worker_6344001</th>\n",
       "      <td>4</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.04</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>worker_6346694</th>\n",
       "      <td>5</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.10</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.833333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>worker_6363996</th>\n",
       "      <td>6</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.02</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>worker_6371053</th>\n",
       "      <td>7</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>worker_6453108</th>\n",
       "      <td>8</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.02</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>worker_6737418</th>\n",
       "      <td>9</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     j Polarity  Coverage  Overlaps  Conflicts  Correct  \\\n",
       "polarity_positive    0      [1]      0.30      0.16       0.12       15   \n",
       "polarity_negative    1      [0]      0.10      0.10       0.04        5   \n",
       "polarity_negative_2  2      [0]      0.70      0.40       0.32       26   \n",
       "worker_6340330       3      [1]      0.04      0.04       0.04        2   \n",
       "worker_6344001       4      [1]      0.04      0.04       0.04        2   \n",
       "worker_6346694       5      [1]      0.12      0.12       0.10        5   \n",
       "worker_6363996       6      [1]      0.04      0.04       0.02        2   \n",
       "worker_6371053       7      [1]      0.06      0.06       0.06        2   \n",
       "worker_6453108       8      [1]      0.04      0.04       0.02        2   \n",
       "worker_6737418       9      [1]      0.06      0.06       0.06        2   \n",
       "\n",
       "                     Incorrect  Emp. Acc.  \n",
       "polarity_positive            0   1.000000  \n",
       "polarity_negative            0   1.000000  \n",
       "polarity_negative_2          9   0.742857  \n",
       "worker_6340330               0   1.000000  \n",
       "worker_6344001               0   1.000000  \n",
       "worker_6346694               1   0.833333  \n",
       "worker_6363996               0   1.000000  \n",
       "worker_6371053               1   0.666667  \n",
       "worker_6453108               0   1.000000  \n",
       "worker_6737418               1   0.666667  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LFAnalysis(L_dev).lf_summary(Y_dev, lf_names=lf_names).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the text-based LFs, we've expanded coverage on both our training set\n",
    "and dev set to 100%.\n",
    "We'll now take these noisy and conflicting labels, and use the label model\n",
    "to denoise and combine them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set coverge: 1.0\n",
      "Dev set coverge: 1.0\n"
     ]
    }
   ],
   "source": [
    "print(\"Training set coverge:\", LFAnalysis(L_train).label_coverage())\n",
    "print(\"Dev set coverge:\", LFAnalysis(L_dev).label_coverage())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Label Model And Generate Soft Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing O...\n",
      "Estimating \\mu...\n",
      "[0 epochs]: TRAIN:[loss=2.371]\n",
      "[20 epochs]: TRAIN:[loss=0.568]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[40 epochs]: TRAIN:[loss=0.536]\n",
      "[60 epochs]: TRAIN:[loss=0.522]\n",
      "[80 epochs]: TRAIN:[loss=0.524]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "from snorkel.labeling.model.label_model import LabelModel\n",
    "\n",
    "# Train label model.\n",
    "label_model = LabelModel(cardinality=2, verbose=True)\n",
    "label_model.fit(L_train, n_epochs=100, seed=123, log_freq=20, l2=0.1, lr=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a spot-check for the quality of our label model, we'll score it on the dev set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label Model Accuracy: 0.920\n"
     ]
    }
   ],
   "source": [
    "from snorkel.analysis.metrics import metric_score\n",
    "from snorkel.analysis.utils import probs_to_preds\n",
    "\n",
    "Y_dev_prob = label_model.predict_proba(L_dev)\n",
    "Y_dev_pred = probs_to_preds(Y_dev_prob)\n",
    "\n",
    "acc = metric_score(Y_dev, Y_dev_pred, probs=None, metric=\"accuracy\")\n",
    "print(f\"Label Model Accuracy: {acc:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look at that, we get very high accuracy on the development set.\n",
    "This is due to the abundance of high quality crowd worker labels.\n",
    "**Since we don't have these high quality crowdsourcing labels for the\n",
    "test set or new incoming examples, we can't use the label model reliably\n",
    "at inference time.**\n",
    "In order to run inference on new incoming examples, we need to train a\n",
    "discriminative model over the tweets themselves.\n",
    "Let's generate a set of probabilistic labels for the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train_prob = label_model.predict_proba(L_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use Soft Labels to Train End Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting features from BERT\n",
    "Since we have very limited training data, we cannot train a complex model like an LSTM with a lot of parameters. Instead, we use a pre-trained model, [BERT](https://github.com/google-research/bert), to generate embeddings for each our tweets, and treat the embedding values as features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from pytorch_transformers import BertModel, BertTokenizer\n",
    "\n",
    "model = BertModel.from_pretrained(\"bert-base-uncased\")\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "\n",
    "def encode_text(text):\n",
    "    input_ids = torch.tensor([tokenizer.encode(text)])\n",
    "    return model(input_ids)[0].mean(1)[0].detach().numpy()\n",
    "\n",
    "\n",
    "train_vectors = np.array(list(df_train.tweet_text.apply(encode_text).values))\n",
    "test_vectors = np.array(list(df_test.tweet_text.apply(encode_text).values))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model on soft labels\n",
    "Now, we train a simple logistic regression model on the BERT features, using labels\n",
    "obtained from our label model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of trained model: 0.86\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "sklearn_model = LogisticRegression(solver=\"liblinear\")\n",
    "sklearn_model.fit(train_vectors, probs_to_preds(Y_train_prob))\n",
    "\n",
    "print(f\"Accuracy of trained model: {sklearn_model.score(test_vectors, Y_test)}\")"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
