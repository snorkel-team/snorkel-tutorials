{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detecting spouse mentions in sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "We will walk through an example text classification task to explore how Snorkel works with user-defined LFs. Run every cell in the notebook (unless otherwise noted) before proceeding to the next one!\n",
    "## Classification Task\n",
    "<img src=\"imgs/sentence.jpg\" width=\"700px;\">\n",
    "\n",
    "We want to classify each __candidate__ or pair of people mentioned in a sentence, as being married at some point or not.\n",
    "\n",
    "In the above example, our candidate represents the possible relation `(Barack Obama, Michelle Obama)`. As readers, we know this mention is true due to external knowledge and the keyword of `wedding` occuring later in the sentence.\n",
    "We begin with some basic setup and data downloading.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "import pickle\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import subprocess\n",
    "\n",
    "if os.path.basename(os.getcwd()) == \"snorkel-tutorials\":\n",
    "    os.chdir(\"spouse\")\n",
    "\n",
    "subprocess.run([\"bash\", \"download_data.sh\"], check=True)\n",
    "with open(os.path.join(\"data/dev_data.pkl\"), \"rb\") as f:\n",
    "    dev_df = pickle.load(f)\n",
    "    dev_labels = pickle.load(f)\n",
    "\n",
    "with open(os.path.join(\"data/train_data.pkl\"), \"rb\") as f:\n",
    "    train_df = pickle.load(f)\n",
    "\n",
    "with open(os.path.join(\"data/test_data.pkl\"), \"rb\") as f:\n",
    "    test_df = pickle.load(f)\n",
    "    test_labels = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Input Data:** `dev_df` is a Pandas DataFrame object, where each row represents a particular __candidate__. The DataFrames contain the fields `sentence`, which refers to the sentence the candidate is in, `tokens`, the tokenized form of the sentence, `person1_word_idx` and `person2_word_idx`, which represent `[start, end]` indices in the tokens at which the first and second person's name appear, respectively.\n",
    "\n",
    "We also have certain **preprocessed fields**, that we discuss a few cells below. We have other tutorials focused on generating such datasets (e.g., from richy-formatted data), but assume we have access to a Pandas DataFrame for the purpose of this specific tutorial!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>person1_word_idx</th>\n",
       "      <th>person2_word_idx</th>\n",
       "      <th>sentence</th>\n",
       "      <th>tokens</th>\n",
       "      <th>person1_right_tokens</th>\n",
       "      <th>person2_right_tokens</th>\n",
       "      <th>between_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>(22, 24)</td>\n",
       "      <td>The Richards are half-sisters to Kathy Hilton,...</td>\n",
       "      <td>[The, Richards, are, half, -, sisters, to, Kat...</td>\n",
       "      <td>[are, half, -, sisters]</td>\n",
       "      <td>[., ]</td>\n",
       "      <td>[are, half, -, sisters, to, Kathy, Hilton, ,, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>(7, 8)</td>\n",
       "      <td>The Richards are half-sisters to Kathy Hilton,...</td>\n",
       "      <td>[The, Richards, are, half, -, sisters, to, Kat...</td>\n",
       "      <td>[are, half, -, sisters]</td>\n",
       "      <td>[,, the, mother, of]</td>\n",
       "      <td>[are, half, -, sisters, to]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(7, 8)</td>\n",
       "      <td>(22, 24)</td>\n",
       "      <td>The Richards are half-sisters to Kathy Hilton,...</td>\n",
       "      <td>[The, Richards, are, half, -, sisters, to, Kat...</td>\n",
       "      <td>[,, the, mother, of]</td>\n",
       "      <td>[., ]</td>\n",
       "      <td>[,, the, mother, of, socialite, Paris, Hilton,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(6, 6)</td>\n",
       "      <td>(20, 21)</td>\n",
       "      <td>Prior to both his guests, Colbert's monologue ...</td>\n",
       "      <td>[Prior, to, both, his, guests, ,, Colbert, s, ...</td>\n",
       "      <td>[s, monologue, -, parts]</td>\n",
       "      <td>[and, his, oft, -]</td>\n",
       "      <td>[s, monologue, -, parts, of, which, he, did, s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(2, 2)</td>\n",
       "      <td>(4, 5)</td>\n",
       "      <td>People reported Williams and Ven Veen tied the...</td>\n",
       "      <td>[People, reported, Williams, and, Ven, Veen, t...</td>\n",
       "      <td>[and, Ven, Veen, tied]</td>\n",
       "      <td>[tied, the, knot, Saturday]</td>\n",
       "      <td>[and]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  person1_word_idx person2_word_idx  \\\n",
       "0           (1, 1)         (22, 24)   \n",
       "1           (1, 1)           (7, 8)   \n",
       "2           (7, 8)         (22, 24)   \n",
       "3           (6, 6)         (20, 21)   \n",
       "4           (2, 2)           (4, 5)   \n",
       "\n",
       "                                            sentence  \\\n",
       "0  The Richards are half-sisters to Kathy Hilton,...   \n",
       "1  The Richards are half-sisters to Kathy Hilton,...   \n",
       "2  The Richards are half-sisters to Kathy Hilton,...   \n",
       "3  Prior to both his guests, Colbert's monologue ...   \n",
       "4  People reported Williams and Ven Veen tied the...   \n",
       "\n",
       "                                              tokens  \\\n",
       "0  [The, Richards, are, half, -, sisters, to, Kat...   \n",
       "1  [The, Richards, are, half, -, sisters, to, Kat...   \n",
       "2  [The, Richards, are, half, -, sisters, to, Kat...   \n",
       "3  [Prior, to, both, his, guests, ,, Colbert, s, ...   \n",
       "4  [People, reported, Williams, and, Ven, Veen, t...   \n",
       "\n",
       "       person1_right_tokens         person2_right_tokens  \\\n",
       "0   [are, half, -, sisters]                        [., ]   \n",
       "1   [are, half, -, sisters]         [,, the, mother, of]   \n",
       "2      [,, the, mother, of]                        [., ]   \n",
       "3  [s, monologue, -, parts]           [and, his, oft, -]   \n",
       "4    [and, Ven, Veen, tied]  [tied, the, knot, Saturday]   \n",
       "\n",
       "                                      between_tokens  \n",
       "0  [are, half, -, sisters, to, Kathy, Hilton, ,, ...  \n",
       "1                        [are, half, -, sisters, to]  \n",
       "2  [,, the, mother, of, socialite, Paris, Hilton,...  \n",
       "3  [s, monologue, -, parts, of, which, he, did, s...  \n",
       "4                                              [and]  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You'll interact with these candidates while writing labeling functions in Snorkel. We look at a candidate in the development set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence:   \t The engagement between Josh, who was previously married to Diane Lane, and his  former assistant was revealed in May, after a two year romance.   \n",
      "Person 1:   \t Josh\n",
      "Person 2:   \t Diane Lane\n"
     ]
    }
   ],
   "source": [
    "from preprocessors import get_person_text\n",
    "\n",
    "candidate = dev_df.loc[112]\n",
    "person_names = get_person_text(candidate)\n",
    "\n",
    "print(\"Sentence:   \\t\", candidate[\"sentence\"])\n",
    "print(\"Person 1:   \\t\", person_names[0])\n",
    "print(\"Person 2:   \\t\", person_names[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: Writing  Labeling Functions\n",
    "\n",
    "In Snorkel, our primary interface through which we provide training signal to the end extraction model we are training is by writing **labeling functions (LFs)** (as opposed to hand-labeling massive training sets).  We'll go through some examples for our spouse classification task below.\n",
    "\n",
    "A labeling function is a Python function that accepts a candidate, or a row of the DataFrame, as the input argument and outputs a label for the candidate. For ease of exposition in this notebook, we return `1` if it says the pair of persons in the candidate were married at some point,  `-1` if the pair of persons in the candidate were never married, and `0` if it doesn't know how to vote and abstains. In practice, many labeling functions are often unipolar: it labels only `1`s and `0`s, or it labels only `-1`s and `0`s.\n",
    "\n",
    "(Note we will change our mapping to use `2` to represent the absence of a relationship to match the multiclass convention when feeding it to the LabelModel later.)\n",
    "Recall that our goal is to ultimately train a high-performance classification model that predicts which of our candidates are true spouse relations. It turns out that we can do this by writing potentially low-quality labeling functions!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  I. Background\n",
    "\n",
    "## Preprocessing the Database\n",
    "\n",
    "In a real application, there is a lot of data preparation, parsing, and database loading that needs to be completed before we dive into writing labeling functions. Here we've pre-generated candidates in a pandas DataFrame object per split (train,dev,test).\n",
    "\n",
    "###  Using a _Development Set_ of Human-labeled Data\n",
    "\n",
    "In our setting, we will use the phrase _development set_ to refer to a set of examples (here, a subset of our training set) which we label by hand and use to help us develop and refine labeling functions.  Unlike the _test set_, which we do not look at and use for final evaluation, we can inspect the development set while writing labeling functions. This is a list of `{-1,1}` labels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Labeling Function Helpers\n",
    "\n",
    "When writing labeling functions, there are several operators you will use over and over again. In the case of text relation extraction as with this task, common operators include fetching text between mentions of the two people in a candidate, examing word windows around person mentions, etc. Note that other domains and tasks, the required preprocessors will be different.\n",
    "\n",
    "We provide several helper functions in `preprocessors`:  these are Python helper functions that you can apply to candidates in the DataFrame to return objects that are helpful during LF development. You can (and should!) write your own helper functions to help write LFs.\n",
    "\n",
    "We provide an example of a preprocessor definition here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from snorkel.labeling.preprocess import preprocessor\n",
    "\n",
    "\n",
    "@preprocessor\n",
    "def get_text_between(cand):\n",
    "    \"\"\"\n",
    "    Returns the text between the two person mentions in the sentence for a candidate\n",
    "    \"\"\"\n",
    "    start = cand.person1_word_idx[1] + 1\n",
    "    end = cand.person2_word_idx[0]\n",
    "    cand.text_between = \" \".join(cand.tokens[start:end])\n",
    "    return cand"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Candidate PreProcessors\n",
    "\n",
    "We provide a set of helper functions for this task in `preprocessors.py` that take as input a candidate, or row of a DataFrame in our case. For the purpose of the tutorial, we have two of these fields preprocessed in the data, which can be used when creating labeling functions.\n",
    "\n",
    "`get_between_tokens(cand)`\n",
    "\n",
    "`get_left_tokens(cand)`\n",
    "\n",
    "`get_right_tokens(cand)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "II. Labeling Functions\n",
    "\n",
    "# A. Pattern Matching Labeling Functions\n",
    "\n",
    "One powerful form of labeling function design is defining sets of keywords or regular expressions that, as a human labeler, you know are correlated with the true label. For example, we could define a dictionary of terms that occur between person names in a candidate. One simple dictionary of terms indicating a true relation could be, which we could use in a labeling function like shown below:\n",
    "\n",
    "    spouses = {'spouse', 'wife', 'husband', 'ex-wife', 'ex-husband'}\n",
    "\n",
    "\n",
    "    @labeling_function(resources=dict(spouses=spouses), preprocessors=[get_left_tokens])\n",
    "    def LF_husband_wife_left_window(x, spouses):\n",
    "        if len(set(spouses).intersection(set(x.person1_left_tokens))) > 0:\n",
    "            return POS\n",
    "        elif len(set(spouses).intersection(set(x.person2_left_tokens))) > 0:\n",
    "            return POS\n",
    "        else:\n",
    "            return ABSTAIN\n",
    "\n",
    "**Note that:**\n",
    "1. To access the text between the person mentions, we can use the **`get_left_tokens` preprocessor!**\n",
    "2. We use **resources like the spouses dictionary** to encode themes/categories of relationships!\n",
    "\n",
    "There are a few advantages of having preprocessors and labeling functions in this form:\n",
    "\n",
    "**Data Agnostic:**  Operate over multiple data types without rewriting\n",
    "\n",
    "**Incremental Processing:** Can create preprocessors as needed while writing LFs!\n",
    "\n",
    "**Future Use:** Can store them for later for different tasks since they are reproducible and modular\n",
    "\n",
    "**Optimizations:** Allows caching behind-the-scenes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "\n",
    "from snorkel.labeling.apply import PandasLFApplier\n",
    "from snorkel.labeling.lf import labeling_function\n",
    "from snorkel.types import DataPoint\n",
    "\n",
    "from preprocessors import get_left_tokens, get_person_last_names, get_person_text\n",
    "\n",
    "POS = 1\n",
    "NEG = -1\n",
    "ABSTAIN = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for the `spouse` words appearing between the person mentions\n",
    "spouses = {\"spouse\", \"wife\", \"husband\", \"ex-wife\", \"ex-husband\"}\n",
    "\n",
    "\n",
    "@labeling_function(resources=dict(spouses=spouses))\n",
    "def LF_husband_wife(x, spouses):\n",
    "    return POS if len(spouses.intersection(set(x.between_tokens))) > 0 else ABSTAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for the `spouse` words appearing to the left of the person mentions\n",
    "@labeling_function(resources=dict(spouses=spouses), preprocessors=[get_left_tokens])\n",
    "def LF_husband_wife_left_window(x, spouses):\n",
    "    if len(set(spouses).intersection(set(x.person1_left_tokens))) > 0:\n",
    "        return POS\n",
    "    elif len(set(spouses).intersection(set(x.person2_left_tokens))) > 0:\n",
    "        return POS\n",
    "    else:\n",
    "        return ABSTAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for the person mentions having the same last name\n",
    "@labeling_function()\n",
    "def LF_same_last_name(x):\n",
    "    p1_ln, p2_ln = get_person_last_names(x)\n",
    "\n",
    "    if p1_ln and p2_ln and p1_ln == p2_ln:\n",
    "        return POS\n",
    "    return ABSTAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for the words `and ... married` between person mentions\n",
    "@labeling_function()\n",
    "def LF_and_married(x):\n",
    "    return (\n",
    "        POS\n",
    "        if \"and\" in x.between_tokens and \"married\" in x.person2_right_tokens\n",
    "        else ABSTAIN\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for words that refer to `family` relationships between and to the left of the person mentions\n",
    "family = [\n",
    "    \"father\",\n",
    "    \"mother\",\n",
    "    \"sister\",\n",
    "    \"brother\",\n",
    "    \"son\",\n",
    "    \"daughter\",\n",
    "    \"grandfather\",\n",
    "    \"grandmother\",\n",
    "    \"uncle\",\n",
    "    \"aunt\",\n",
    "    \"cousin\",\n",
    "]\n",
    "family = set(family + [f + \"-in-law\" for f in family])\n",
    "\n",
    "\n",
    "@labeling_function(resources=dict(family=family))\n",
    "def LF_familial_relationship(x, family):\n",
    "    return POS if len(family.intersection(set(x.between_tokens))) > 0 else ABSTAIN\n",
    "\n",
    "\n",
    "@labeling_function(resources=dict(family=family), preprocessors=[get_left_tokens])\n",
    "def LF_family_left_window(x, family):\n",
    "    if len(set(family).intersection(set(x.person1_left_tokens))) > 0:\n",
    "        return NEG\n",
    "    elif len(set(family).intersection(set(x.person2_left_tokens))) > 0:\n",
    "        return NEG\n",
    "    else:\n",
    "        return ABSTAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for `other` relationship words between person mentions\n",
    "other = {\"boyfriend\", \"girlfriend\" \"boss\", \"employee\", \"secretary\", \"co-worker\"}\n",
    "\n",
    "\n",
    "@labeling_function(resources=dict(other=other))\n",
    "def LF_other_relationship(x, other):\n",
    "    return NEG if len(other.intersection(set(x.between_tokens))) > 0 else ABSTAIN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Apply Labeling Functions to the Data\n",
    "We create a list of labeling functions and apply them to the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/2811 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  4%|▎         | 104/2811 [00:00<00:02, 1032.52it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  7%|▋         | 208/2811 [00:00<00:02, 1032.43it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 11%|█         | 312/2811 [00:00<00:02, 1032.07it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 15%|█▍        | 414/2811 [00:00<00:02, 1026.29it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 18%|█▊        | 519/2811 [00:00<00:02, 1032.17it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 22%|██▏       | 624/2811 [00:00<00:02, 1035.19it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 26%|██▌       | 728/2811 [00:00<00:02, 1035.86it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 30%|██▉       | 833/2811 [00:00<00:01, 1037.85it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 33%|███▎      | 937/2811 [00:00<00:01, 1038.08it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 37%|███▋      | 1041/2811 [00:01<00:01, 1036.67it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 41%|████      | 1145/2811 [00:01<00:01, 1035.25it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 44%|████▍     | 1249/2811 [00:01<00:01, 1035.21it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 48%|████▊     | 1355/2811 [00:01<00:01, 1039.63it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 52%|█████▏    | 1459/2811 [00:01<00:01, 1039.30it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 56%|█████▌    | 1563/2811 [00:01<00:01, 1039.48it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 59%|█████▉    | 1667/2811 [00:01<00:01, 1038.74it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 63%|██████▎   | 1771/2811 [00:01<00:01, 1039.03it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 67%|██████▋   | 1875/2811 [00:01<00:00, 1037.16it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 70%|███████   | 1981/2811 [00:01<00:00, 1041.90it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 74%|███████▍  | 2086/2811 [00:02<00:00, 1037.42it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 78%|███████▊  | 2190/2811 [00:02<00:00, 1033.28it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 82%|████████▏ | 2295/2811 [00:02<00:00, 1037.53it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 85%|████████▌ | 2400/2811 [00:02<00:00, 1039.59it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 89%|████████▉ | 2505/2811 [00:02<00:00, 1040.15it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 93%|█████████▎| 2610/2811 [00:02<00:00, 1041.84it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 97%|█████████▋| 2715/2811 [00:02<00:00, 1042.67it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "100%|██████████| 2811/2811 [00:02<00:00, 1037.14it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "lfs = [\n",
    "    LF_husband_wife,\n",
    "    LF_husband_wife_left_window,\n",
    "    LF_same_last_name,\n",
    "    LF_and_married,\n",
    "    LF_familial_relationship,\n",
    "    LF_family_left_window,\n",
    "    LF_other_relationship,\n",
    "]\n",
    "applier = PandasLFApplier(lfs)\n",
    "L = applier.apply(dev_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Labeling Function Metrics\n",
    "\n",
    "We can use the lf_summary function to measure various coverage related metrics for LFs. If we have gold labeled data, we can also evaluate accuracy.\n",
    "\n",
    "#### Polarity\n",
    "The set of label values the LF can output when it doesn't abstain. It is common for each LF to have a single polarity.\n",
    "\n",
    "#### Coverage\n",
    "The fraction of candidates that is labeled by our LF.\n",
    "\n",
    "#### Overlaps\n",
    "The fraction of examples labeled by the LF that is also labeled by another LF.\n",
    "\n",
    "#### Conflicts\n",
    "The fraction of examples labeled by the LF that is given a different (non-abstain) label by another LF.\n",
    "\n",
    "#### Correct\n",
    "The number of correctly labeled examples on the gold labeled data.\n",
    "\n",
    "#### Incorrect\n",
    "The number of incorrectly labeled examples on the gold labeled data.\n",
    "\n",
    "#### Empirical Accuracy\n",
    "The fraction of correctly labeled examples on the gold data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>j</th>\n",
       "      <th>Polarity</th>\n",
       "      <th>Coverage</th>\n",
       "      <th>Overlaps</th>\n",
       "      <th>Conflicts</th>\n",
       "      <th>Correct</th>\n",
       "      <th>Incorrect</th>\n",
       "      <th>Emp. Acc.</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LF_husband_wife</th>\n",
       "      <td>0</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.089648</td>\n",
       "      <td>0.035930</td>\n",
       "      <td>0.005336</td>\n",
       "      <td>93</td>\n",
       "      <td>146</td>\n",
       "      <td>0.369048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_husband_wife_left_window</th>\n",
       "      <td>1</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.025258</td>\n",
       "      <td>0.020633</td>\n",
       "      <td>0.001067</td>\n",
       "      <td>30</td>\n",
       "      <td>39</td>\n",
       "      <td>0.422535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_same_last_name</th>\n",
       "      <td>2</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.040555</td>\n",
       "      <td>0.014230</td>\n",
       "      <td>0.003557</td>\n",
       "      <td>19</td>\n",
       "      <td>95</td>\n",
       "      <td>0.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_and_married</th>\n",
       "      <td>3</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.001423</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_familial_relationship</th>\n",
       "      <td>4</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.115617</td>\n",
       "      <td>0.049449</td>\n",
       "      <td>0.032729</td>\n",
       "      <td>15</td>\n",
       "      <td>299</td>\n",
       "      <td>0.046154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_family_left_window</th>\n",
       "      <td>5</td>\n",
       "      <td>[2]</td>\n",
       "      <td>0.041266</td>\n",
       "      <td>0.033440</td>\n",
       "      <td>0.033440</td>\n",
       "      <td>110</td>\n",
       "      <td>2</td>\n",
       "      <td>0.948276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_other_relationship</th>\n",
       "      <td>6</td>\n",
       "      <td>[2]</td>\n",
       "      <td>0.007115</td>\n",
       "      <td>0.001067</td>\n",
       "      <td>0.001067</td>\n",
       "      <td>14</td>\n",
       "      <td>3</td>\n",
       "      <td>0.700000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             j Polarity  Coverage  Overlaps  Conflicts  \\\n",
       "LF_husband_wife              0      [1]  0.089648  0.035930   0.005336   \n",
       "LF_husband_wife_left_window  1      [1]  0.025258  0.020633   0.001067   \n",
       "LF_same_last_name            2      [1]  0.040555  0.014230   0.003557   \n",
       "LF_and_married               3      [1]  0.001423  0.000000   0.000000   \n",
       "LF_familial_relationship     4      [1]  0.115617  0.049449   0.032729   \n",
       "LF_family_left_window        5      [2]  0.041266  0.033440   0.033440   \n",
       "LF_other_relationship        6      [2]  0.007115  0.001067   0.001067   \n",
       "\n",
       "                             Correct  Incorrect  Emp. Acc.  \n",
       "LF_husband_wife                   93        146   0.369048  \n",
       "LF_husband_wife_left_window       30         39   0.422535  \n",
       "LF_same_last_name                 19         95   0.166667  \n",
       "LF_and_married                     2          2   0.500000  \n",
       "LF_familial_relationship          15        299   0.046154  \n",
       "LF_family_left_window            110          2   0.948276  \n",
       "LF_other_relationship             14          3   0.700000  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from snorkel.analysis.utils import convert_labels\n",
    "from snorkel.labeling.analysis import lf_summary\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "Y_cat = convert_labels(dev_labels, \"plusminus\", \"categorical\")\n",
    "L_cat = convert_labels(L.todense(), \"plusminus\", \"categorical\")\n",
    "lf_names = [lf.name for lf in lfs]\n",
    "\n",
    "lf_summary(csr_matrix(L_cat), Y_cat, lf_names=lf_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## B. Distant Supervision Labeling Functions\n",
    "\n",
    "In addition to using factories that encode pattern matching heuristics, we can also write labeling functions that _distantly supervise_ examples. Here, we'll load in a list of known spouse pairs and check to see if the pair of persons in a candidate matches one of these.\n",
    "\n",
    "**DBpedia**\n",
    "http://wiki.dbpedia.org/\n",
    "Our database of known spouses comes from DBpedia, which is a community-driven resource similar to Wikipedia but for curating structured data. We'll use a preprocessed snapshot as our knowledge base for all labeling function development.\n",
    "\n",
    "We can look at some of the example entries from DBPedia and use them in a simple distant supervision labeling function.\n",
    "\n",
    "Make sure `dbpedia.pkl` is in the `tutorials/workshop/` directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Jane Digby', 'The Earl of Ellenborough'),\n",
       " ('Agnes of Hesse-Kassel', 'John Casimir'),\n",
       " ('Elisabeth of Hesse', 'Louis II of Zweibrücken'),\n",
       " ('Catherine Elisabeth of Brunswick-Lüneburg', 'Gerhard VI Count of Holstein'),\n",
       " ('Stanley Donen', 'Yvette Mimieux')]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"data/dbpedia.pkl\", \"rb\") as f:\n",
    "    known_spouses = pickle.load(f)\n",
    "\n",
    "list(known_spouses)[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "@labeling_function(resources=dict(known_spouses=known_spouses))\n",
    "def LF_distant_supervision(x: DataPoint, known_spouses: List[str]) -> int:\n",
    "    p1, p2 = get_person_text(x)\n",
    "    return POS if (p1, p2) in known_spouses or (p2, p1) in known_spouses else ABSTAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to get last name\n",
    "def last_name(s):\n",
    "    name_parts = s.split(\" \")\n",
    "    return name_parts[-1] if len(name_parts) > 1 else None\n",
    "\n",
    "\n",
    "# Last name pairs for known spouses\n",
    "last_names = set(\n",
    "    [\n",
    "        (last_name(x), last_name(y))\n",
    "        for x, y in known_spouses\n",
    "        if last_name(x) and last_name(y)\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "@labeling_function(resources=dict(last_names=last_names))\n",
    "def LF_distant_supervision_last_names(x: DataPoint, last_names: List[str]) -> int:\n",
    "    p1_ln, p2_ln = get_person_last_names(x)\n",
    "\n",
    "    return (\n",
    "        POS\n",
    "        if (p1_ln != p2_ln)\n",
    "        and ((p1_ln, p2_ln) in last_names or (p2_ln, p1_ln) in last_names)\n",
    "        else ABSTAIN\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Every time you write a new labeling function, add it to appliers and make sure to include it in the new L matrix!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "applier = PandasLFApplier(\n",
    "    [\n",
    "        LF_husband_wife,\n",
    "        LF_husband_wife_left_window,\n",
    "        LF_same_last_name,\n",
    "        LF_and_married,\n",
    "        LF_familial_relationship,\n",
    "        LF_family_left_window,\n",
    "        LF_other_relationship,\n",
    "        LF_distant_supervision,\n",
    "        LF_distant_supervision_last_names,\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/2811 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  3%|▎         | 90/2811 [00:00<00:03, 890.68it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  6%|▋         | 179/2811 [00:00<00:02, 890.06it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  9%|▉         | 267/2811 [00:00<00:02, 885.97it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 13%|█▎        | 356/2811 [00:00<00:02, 885.94it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 16%|█▌        | 445/2811 [00:00<00:02, 884.43it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 19%|█▉        | 535/2811 [00:00<00:02, 888.57it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 22%|██▏       | 626/2811 [00:00<00:02, 893.64it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 25%|██▌       | 716/2811 [00:00<00:02, 895.43it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 29%|██▊       | 806/2811 [00:00<00:02, 896.40it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 32%|███▏      | 896/2811 [00:01<00:02, 896.81it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 35%|███▌      | 986/2811 [00:01<00:02, 897.34it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 38%|███▊      | 1075/2811 [00:01<00:01, 894.33it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 41%|████▏     | 1165/2811 [00:01<00:01, 895.28it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 45%|████▍     | 1255/2811 [00:01<00:01, 895.71it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 48%|████▊     | 1346/2811 [00:01<00:01, 898.15it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 51%|█████     | 1437/2811 [00:01<00:01, 900.44it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 54%|█████▍    | 1528/2811 [00:01<00:01, 901.00it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 58%|█████▊    | 1618/2811 [00:01<00:01, 899.66it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 61%|██████    | 1708/2811 [00:01<00:01, 898.92it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 64%|██████▍   | 1798/2811 [00:02<00:01, 898.89it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 67%|██████▋   | 1888/2811 [00:02<00:01, 898.01it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 70%|███████   | 1979/2811 [00:02<00:00, 899.51it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 74%|███████▎  | 2069/2811 [00:02<00:00, 893.53it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 77%|███████▋  | 2159/2811 [00:02<00:00, 895.26it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|████████  | 2250/2811 [00:02<00:00, 896.74it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 83%|████████▎ | 2340/2811 [00:02<00:00, 896.15it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 86%|████████▋ | 2431/2811 [00:02<00:00, 897.80it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 90%|████████▉ | 2522/2811 [00:02<00:00, 898.96it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 93%|█████████▎| 2613/2811 [00:02<00:00, 900.28it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 96%|█████████▌| 2704/2811 [00:03<00:00, 900.24it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 99%|█████████▉| 2795/2811 [00:03<00:00, 899.84it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "100%|██████████| 2811/2811 [00:03<00:00, 895.58it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\r",
      "  0%|          | 0/22254 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 84/22254 [00:00<00:26, 831.95it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  1%|          | 173/22254 [00:00<00:26, 847.65it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  1%|          | 263/22254 [00:00<00:25, 861.36it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  2%|▏         | 352/22254 [00:00<00:25, 869.58it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  2%|▏         | 441/22254 [00:00<00:24, 874.01it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  2%|▏         | 530/22254 [00:00<00:24, 877.33it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  3%|▎         | 619/22254 [00:00<00:24, 878.86it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  3%|▎         | 708/22254 [00:00<00:24, 879.77it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  4%|▎         | 798/22254 [00:00<00:24, 883.88it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  4%|▍         | 887/22254 [00:01<00:24, 885.67it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  4%|▍         | 976/22254 [00:01<00:23, 886.79it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  5%|▍         | 1065/22254 [00:01<00:23, 886.87it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  5%|▌         | 1154/22254 [00:01<00:23, 887.21it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  6%|▌         | 1243/22254 [00:01<00:23, 887.87it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  6%|▌         | 1333/22254 [00:01<00:23, 889.45it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  6%|▋         | 1422/22254 [00:01<00:23, 886.98it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  7%|▋         | 1511/22254 [00:01<00:23, 886.75it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  7%|▋         | 1600/22254 [00:01<00:23, 884.91it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  8%|▊         | 1689/22254 [00:01<00:23, 885.71it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  8%|▊         | 1778/22254 [00:02<00:23, 886.48it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  8%|▊         | 1868/22254 [00:02<00:22, 889.27it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  9%|▉         | 1957/22254 [00:02<00:23, 881.64it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  9%|▉         | 2046/22254 [00:02<00:22, 883.67it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 10%|▉         | 2135/22254 [00:02<00:22, 884.58it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 10%|▉         | 2224/22254 [00:02<00:22, 885.12it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 10%|█         | 2314/22254 [00:02<00:22, 887.93it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 11%|█         | 2403/22254 [00:02<00:22, 886.55it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 11%|█         | 2492/22254 [00:02<00:22, 885.79it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 12%|█▏        | 2581/22254 [00:02<00:22, 884.65it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 12%|█▏        | 2670/22254 [00:03<00:22, 879.65it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 12%|█▏        | 2759/22254 [00:03<00:22, 882.47it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 13%|█▎        | 2848/22254 [00:03<00:22, 881.79it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 13%|█▎        | 2937/22254 [00:03<00:21, 882.58it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 14%|█▎        | 3027/22254 [00:03<00:21, 885.68it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 14%|█▍        | 3117/22254 [00:03<00:21, 888.60it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 14%|█▍        | 3206/22254 [00:03<00:21, 886.67it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 15%|█▍        | 3295/22254 [00:03<00:21, 884.24it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 15%|█▌        | 3384/22254 [00:03<00:21, 885.72it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 16%|█▌        | 3473/22254 [00:03<00:21, 885.97it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 16%|█▌        | 3562/22254 [00:04<00:21, 883.90it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 16%|█▋        | 3651/22254 [00:04<00:21, 884.44it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 17%|█▋        | 3740/22254 [00:04<00:20, 884.30it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 17%|█▋        | 3829/22254 [00:04<00:20, 884.16it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 18%|█▊        | 3919/22254 [00:04<00:20, 886.46it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 18%|█▊        | 4008/22254 [00:04<00:20, 886.68it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 18%|█▊        | 4097/22254 [00:04<00:20, 887.29it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 19%|█▉        | 4186/22254 [00:04<00:20, 886.68it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 19%|█▉        | 4275/22254 [00:04<00:20, 885.83it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|█▉        | 4364/22254 [00:04<00:20, 884.95it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|██        | 4453/22254 [00:05<00:20, 884.12it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|██        | 4543/22254 [00:05<00:19, 886.68it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 21%|██        | 4633/22254 [00:05<00:19, 888.27it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 21%|██        | 4722/22254 [00:05<00:19, 887.75it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 22%|██▏       | 4811/22254 [00:05<00:19, 887.93it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 22%|██▏       | 4900/22254 [00:05<00:19, 888.23it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 22%|██▏       | 4989/22254 [00:05<00:19, 885.55it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 23%|██▎       | 5079/22254 [00:05<00:19, 887.42it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 23%|██▎       | 5169/22254 [00:05<00:19, 889.72it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 24%|██▎       | 5258/22254 [00:05<00:19, 889.62it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 24%|██▍       | 5348/22254 [00:06<00:18, 889.89it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 24%|██▍       | 5437/22254 [00:06<00:18, 889.86it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 25%|██▍       | 5527/22254 [00:06<00:18, 891.94it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 25%|██▌       | 5617/22254 [00:06<00:18, 893.06it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 26%|██▌       | 5707/22254 [00:06<00:18, 894.23it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 26%|██▌       | 5797/22254 [00:06<00:18, 894.58it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 26%|██▋       | 5887/22254 [00:06<00:18, 894.96it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 27%|██▋       | 5977/22254 [00:06<00:18, 891.69it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 27%|██▋       | 6067/22254 [00:06<00:18, 889.10it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 28%|██▊       | 6156/22254 [00:06<00:18, 887.15it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 28%|██▊       | 6245/22254 [00:07<00:18, 883.19it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 28%|██▊       | 6335/22254 [00:07<00:17, 885.88it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 29%|██▉       | 6425/22254 [00:07<00:17, 887.71it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 29%|██▉       | 6514/22254 [00:07<00:17, 888.16it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 30%|██▉       | 6603/22254 [00:07<00:17, 887.91it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 30%|███       | 6692/22254 [00:07<00:17, 887.49it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 30%|███       | 6781/22254 [00:07<00:17, 877.92it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 31%|███       | 6870/22254 [00:07<00:17, 880.18it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 31%|███▏      | 6959/22254 [00:07<00:17, 881.49it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 32%|███▏      | 7048/22254 [00:07<00:17, 878.21it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 32%|███▏      | 7137/22254 [00:08<00:17, 880.84it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 32%|███▏      | 7227/22254 [00:08<00:16, 885.47it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 33%|███▎      | 7316/22254 [00:08<00:16, 885.93it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 33%|███▎      | 7406/22254 [00:08<00:16, 887.54it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 34%|███▎      | 7495/22254 [00:08<00:16, 884.09it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 34%|███▍      | 7585/22254 [00:08<00:16, 886.29it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 34%|███▍      | 7674/22254 [00:08<00:16, 887.38it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 35%|███▍      | 7763/22254 [00:08<00:16, 886.76it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 35%|███▌      | 7852/22254 [00:08<00:16, 887.35it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 36%|███▌      | 7941/22254 [00:08<00:16, 885.92it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 36%|███▌      | 8030/22254 [00:09<00:16, 882.86it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 36%|███▋      | 8120/22254 [00:09<00:15, 884.63it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 37%|███▋      | 8209/22254 [00:09<00:15, 884.72it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 37%|███▋      | 8299/22254 [00:09<00:15, 888.35it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 38%|███▊      | 8388/22254 [00:09<00:15, 888.64it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 38%|███▊      | 8478/22254 [00:09<00:15, 890.74it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 39%|███▊      | 8568/22254 [00:09<00:15, 891.03it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 39%|███▉      | 8658/22254 [00:09<00:15, 889.15it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 39%|███▉      | 8747/22254 [00:09<00:15, 888.00it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|███▉      | 8837/22254 [00:09<00:15, 890.27it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|████      | 8927/22254 [00:10<00:15, 885.41it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 41%|████      | 9016/22254 [00:10<00:15, 882.25it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 41%|████      | 9105/22254 [00:10<00:14, 883.71it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 41%|████▏     | 9194/22254 [00:10<00:14, 883.87it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 42%|████▏     | 9283/22254 [00:10<00:14, 881.74it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 42%|████▏     | 9373/22254 [00:10<00:14, 886.09it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 43%|████▎     | 9462/22254 [00:10<00:14, 884.94it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 43%|████▎     | 9551/22254 [00:10<00:14, 885.01it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 43%|████▎     | 9641/22254 [00:10<00:14, 888.10it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 44%|████▎     | 9730/22254 [00:10<00:14, 888.55it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 44%|████▍     | 9820/22254 [00:11<00:13, 890.20it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 45%|████▍     | 9910/22254 [00:11<00:13, 891.66it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 45%|████▍     | 10000/22254 [00:11<00:13, 891.36it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 45%|████▌     | 10090/22254 [00:11<00:13, 890.87it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 46%|████▌     | 10180/22254 [00:11<00:13, 890.73it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 46%|████▌     | 10270/22254 [00:11<00:13, 890.13it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 47%|████▋     | 10360/22254 [00:11<00:13, 887.59it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 47%|████▋     | 10449/22254 [00:11<00:13, 886.09it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 47%|████▋     | 10539/22254 [00:11<00:13, 888.72it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 48%|████▊     | 10628/22254 [00:11<00:13, 885.51it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 48%|████▊     | 10717/22254 [00:12<00:13, 881.91it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 49%|████▊     | 10806/22254 [00:12<00:13, 878.54it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 49%|████▉     | 10895/22254 [00:12<00:12, 879.64it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 49%|████▉     | 10983/22254 [00:12<00:12, 877.83it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|████▉     | 11073/22254 [00:12<00:12, 881.62it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|█████     | 11162/22254 [00:12<00:12, 882.84it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 51%|█████     | 11251/22254 [00:12<00:12, 884.05it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 51%|█████     | 11340/22254 [00:12<00:12, 882.08it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 51%|█████▏    | 11430/22254 [00:12<00:12, 884.58it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 52%|█████▏    | 11519/22254 [00:13<00:12, 885.09it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 52%|█████▏    | 11608/22254 [00:13<00:12, 880.04it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 53%|█████▎    | 11697/22254 [00:13<00:11, 880.76it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 53%|█████▎    | 11787/22254 [00:13<00:11, 884.41it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 53%|█████▎    | 11876/22254 [00:13<00:11, 885.42it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 54%|█████▍    | 11965/22254 [00:13<00:11, 885.50it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 54%|█████▍    | 12055/22254 [00:13<00:11, 889.08it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 55%|█████▍    | 12144/22254 [00:13<00:11, 889.10it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 55%|█████▍    | 12233/22254 [00:13<00:11, 889.12it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 55%|█████▌    | 12322/22254 [00:13<00:11, 889.29it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 56%|█████▌    | 12411/22254 [00:14<00:11, 885.99it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 56%|█████▌    | 12501/22254 [00:14<00:10, 887.53it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 57%|█████▋    | 12591/22254 [00:14<00:10, 889.46it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 57%|█████▋    | 12680/22254 [00:14<00:10, 889.44it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 57%|█████▋    | 12769/22254 [00:14<00:10, 888.74it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 58%|█████▊    | 12858/22254 [00:14<00:10, 888.25it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 58%|█████▊    | 12947/22254 [00:14<00:10, 888.62it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 59%|█████▊    | 13036/22254 [00:14<00:10, 888.68it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 59%|█████▉    | 13125/22254 [00:14<00:10, 887.71it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 59%|█████▉    | 13214/22254 [00:14<00:10, 886.29it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|█████▉    | 13303/22254 [00:15<00:10, 886.64it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|██████    | 13392/22254 [00:15<00:10, 883.54it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 61%|██████    | 13482/22254 [00:15<00:09, 886.45it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 61%|██████    | 13572/22254 [00:15<00:09, 887.77it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 61%|██████▏   | 13663/22254 [00:15<00:09, 891.79it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 62%|██████▏   | 13753/22254 [00:15<00:09, 891.14it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 62%|██████▏   | 13843/22254 [00:15<00:09, 889.73it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 63%|██████▎   | 13933/22254 [00:15<00:09, 890.61it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 63%|██████▎   | 14023/22254 [00:15<00:09, 888.46it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 63%|██████▎   | 14112/22254 [00:15<00:09, 884.67it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 64%|██████▍   | 14201/22254 [00:16<00:09, 885.10it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 64%|██████▍   | 14290/22254 [00:16<00:09, 884.80it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 65%|██████▍   | 14379/22254 [00:16<00:08, 884.90it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 65%|██████▌   | 14468/22254 [00:16<00:08, 883.78it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 65%|██████▌   | 14558/22254 [00:16<00:08, 886.71it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 66%|██████▌   | 14648/22254 [00:16<00:08, 887.87it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 66%|██████▌   | 14738/22254 [00:16<00:08, 891.25it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 67%|██████▋   | 14828/22254 [00:16<00:08, 886.53it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 67%|██████▋   | 14917/22254 [00:16<00:08, 883.34it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 67%|██████▋   | 15007/22254 [00:16<00:08, 886.21it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 68%|██████▊   | 15097/22254 [00:17<00:08, 889.44it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 68%|██████▊   | 15186/22254 [00:17<00:07, 889.31it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 69%|██████▊   | 15275/22254 [00:17<00:07, 889.24it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 69%|██████▉   | 15365/22254 [00:17<00:07, 890.36it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 69%|██████▉   | 15455/22254 [00:17<00:07, 892.57it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 70%|██████▉   | 15545/22254 [00:17<00:07, 893.37it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 70%|███████   | 15635/22254 [00:17<00:07, 891.92it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 71%|███████   | 15725/22254 [00:17<00:07, 890.37it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 71%|███████   | 15815/22254 [00:17<00:07, 888.31it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 71%|███████▏  | 15905/22254 [00:17<00:07, 889.72it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 72%|███████▏  | 15995/22254 [00:18<00:07, 891.61it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 72%|███████▏  | 16085/22254 [00:18<00:06, 887.30it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 73%|███████▎  | 16174/22254 [00:18<00:06, 884.22it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 73%|███████▎  | 16263/22254 [00:18<00:06, 884.77it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 73%|███████▎  | 16353/22254 [00:18<00:06, 888.69it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 74%|███████▍  | 16443/22254 [00:18<00:06, 889.96it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 74%|███████▍  | 16533/22254 [00:18<00:06, 891.62it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 75%|███████▍  | 16623/22254 [00:18<00:06, 890.11it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 75%|███████▌  | 16713/22254 [00:18<00:06, 890.55it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 76%|███████▌  | 16803/22254 [00:18<00:06, 890.19it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 76%|███████▌  | 16893/22254 [00:19<00:06, 886.59it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 76%|███████▋  | 16982/22254 [00:19<00:05, 885.91it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 77%|███████▋  | 17071/22254 [00:19<00:05, 886.76it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 77%|███████▋  | 17160/22254 [00:19<00:05, 887.66it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 78%|███████▊  | 17249/22254 [00:19<00:05, 883.95it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 78%|███████▊  | 17339/22254 [00:19<00:05, 885.80it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 78%|███████▊  | 17428/22254 [00:19<00:05, 883.77it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 79%|███████▊  | 17517/22254 [00:19<00:05, 883.76it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 79%|███████▉  | 17607/22254 [00:19<00:05, 886.66it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|███████▉  | 17697/22254 [00:19<00:05, 887.70it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|███████▉  | 17786/22254 [00:20<00:05, 886.25it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|████████  | 17875/22254 [00:20<00:04, 886.03it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 81%|████████  | 17964/22254 [00:20<00:04, 881.59it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 81%|████████  | 18053/22254 [00:20<00:04, 879.48it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 82%|████████▏ | 18142/22254 [00:20<00:04, 881.44it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 82%|████████▏ | 18231/22254 [00:20<00:04, 882.27it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 82%|████████▏ | 18321/22254 [00:20<00:04, 886.06it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 83%|████████▎ | 18410/22254 [00:20<00:04, 886.05it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 83%|████████▎ | 18500/22254 [00:20<00:04, 887.33it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 84%|████████▎ | 18590/22254 [00:20<00:04, 888.67it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 84%|████████▍ | 18679/22254 [00:21<00:04, 888.51it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 84%|████████▍ | 18769/22254 [00:21<00:03, 889.09it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 85%|████████▍ | 18859/22254 [00:21<00:03, 890.16it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 85%|████████▌ | 18949/22254 [00:21<00:03, 890.63it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 86%|████████▌ | 19039/22254 [00:21<00:03, 891.45it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 86%|████████▌ | 19129/22254 [00:21<00:03, 892.48it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 86%|████████▋ | 19219/22254 [00:21<00:03, 892.58it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 87%|████████▋ | 19309/22254 [00:21<00:03, 893.06it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 87%|████████▋ | 19399/22254 [00:21<00:03, 892.53it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 88%|████████▊ | 19489/22254 [00:21<00:03, 892.24it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 88%|████████▊ | 19579/22254 [00:22<00:02, 891.83it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 88%|████████▊ | 19669/22254 [00:22<00:02, 890.64it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 89%|████████▉ | 19759/22254 [00:22<00:02, 886.58it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 89%|████████▉ | 19848/22254 [00:22<00:02, 886.02it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 90%|████████▉ | 19937/22254 [00:22<00:02, 885.39it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 90%|████████▉ | 20026/22254 [00:22<00:02, 886.06it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 90%|█████████ | 20115/22254 [00:22<00:02, 886.87it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 91%|█████████ | 20204/22254 [00:22<00:02, 887.73it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 91%|█████████ | 20294/22254 [00:22<00:02, 889.01it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 92%|█████████▏| 20383/22254 [00:22<00:02, 888.15it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 92%|█████████▏| 20472/22254 [00:23<00:02, 888.28it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 92%|█████████▏| 20561/22254 [00:23<00:01, 888.39it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 93%|█████████▎| 20650/22254 [00:23<00:01, 884.54it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 93%|█████████▎| 20739/22254 [00:23<00:01, 884.68it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 94%|█████████▎| 20829/22254 [00:23<00:01, 886.99it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 94%|█████████▍| 20918/22254 [00:23<00:01, 886.30it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 94%|█████████▍| 21008/22254 [00:23<00:01, 888.94it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 95%|█████████▍| 21098/22254 [00:23<00:01, 891.39it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 95%|█████████▌| 21188/22254 [00:23<00:01, 891.64it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 96%|█████████▌| 21278/22254 [00:23<00:01, 891.66it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 96%|█████████▌| 21368/22254 [00:24<00:00, 892.16it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 96%|█████████▋| 21458/22254 [00:24<00:00, 888.83it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 97%|█████████▋| 21547/22254 [00:24<00:00, 886.41it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 97%|█████████▋| 21636/22254 [00:24<00:00, 886.65it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 98%|█████████▊| 21725/22254 [00:24<00:00, 886.34it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 98%|█████████▊| 21814/22254 [00:24<00:00, 885.42it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 98%|█████████▊| 21903/22254 [00:24<00:00, 885.66it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 99%|█████████▉| 21992/22254 [00:24<00:00, 886.69it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 99%|█████████▉| 22081/22254 [00:24<00:00, 887.22it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "100%|█████████▉| 22170/22254 [00:25<00:00, 886.94it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "100%|██████████| 22254/22254 [00:25<00:00, 886.67it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "dev_L = applier.apply(dev_df)\n",
    "\n",
    "train_L = applier.apply(train_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## C. Writing Custom Labeling Functions\n",
    "\n",
    "The strength of LFs is that you can write any arbitrary function and use it to supervise a classification task. This approach can combine many of the same strategies discussed above or encode other information.\n",
    "\n",
    "For example, we observe that when mentions of person names occur far apart in a sentence, this is a good indicator that the candidate's label is False. You can write a labeling function that uses preprocessor `get_text_between` or the existing field `get_between_tokens` to write such an LF!\n",
    "\n",
    "**IMPORTANT** Good labeling functions manage a trade-off between high coverage and high precision. When constructing your dictionaries, think about building larger, noiser sets of terms instead of relying on 1 or 2 keywords. Sometimes a single word can be very predictive (e.g., `ex-wife`) but it's almost always better to define something more general, such as a regular expression pattern capturing _any_ string with the `ex-` prefix.\n",
    "\n",
    "**Try editing and running the cells below!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @labeling_function()\n",
    "# def LF_new(x: DataPoint) -> int:\n",
    "#     return POS if x.person1_word_idx[0] > 3 else ABSTAIN #TODO: Change this!\n",
    "\n",
    "# applier = PandasLFApplier([LF_new])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new_dev_L = applier.apply(dev_df)\n",
    "# dev_L = sp.hstack((dev_L, new_dev_L), format='csr')\n",
    "\n",
    "# new_train_L = applier.apply(train_df)\n",
    "# train_L = sp.hstack((train_L, new_train_L), format='csr')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Training the Label Model\n",
    "\n",
    "Now, we'll train a model of the LFs to estimate their accuracies. Once the model is trained, we can combine the outputs of the LFs into a single, noise-aware training label set for our extractor. Intuitively, we'll model the LFs by observing how they overlap and conflict with each other."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Label Model\n",
    "We know that our labeling functions will not be perfect, and some may be quite low-quality, so we will _model_ their accuracies with a factor-graph based label model, which Snorkel will help us easily apply.\n",
    "\n",
    "This will ultimately produce a single set of **noise-aware training labels**, which are probabilistic or confidence-weighted labels. We will then use these labels to train an end extraction model in the next notebook.  For more technical details of this overall approach, see our [NeurIPS 2016](https://arxiv.org/abs/1605.07723) and [AAAI 2019](https://arxiv.org/abs/1810.02840) papers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Training the Model\n",
    "When training the generative model, we use convert_labels with arguments `plusminus` and `categorical` to map our labeling convention from `{0,-1,1}` in the labeling functions to `{0,1,2}` as required by the `LabelModel`.\n",
    "\n",
    "**Parameter Definitions**\n",
    "\n",
    "    k  Cardinality, or the number of classes in the task\n",
    "    lr  The factor by which we update model weights after computing the gradient\n",
    "    class_balance Proportion of [positive, negative] samples in the dataset\n",
    "    n_epochs     A single pass through all the data in your training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not find kwarg \"k\" in destination dict.\n",
      "Computing O...\n",
      "Estimating \\mu...\n",
      "[1 epochs]: TRAIN:[loss=0.008]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "from snorkel.labeling.model.label_model import LabelModel\n",
    "from snorkel.analysis.utils import convert_labels\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "label_model = LabelModel(k=2, verbose=True, seed=123)\n",
    "label_model.train_model(\n",
    "    csr_matrix(convert_labels(train_L.toarray(), \"plusminus\", \"categorical\")),\n",
    "    lr=1e-1,\n",
    "    class_balance=[0.1, 0.9],\n",
    "    n_epochs=5000,\n",
    "    log_train_every=500,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Label Model Accuracy\n",
    "This is the accuracy of the labels inferred by the Label Model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9052904180540141"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from snorkel.analysis.metrics import metric_score\n",
    "from snorkel.analysis.utils import probs_to_preds\n",
    "\n",
    "Y_probs_dev = label_model.predict_proba(dev_L)\n",
    "Y_preds_dev = probs_to_preds(Y_probs_dev)\n",
    "metric_score(\n",
    "    convert_labels(dev_labels, \"plusminus\", \"categorical\"),\n",
    "    Y_preds_dev,\n",
    "    probs=None,\n",
    "    metric=\"accuracy\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Majority Vote Comparison\n",
    "We can also compare the performance of the LabelModel to computing a majority vote across all the LFs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.07029226785053644"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from snorkel.labeling.model import MajorityLabelVoter\n",
    "\n",
    "mv_model = MajorityLabelVoter()\n",
    "Y_probs_dev = mv_model.predict_proba(dev_L)\n",
    "Y_preds_dev = probs_to_preds(Y_probs_dev)\n",
    "metric_score(\n",
    "    convert_labels(dev_labels, \"plusminus\", \"categorical\"),\n",
    "    Y_preds_dev,\n",
    "    probs=None,\n",
    "    metric=\"accuracy\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting Probabilistic Labels\n",
    "One immediate santity check  you can peform using the generative model is to visually examine the distribution of predicted training probabilistic labels. Ideally, there should get a bimodal distribution with large seperation between each peaks, as shown below by the far right image. The corresponds to good signal for true and positive class labels. For your first Snorkel application, you'll probably see probabilistic labels closer to the far left or middle images. With all mass centered around p=0.5, as shown on the **left**, you probably need to write more LFs got get more overall _coverage_. In the **right** image, you have good negative coverage, but not enough positive LFs\n",
    "\n",
    "<img align=\"left\" src=\"imgs/marginals-common.jpg\" width=\"265px\" style=\"margin-right:0px\">\n",
    "\n",
    "<img align=\"center\" src=\"imgs/marginals-real.jpg\" width=\"265px\" style=\"margin-right:0px\">\n",
    "\n",
    "<img align=\"right\" src=\"imgs/marginals-ideal.jpg\" width=\"265px\" style=\"margin-right:0px\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "train_proba = label_model.predict_proba(\n",
    "    csr_matrix(convert_labels(train_L.todense(), \"plusminus\", \"categorical\"))\n",
    ")\n",
    "plt.hist(train_proba[:, 0], bins=20, range=(0.0, 1.0))\n",
    "plt.show()\n",
    "\n",
    "# # %% [markdown]\n",
    "# ## Part 4: Training our End Extraction Model\n",
    "# #\n",
    "# # In this final section of the tutorial, we'll use the noisy training labels we generated in the last tutorial part to train our end machine learning model.\n",
    "# #\n",
    "# # For this tutorial, we will be training a fairly effective deep learning model. More generally, however, Snorkel plugs in with many ML libraries, making it easy to use almost any state-of-the-art model as the end model!\n",
    "#\n",
    "# # %% [markdown]\n",
    "# ## II. Training a _Long Short-term Memory_ (LSTM) Neural Network\n",
    "#\n",
    "# [LSTMs](https://en.wikipedia.org/wiki/Long_short-term_memory) can acheive state-of-the-art performance on many text classification tasks. We'll train a simple LSTM model below. tf_model contains functions for processing features and building the tensorflow graphs for training and evaliation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tf_model import get_features_and_labels, get_train_and_loss_op, get_predictions_op"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0719 23:19:12.270254 139689312630592 deprecation.py:323] From /home/ubuntu/snorkel-tutorials/.tox/spouse/lib/python3.6/site-packages/tensorflow/python/data/ops/dataset_ops.py:494: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "tf.py_func is deprecated in TF V2. Instead, there are two\n",
      "    options available in V2.\n",
      "    - tf.py_function takes a python function which manipulates tf eager\n",
      "    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to\n",
      "    an ndarray (just call tensor.numpy()) but having access to eager tensors\n",
      "    means `tf.py_function`s can use accelerators such as GPUs as well as\n",
      "    being differentiable using a gradient tape.\n",
      "    - tf.numpy_function maintains the semantics of the deprecated tf.py_func\n",
      "    (it is not differentiable, and manipulates numpy arrays). It drops the\n",
      "    stateful argument making all functions stateful.\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0719 23:19:12.311430 139689312630592 deprecation_wrapper.py:119] From /home/ubuntu/snorkel-tutorials/spouse/tf_model.py:39: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0719 23:19:12.313472 139689312630592 deprecation.py:506] From /home/ubuntu/snorkel-tutorials/.tox/spouse/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0719 23:19:12.334612 139689312630592 deprecation_wrapper.py:119] From /home/ubuntu/snorkel-tutorials/spouse/tf_model.py:58: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0719 23:19:12.511238 139689312630592 deprecation.py:323] From /home/ubuntu/snorkel-tutorials/.tox/spouse/lib/python3.6/site-packages/tensorflow/python/keras/backend.py:3794: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0719 23:19:12.560349 139689312630592 deprecation_wrapper.py:119] From /home/ubuntu/snorkel-tutorials/spouse/tf_model.py:72: The name tf.train.get_or_create_global_step is deprecated. Please use tf.compat.v1.train.get_or_create_global_step instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0719 23:19:12.564123 139689312630592 deprecation_wrapper.py:119] From /home/ubuntu/snorkel-tutorials/spouse/tf_model.py:73: The name tf.train.AdagradOptimizer is deprecated. Please use tf.compat.v1.train.AdagradOptimizer instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0719 23:19:12.996038 139689312630592 deprecation.py:506] From /home/ubuntu/snorkel-tutorials/.tox/spouse/lib/python3.6/site-packages/tensorflow/python/training/adagrad.py:76: calling Constant.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.693599\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 0 loss: 0.531689\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final loss: 0.495880\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "sess = tf.InteractiveSession()\n",
    "# Train ops\n",
    "tokens, idx1, idx2, label_probs = get_features_and_labels(\n",
    "    train_df, train_proba, tf.float32\n",
    ")\n",
    "train_op, mean_loss = get_train_and_loss_op(tokens, idx1, idx2, label_probs)\n",
    "# Evaluation ops\n",
    "# Change label format for consistency with predict_proba.\n",
    "test_labels_flipped = 1 - convert_labels(test_labels, \"plusminus\", \"onezero\")\n",
    "tokens, idx1, idx2, test_labels_op = get_features_and_labels(\n",
    "    test_df, np.expand_dims(test_labels_flipped, 1), tf.int64\n",
    ")\n",
    "predictions_op = get_predictions_op(tokens, idx1, idx2)\n",
    "\n",
    "# Initialize and train. Set num_train_steps to ~ 2000.\n",
    "# Note: Training ~2000 steps takes several minutes.\n",
    "num_train_steps = 5\n",
    "sess.run(tf.global_variables_initializer())\n",
    "print(sess.run(mean_loss))\n",
    "for step in range(num_train_steps):\n",
    "    sess.run(train_op)\n",
    "    if step % 200 == 0:\n",
    "        print(\"step: %d loss: %f\" % (step, sess.run(mean_loss)))\n",
    "print(\"Final loss: %f\" % sess.run(mean_loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can measure the trained model's prediction accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9067431640625\n"
     ]
    }
   ],
   "source": [
    "# Measure model accuracy on test set.\n",
    "accuracy_op = tf.reduce_mean(\n",
    "    tf.cast(tf.equal(test_labels_op, predictions_op), tf.float32)\n",
    ")\n",
    "mean_accuracy = sum([sess.run(accuracy_op) for _ in range(100)]) / 100.0\n",
    "print(mean_accuracy)"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
