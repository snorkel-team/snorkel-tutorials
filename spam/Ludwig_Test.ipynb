{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from utils import load_spam_dataset\n",
    "\n",
    "df_train, df_valid, df_test = load_spam_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_train = df_train.sample(300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1586"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_train = [row.CONTENT for i, row in df_train.iterrows()]\n",
    "words_valid = [row.CONTENT for i, row in df_valid.iterrows()]\n",
    "words_test = [row.CONTENT for i, row in df_test.iterrows()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vectorizer = CountVectorizer(ngram_range=(1,2))               \n",
    "X_train = vectorizer.fit_transform(words_train)\n",
    "X_valid = vectorizer.transform(words_valid)\n",
    "X_test = vectorizer.transform(words_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train = df_train['LABEL'].map({1: 1, 2: 0})\n",
    "Y_valid = df_valid['LABEL'].map({1: 1, 2: 0})\n",
    "Y_test = df_test['LABEL'].map({1: 1, 2: 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/braden/repos/snorkel-tutorials/.env/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='warn', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "sklearn_model = LogisticRegression()\n",
    "# sklearn_model = RandomForestClassifier()\n",
    "sklearn_model.fit(X_train[:300,:], Y_train[:300])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8341740226986128\n",
      "0.8378378378378378\n",
      "0.8702702702702703\n"
     ]
    }
   ],
   "source": [
    "print(sklearn_model.score(X_train, Y_train))\n",
    "print(sklearn_model.score(X_valid, Y_valid))\n",
    "print(sklearn_model.score(X_test, Y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ludwig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['LABEL'] = df_train['LABEL'].map({1: 1, 2: 0})\n",
    "df_valid['LABEL'] = df_valid['LABEL'].map({1: 1, 2: 0})\n",
    "df_test['LABEL'] = df_test['LABEL'].map({1: 1, 2: 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Experiment name: api_experiment\n",
      "INFO:root:Model name: run\n",
      "INFO:root:Output path: results/api_experiment_run_17\n",
      "INFO:root:\n",
      "\n",
      "INFO:root:ludwig_version: '0.1.2'\n",
      "INFO:root:command: ('/Users/braden/repos/snorkel-tutorials/.env/lib/python3.7/site-packages/ipykernel_launcher.py '\n",
      " '-f '\n",
      " '/Users/braden/Library/Jupyter/runtime/kernel-afeb171d-e3e5-465f-a6a9-dd8412701efc.json')\n",
      "INFO:root:commit_hash: '94dc2f8b0732'\n",
      "INFO:root:random_seed: 42\n",
      "INFO:root:model_definition: {   'combiner': {'type': 'concat'},\n",
      "    'input_features': [   {   'encoder': 'parallel_cnn',\n",
      "                              'level': 'word',\n",
      "                              'name': 'CONTENT',\n",
      "                              'tied_weights': None,\n",
      "                              'type': 'text'}],\n",
      "    'output_features': [   {   'dependencies': [],\n",
      "                               'loss': {   'confidence_penalty': 0,\n",
      "                                           'robust_lambda': 0,\n",
      "                                           'threshold': 0.5,\n",
      "                                           'weight': 1},\n",
      "                               'name': 'LABEL',\n",
      "                               'reduce_dependencies': 'sum',\n",
      "                               'reduce_input': 'sum',\n",
      "                               'threshold': 0.5,\n",
      "                               'type': 'binary',\n",
      "                               'weight': 1}],\n",
      "    'preprocessing': {   'bag': {   'fill_value': '',\n",
      "                                    'format': 'space',\n",
      "                                    'lowercase': False,\n",
      "                                    'missing_value_strategy': 'fill_with_const',\n",
      "                                    'most_common': 10000},\n",
      "                         'binary': {   'fill_value': 0,\n",
      "                                       'missing_value_strategy': 'fill_with_const'},\n",
      "                         'category': {   'fill_value': '<UNK>',\n",
      "                                         'lowercase': False,\n",
      "                                         'missing_value_strategy': 'fill_with_const',\n",
      "                                         'most_common': 10000},\n",
      "                         'force_split': False,\n",
      "                         'image': {   'in_memory': True,\n",
      "                                      'missing_value_strategy': 'backfill',\n",
      "                                      'resize_method': 'crop_or_pad'},\n",
      "                         'numerical': {   'fill_value': 0,\n",
      "                                          'missing_value_strategy': 'fill_with_const'},\n",
      "                         'sequence': {   'fill_value': '',\n",
      "                                         'format': 'space',\n",
      "                                         'lowercase': False,\n",
      "                                         'missing_value_strategy': 'fill_with_const',\n",
      "                                         'most_common': 20000,\n",
      "                                         'padding': 'right',\n",
      "                                         'padding_symbol': '<PAD>',\n",
      "                                         'sequence_length_limit': 256,\n",
      "                                         'unknown_symbol': '<UNK>'},\n",
      "                         'set': {   'fill_value': '',\n",
      "                                    'format': 'space',\n",
      "                                    'lowercase': False,\n",
      "                                    'missing_value_strategy': 'fill_with_const',\n",
      "                                    'most_common': 10000},\n",
      "                         'split_probabilities': (0.7, 0.1, 0.2),\n",
      "                         'stratify': None,\n",
      "                         'text': {   'char_format': 'characters',\n",
      "                                     'char_most_common': 70,\n",
      "                                     'char_sequence_length_limit': 1024,\n",
      "                                     'fill_value': '',\n",
      "                                     'lowercase': True,\n",
      "                                     'missing_value_strategy': 'fill_with_const',\n",
      "                                     'padding': 'right',\n",
      "                                     'padding_symbol': '<PAD>',\n",
      "                                     'unknown_symbol': '<UNK>',\n",
      "                                     'word_format': 'space_punct',\n",
      "                                     'word_most_common': 20000,\n",
      "                                     'word_sequence_length_limit': 256},\n",
      "                         'timeseries': {   'fill_value': '',\n",
      "                                           'format': 'space',\n",
      "                                           'missing_value_strategy': 'fill_with_const',\n",
      "                                           'padding': 'right',\n",
      "                                           'padding_value': 0,\n",
      "                                           'timeseries_length_limit': 256}},\n",
      "    'training': {   'batch_size': 128,\n",
      "                    'bucketing_field': None,\n",
      "                    'decay': False,\n",
      "                    'decay_rate': 0.96,\n",
      "                    'decay_steps': 10000,\n",
      "                    'dropout_rate': 0.0,\n",
      "                    'early_stop': 5,\n",
      "                    'epochs': 10,\n",
      "                    'eval_batch_size': 0,\n",
      "                    'gradient_clipping': None,\n",
      "                    'increase_batch_size_on_plateau': 0,\n",
      "                    'increase_batch_size_on_plateau_max': 512,\n",
      "                    'increase_batch_size_on_plateau_patience': 5,\n",
      "                    'increase_batch_size_on_plateau_rate': 2,\n",
      "                    'learning_rate': 0.001,\n",
      "                    'learning_rate_warmup_epochs': 5,\n",
      "                    'optimizer': {   'beta1': 0.9,\n",
      "                                     'beta2': 0.999,\n",
      "                                     'epsilon': 1e-08,\n",
      "                                     'type': 'adam'},\n",
      "                    'reduce_learning_rate_on_plateau': 0,\n",
      "                    'reduce_learning_rate_on_plateau_patience': 5,\n",
      "                    'reduce_learning_rate_on_plateau_rate': 0.5,\n",
      "                    'regularization_lambda': 0,\n",
      "                    'regularizer': 'l2',\n",
      "                    'staircase': False,\n",
      "                    'validation_field': 'combined',\n",
      "                    'validation_measure': 'loss'}}\n",
      "INFO:root:\n",
      "\n",
      "INFO:root:Using training dataframe\n",
      "INFO:root:Building dataset (it may take a while)\n",
      "/Users/braden/repos/snorkel-tutorials/.env/lib/python3.7/site-packages/ludwig/features/binary_feature.py:62: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  np.bool_).as_matrix()\n",
      "INFO:root:Training set: 1586\n",
      "INFO:root:Validation set: 185\n",
      "INFO:root:Test set: 185\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/braden/repos/snorkel-tutorials/.env/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/braden/repos/snorkel-tutorials/.env/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/braden/repos/snorkel-tutorials/.env/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/braden/repos/snorkel-tutorials/.env/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/braden/repos/snorkel-tutorials/.env/lib/python3.7/site-packages/tensorflow/python/ops/math_grad.py:102: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Deprecated in favor of operator or tf.math.divide.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/braden/repos/snorkel-tutorials/.env/lib/python3.7/site-packages/tensorflow/python/ops/math_grad.py:102: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Deprecated in favor of operator or tf.math.divide.\n",
      "INFO:root:\n",
      "INFO:root:╒══════════╕\n",
      "INFO:root:│ TRAINING │\n",
      "INFO:root:╘══════════╛\n",
      "INFO:root:\n",
      "INFO:root:\n",
      "Epoch  1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 13/13 [00:34<00:00,  2.22s/it]\n",
      "Evaluation train: 100%|██████████| 13/13 [00:09<00:00,  1.60it/s]\n",
      "Evaluation vali : 100%|██████████| 2/2 [00:01<00:00,  1.34it/s]\n",
      "Evaluation test : 100%|██████████| 2/2 [00:01<00:00,  1.45it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Took 46.4701s\n",
      "INFO:root:╒═════════╤════════╤════════════╕\n",
      "│ LABEL   │   loss │   accuracy │\n",
      "╞═════════╪════════╪════════════╡\n",
      "│ train   │ 0.5706 │     0.6557 │\n",
      "├─────────┼────────┼────────────┤\n",
      "│ vali    │ 0.6926 │     0.6216 │\n",
      "├─────────┼────────┼────────────┤\n",
      "│ test    │ 0.7356 │     0.6108 │\n",
      "╘═════════╧════════╧════════════╛\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Validation loss on combined improved, model saved\n",
      "INFO:root:\n",
      "INFO:root:\n",
      "Epoch  2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 13/13 [00:31<00:00,  2.07s/it]\n",
      "Evaluation train: 100%|██████████| 13/13 [00:09<00:00,  1.62it/s]\n",
      "Evaluation vali : 100%|██████████| 2/2 [00:01<00:00,  1.39it/s]\n",
      "Evaluation test : 100%|██████████| 2/2 [00:01<00:00,  1.43it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Took 43.7995s\n",
      "INFO:root:╒═════════╤════════╤════════════╕\n",
      "│ LABEL   │   loss │   accuracy │\n",
      "╞═════════╪════════╪════════════╡\n",
      "│ train   │ 0.1351 │     0.9603 │\n",
      "├─────────┼────────┼────────────┤\n",
      "│ vali    │ 0.2021 │     0.8919 │\n",
      "├─────────┼────────┼────────────┤\n",
      "│ test    │ 0.2511 │     0.8865 │\n",
      "╘═════════╧════════╧════════════╛\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Validation loss on combined improved, model saved\n",
      "INFO:root:\n",
      "INFO:root:\n",
      "Epoch  3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 13/13 [00:32<00:00,  2.16s/it]\n",
      "Evaluation train: 100%|██████████| 13/13 [00:09<00:00,  1.56it/s]\n",
      "Evaluation vali : 100%|██████████| 2/2 [00:01<00:00,  1.29it/s]\n",
      "Evaluation test : 100%|██████████| 2/2 [00:01<00:00,  1.37it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Took 45.3486s\n",
      "INFO:root:╒═════════╤════════╤════════════╕\n",
      "│ LABEL   │   loss │   accuracy │\n",
      "╞═════════╪════════╪════════════╡\n",
      "│ train   │ 0.0692 │     0.9741 │\n",
      "├─────────┼────────┼────────────┤\n",
      "│ vali    │ 0.2185 │     0.9189 │\n",
      "├─────────┼────────┼────────────┤\n",
      "│ test    │ 0.2643 │     0.8919 │\n",
      "╘═════════╧════════╧════════════╛\n",
      "INFO:root:Last improvement of loss on combined happened 1 epoch ago\n",
      "INFO:root:\n",
      "INFO:root:\n",
      "Epoch  4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training: 100%|██████████| 13/13 [00:32<00:00,  2.11s/it]\n",
      "Evaluation train: 100%|██████████| 13/13 [00:10<00:00,  1.37it/s]\n",
      "Evaluation vali : 100%|██████████| 2/2 [00:01<00:00,  1.17it/s]\n",
      "Evaluation test : 100%|██████████| 2/2 [00:01<00:00,  1.23it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Took 45.5533s\n",
      "INFO:root:╒═════════╤════════╤════════════╕\n",
      "│ LABEL   │   loss │   accuracy │\n",
      "╞═════════╪════════╪════════════╡\n",
      "│ train   │ 0.0219 │     0.9956 │\n",
      "├─────────┼────────┼────────────┤\n",
      "│ vali    │ 0.1753 │     0.9243 │\n",
      "├─────────┼────────┼────────────┤\n",
      "│ test    │ 0.2255 │     0.8865 │\n",
      "╘═════════╧════════╧════════════╛\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Validation loss on combined improved, model saved\n",
      "INFO:root:\n",
      "INFO:root:\n",
      "Epoch  5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 13/13 [00:33<00:00,  2.20s/it]\n",
      "Evaluation train: 100%|██████████| 13/13 [00:09<00:00,  1.58it/s]\n",
      "Evaluation vali : 100%|██████████| 2/2 [00:01<00:00,  1.36it/s]\n",
      "Evaluation test : 100%|██████████| 2/2 [00:01<00:00,  1.44it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Took 45.8508s\n",
      "INFO:root:╒═════════╤════════╤════════════╕\n",
      "│ LABEL   │   loss │   accuracy │\n",
      "╞═════════╪════════╪════════════╡\n",
      "│ train   │ 0.0087 │     1.0000 │\n",
      "├─────────┼────────┼────────────┤\n",
      "│ vali    │ 0.1810 │     0.9351 │\n",
      "├─────────┼────────┼────────────┤\n",
      "│ test    │ 0.2292 │     0.9243 │\n",
      "╘═════════╧════════╧════════════╛\n",
      "INFO:root:Last improvement of loss on combined happened 1 epoch ago\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:\n",
      "INFO:root:\n",
      "Epoch  6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 13/13 [00:32<00:00,  2.14s/it]\n",
      "Evaluation train: 100%|██████████| 13/13 [00:09<00:00,  1.55it/s]\n",
      "Evaluation vali : 100%|██████████| 2/2 [00:01<00:00,  1.32it/s]\n",
      "Evaluation test : 100%|██████████| 2/2 [00:01<00:00,  1.40it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Took 44.2641s\n",
      "INFO:root:╒═════════╤════════╤════════════╕\n",
      "│ LABEL   │   loss │   accuracy │\n",
      "╞═════════╪════════╪════════════╡\n",
      "│ train   │ 0.0075 │     0.9994 │\n",
      "├─────────┼────────┼────────────┤\n",
      "│ vali    │ 0.1496 │     0.9243 │\n",
      "├─────────┼────────┼────────────┤\n",
      "│ test    │ 0.2157 │     0.8811 │\n",
      "╘═════════╧════════╧════════════╛\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Validation loss on combined improved, model saved\n",
      "INFO:root:\n",
      "INFO:root:\n",
      "Epoch  7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 13/13 [00:33<00:00,  2.20s/it]\n",
      "Evaluation train: 100%|██████████| 13/13 [00:09<00:00,  1.52it/s]\n",
      "Evaluation vali : 100%|██████████| 2/2 [00:01<00:00,  1.34it/s]\n",
      "Evaluation test : 100%|██████████| 2/2 [00:01<00:00,  1.39it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Took 45.6442s\n",
      "INFO:root:╒═════════╤════════╤════════════╕\n",
      "│ LABEL   │   loss │   accuracy │\n",
      "╞═════════╪════════╪════════════╡\n",
      "│ train   │ 0.0233 │     0.9968 │\n",
      "├─────────┼────────┼────────────┤\n",
      "│ vali    │ 0.1877 │     0.8973 │\n",
      "├─────────┼────────┼────────────┤\n",
      "│ test    │ 0.2975 │     0.8378 │\n",
      "╘═════════╧════════╧════════════╛\n",
      "INFO:root:Last improvement of loss on combined happened 1 epoch ago\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:\n",
      "INFO:root:\n",
      "Epoch  8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 13/13 [00:33<00:00,  2.19s/it]\n",
      "Evaluation train: 100%|██████████| 13/13 [00:09<00:00,  1.57it/s]\n",
      "Evaluation vali : 100%|██████████| 2/2 [00:01<00:00,  1.42it/s]\n",
      "Evaluation test : 100%|██████████| 2/2 [00:01<00:00,  1.38it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Took 45.4160s\n",
      "INFO:root:╒═════════╤════════╤════════════╕\n",
      "│ LABEL   │   loss │   accuracy │\n",
      "╞═════════╪════════╪════════════╡\n",
      "│ train   │ 0.0144 │     0.9987 │\n",
      "├─────────┼────────┼────────────┤\n",
      "│ vali    │ 0.1876 │     0.8973 │\n",
      "├─────────┼────────┼────────────┤\n",
      "│ test    │ 0.2863 │     0.8486 │\n",
      "╘═════════╧════════╧════════════╛\n",
      "INFO:root:Last improvement of loss on combined happened 2 epochs ago\n",
      "INFO:root:\n",
      "INFO:root:\n",
      "Epoch  9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training: 100%|██████████| 13/13 [00:32<00:00,  2.13s/it]\n",
      "Evaluation train: 100%|██████████| 13/13 [00:09<00:00,  1.61it/s]\n",
      "Evaluation vali : 100%|██████████| 2/2 [00:01<00:00,  1.38it/s]\n",
      "Evaluation test : 100%|██████████| 2/2 [00:01<00:00,  1.39it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Took 44.6549s\n",
      "INFO:root:╒═════════╤════════╤════════════╕\n",
      "│ LABEL   │   loss │   accuracy │\n",
      "╞═════════╪════════╪════════════╡\n",
      "│ train   │ 0.0015 │     1.0000 │\n",
      "├─────────┼────────┼────────────┤\n",
      "│ vali    │ 0.1573 │     0.9405 │\n",
      "├─────────┼────────┼────────────┤\n",
      "│ test    │ 0.2016 │     0.9027 │\n",
      "╘═════════╧════════╧════════════╛\n",
      "INFO:root:Last improvement of loss on combined happened 3 epochs ago\n",
      "INFO:root:\n",
      "INFO:root:\n",
      "Epoch 10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training: 100%|██████████| 13/13 [00:32<00:00,  2.18s/it]\n",
      "Evaluation train: 100%|██████████| 13/13 [00:10<00:00,  1.53it/s]\n",
      "Evaluation vali : 100%|██████████| 2/2 [00:01<00:00,  1.38it/s]\n",
      "Evaluation test : 100%|██████████| 2/2 [00:01<00:00,  1.31it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Took 45.1462s\n",
      "INFO:root:╒═════════╤════════╤════════════╕\n",
      "│ LABEL   │   loss │   accuracy │\n",
      "╞═════════╪════════╪════════════╡\n",
      "│ train   │ 0.0005 │     1.0000 │\n",
      "├─────────┼────────┼────────────┤\n",
      "│ vali    │ 0.1907 │     0.9405 │\n",
      "├─────────┼────────┼────────────┤\n",
      "│ test    │ 0.2356 │     0.9297 │\n",
      "╘═════════╧════════╧════════════╛\n",
      "INFO:root:Last improvement of loss on combined happened 4 epochs ago\n",
      "INFO:root:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Best validation model epoch:\n",
      "INFO:root:Best validation model loss on validation set combined: 0.14955258240570893\n",
      "INFO:root:Best validation model loss on test set combined: 0.21568492167704814\n",
      "INFO:root:\n",
      "Finished: api_experiment_run\n",
      "INFO:root:Saved to: results/api_experiment_run_17\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'train': OrderedDict([('LABEL',\n",
       "               OrderedDict([('loss',\n",
       "                             [0.5705828516360039,\n",
       "                              0.13507230946275053,\n",
       "                              0.06917764898507021,\n",
       "                              0.021943298312935223,\n",
       "                              0.008681294521197093,\n",
       "                              0.007493617912709788,\n",
       "                              0.0233009406477025,\n",
       "                              0.014446346129174491,\n",
       "                              0.0015194243522452526,\n",
       "                              0.0005479127078811541]),\n",
       "                            ('accuracy',\n",
       "                             [0.6557377049180327,\n",
       "                              0.9602774274905422,\n",
       "                              0.9741488020176545,\n",
       "                              0.9955863808322825,\n",
       "                              1.0,\n",
       "                              0.9993694829760403,\n",
       "                              0.9968474148802018,\n",
       "                              0.9987389659520807,\n",
       "                              1.0,\n",
       "                              1.0])])),\n",
       "              ('combined',\n",
       "               {'loss': [0.5705828516360039,\n",
       "                 0.13507230946275053,\n",
       "                 0.06917764898507021,\n",
       "                 0.021943298312935223,\n",
       "                 0.008681294521197093,\n",
       "                 0.007493617912709788,\n",
       "                 0.0233009406477025,\n",
       "                 0.014446346129174491,\n",
       "                 0.0015194243522452526,\n",
       "                 0.0005479127078811541],\n",
       "                'accuracy': [0.6557377049180327,\n",
       "                 0.9602774274905422,\n",
       "                 0.9741488020176545,\n",
       "                 0.9955863808322825,\n",
       "                 1.0,\n",
       "                 0.9993694829760403,\n",
       "                 0.9968474148802018,\n",
       "                 0.9987389659520807,\n",
       "                 1.0,\n",
       "                 1.0]})]),\n",
       " 'validation': OrderedDict([('LABEL',\n",
       "               OrderedDict([('loss',\n",
       "                             [0.692595218967747,\n",
       "                              0.20214009671597868,\n",
       "                              0.218501209568333,\n",
       "                              0.17534602397197002,\n",
       "                              0.18096224810626055,\n",
       "                              0.14955258240570893,\n",
       "                              0.1877452850341797,\n",
       "                              0.18762444161080025,\n",
       "                              0.15726764266555374,\n",
       "                              0.19071542894518054]),\n",
       "                            ('accuracy',\n",
       "                             [0.6216216216216216,\n",
       "                              0.8918918918918919,\n",
       "                              0.918918918918919,\n",
       "                              0.9243243243243243,\n",
       "                              0.9351351351351351,\n",
       "                              0.9243243243243243,\n",
       "                              0.8972972972972973,\n",
       "                              0.8972972972972973,\n",
       "                              0.9405405405405406,\n",
       "                              0.9405405405405406])])),\n",
       "              ('combined',\n",
       "               {'loss': [0.692595218967747,\n",
       "                 0.20214009671597868,\n",
       "                 0.218501209568333,\n",
       "                 0.17534602397197002,\n",
       "                 0.18096224810626055,\n",
       "                 0.14955258240570893,\n",
       "                 0.1877452850341797,\n",
       "                 0.18762444161080025,\n",
       "                 0.15726764266555374,\n",
       "                 0.19071542894518054],\n",
       "                'accuracy': [0.6216216216216216,\n",
       "                 0.8918918918918919,\n",
       "                 0.918918918918919,\n",
       "                 0.9243243243243243,\n",
       "                 0.9351351351351351,\n",
       "                 0.9243243243243243,\n",
       "                 0.8972972972972973,\n",
       "                 0.8972972972972973,\n",
       "                 0.9405405405405406,\n",
       "                 0.9405405405405406]})]),\n",
       " 'test': OrderedDict([('LABEL',\n",
       "               OrderedDict([('loss',\n",
       "                             [0.7356090648754223,\n",
       "                              0.25111203580289276,\n",
       "                              0.26434470511771535,\n",
       "                              0.22552156190614442,\n",
       "                              0.22922840633907834,\n",
       "                              0.21568492167704814,\n",
       "                              0.2974781964276288,\n",
       "                              0.2862645432755754,\n",
       "                              0.20162581366461677,\n",
       "                              0.23563887106405723]),\n",
       "                            ('accuracy',\n",
       "                             [0.6108108108108108,\n",
       "                              0.8864864864864865,\n",
       "                              0.8918918918918919,\n",
       "                              0.8864864864864865,\n",
       "                              0.9243243243243243,\n",
       "                              0.8810810810810811,\n",
       "                              0.8378378378378378,\n",
       "                              0.8486486486486486,\n",
       "                              0.9027027027027027,\n",
       "                              0.9297297297297298])])),\n",
       "              ('combined',\n",
       "               {'loss': [0.7356090648754223,\n",
       "                 0.25111203580289276,\n",
       "                 0.26434470511771535,\n",
       "                 0.22552156190614442,\n",
       "                 0.22922840633907834,\n",
       "                 0.21568492167704814,\n",
       "                 0.2974781964276288,\n",
       "                 0.2862645432755754,\n",
       "                 0.20162581366461677,\n",
       "                 0.23563887106405723],\n",
       "                'accuracy': [0.6108108108108108,\n",
       "                 0.8864864864864865,\n",
       "                 0.8918918918918919,\n",
       "                 0.8864864864864865,\n",
       "                 0.9243243243243243,\n",
       "                 0.8810810810810811,\n",
       "                 0.8378378378378378,\n",
       "                 0.8486486486486486,\n",
       "                 0.9027027027027027,\n",
       "                 0.9297297297297298]})])}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ludwig.api import LudwigModel\n",
    "\n",
    "model_definition = {\n",
    "    \"input_features\": [{\"name\": \"CONTENT\", \"type\": \"text\"}], \n",
    "    \"output_features\": [{\"name\": \"LABEL\", \"type\": \"binary\"}],\n",
    "    \"training\": {\"epochs\": 10},\n",
    "}\n",
    "ludwig_model = LudwigModel(model_definition)\n",
    "\n",
    "train_stats = ludwig_model.train(\n",
    "    data_train_df=df_train, \n",
    "    data_validation_df=df_valid, \n",
    "    data_test_df=df_test, \n",
    "    logging_level=20,\n",
    ")\n",
    "train_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9080459770114943"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from snorkel.analysis.utils import convert_labels\n",
    "from snorkel.analysis.metrics import metric_score\n",
    "\n",
    "Y_preds_test = convert_labels(ludwig_model.predict(df_test).LABEL_predictions.values.astype(int), \"onezero\", \"categorical\")\n",
    "metric_score(Y_test, Y_preds_test, probs=None, metric=\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "snorkel_tutorials_env",
   "language": "python",
   "name": "snorkel_tutorials_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
