{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from utils import load_spam_dataset\n",
    "\n",
    "df_train, df_valid, df_test = load_spam_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>COMMENT_ID</th>\n",
       "      <th>AUTHOR</th>\n",
       "      <th>DATE</th>\n",
       "      <th>CONTENT</th>\n",
       "      <th>LABEL</th>\n",
       "      <th>VIDEO_ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>z13vs53zipmszf1ib04cerd5xlmzdz5qlzw0k</td>\n",
       "      <td>Minecraft-Viasat</td>\n",
       "      <td>2014-11-03T14:38:53</td>\n",
       "      <td>Check my channel﻿</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>291</th>\n",
       "      <td>z13uvdwgrxetgfm0522tzr44tliyuvcgy04</td>\n",
       "      <td>Kawiana Lewis</td>\n",
       "      <td>2015-02-27T02:20:40.987000</td>\n",
       "      <td>Check out this video on YouTube:opponents mm &lt;...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>382</th>\n",
       "      <td>z130tflr2suzejk2s22expyzjmfjifvgs04</td>\n",
       "      <td>Sebastian Garcia</td>\n",
       "      <td>2014-10-16T00:50:14.327000</td>\n",
       "      <td>great l subscribe﻿</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285</th>\n",
       "      <td>z132ep1gxunohv3as04cgjsomlfhtnc5pwo0k</td>\n",
       "      <td>Jephone Cañas</td>\n",
       "      <td>2015-03-01T11:29:19.167000</td>\n",
       "      <td>this video has 800+m views&lt;br /&gt;and the channe...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>LneaDw26bFsNCzFDEM6x7-7RjXB5NjguHaB7LJf7qFg</td>\n",
       "      <td>dungeonturmoil1 .</td>\n",
       "      <td>NaN</td>\n",
       "      <td>YO GUYS SORRY IF THIS ANNOYS YOU!!! BUT CHECK ...</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>z13etj0bclzfztuwc04cgfvrgmf3fvjor1g</td>\n",
       "      <td>Jose Renteria</td>\n",
       "      <td>2013-11-29T00:22:01</td>\n",
       "      <td>We are an EDM apparel company dedicated to bri...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>z12uftqhewi0v3ozj04cgnyylzjitrozgv00k</td>\n",
       "      <td>Pamela  Foster</td>\n",
       "      <td>2015-05-16T11:42:37.704000</td>\n",
       "      <td>I like it&lt;br /&gt;﻿</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>z12ojfkgxxrxurgvz23vxxjg2rabwlikn</td>\n",
       "      <td>Mason Pearce</td>\n",
       "      <td>2015-05-18T07:12:10.556000</td>\n",
       "      <td>like if ur watchin in 900000000000000000000000...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>276</th>\n",
       "      <td>z12jwx2ikmq2hh05q04chpgannnofjzgxto0k</td>\n",
       "      <td>Alain Marius</td>\n",
       "      <td>2014-10-30T16:19:21</td>\n",
       "      <td>http://vimeo.com/106865403﻿</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307</th>\n",
       "      <td>z121j52qizrzhd2pa04ceht4jpeuzvzgunc0k</td>\n",
       "      <td>Niggly Wiggly</td>\n",
       "      <td>2014-11-10T17:39:10</td>\n",
       "      <td>Go to my channel if u want to see a fly gettin...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      COMMENT_ID             AUTHOR  \\\n",
       "84         z13vs53zipmszf1ib04cerd5xlmzdz5qlzw0k   Minecraft-Viasat   \n",
       "291          z13uvdwgrxetgfm0522tzr44tliyuvcgy04      Kawiana Lewis   \n",
       "382          z130tflr2suzejk2s22expyzjmfjifvgs04   Sebastian Garcia   \n",
       "285        z132ep1gxunohv3as04cgjsomlfhtnc5pwo0k      Jephone Cañas   \n",
       "184  LneaDw26bFsNCzFDEM6x7-7RjXB5NjguHaB7LJf7qFg  dungeonturmoil1 .   \n",
       "19           z13etj0bclzfztuwc04cgfvrgmf3fvjor1g      Jose Renteria   \n",
       "198        z12uftqhewi0v3ozj04cgnyylzjitrozgv00k    Pamela  Foster    \n",
       "161            z12ojfkgxxrxurgvz23vxxjg2rabwlikn       Mason Pearce   \n",
       "276        z12jwx2ikmq2hh05q04chpgannnofjzgxto0k       Alain Marius   \n",
       "307        z121j52qizrzhd2pa04ceht4jpeuzvzgunc0k      Niggly Wiggly   \n",
       "\n",
       "                           DATE  \\\n",
       "84          2014-11-03T14:38:53   \n",
       "291  2015-02-27T02:20:40.987000   \n",
       "382  2014-10-16T00:50:14.327000   \n",
       "285  2015-03-01T11:29:19.167000   \n",
       "184                         NaN   \n",
       "19          2013-11-29T00:22:01   \n",
       "198  2015-05-16T11:42:37.704000   \n",
       "161  2015-05-18T07:12:10.556000   \n",
       "276         2014-10-30T16:19:21   \n",
       "307         2014-11-10T17:39:10   \n",
       "\n",
       "                                               CONTENT  LABEL  VIDEO_ID  \n",
       "84                                   Check my channel﻿      1         1  \n",
       "291  Check out this video on YouTube:opponents mm <...      1         3  \n",
       "382                                 great l subscribe﻿      1         3  \n",
       "285  this video has 800+m views<br />and the channe...      1         3  \n",
       "184  YO GUYS SORRY IF THIS ANNOYS YOU!!! BUT CHECK ...      1         4  \n",
       "19   We are an EDM apparel company dedicated to bri...      1         1  \n",
       "198                                   I like it<br />﻿      2         3  \n",
       "161  like if ur watchin in 900000000000000000000000...      1         3  \n",
       "276                        http://vimeo.com/106865403﻿      1         2  \n",
       "307  Go to my channel if u want to see a fly gettin...      1         1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['LABEL'] = df_train['LABEL'].map({1: 1, 2: 0})\n",
    "df_valid['LABEL'] = df_valid['LABEL'].map({1: 1, 2: 0})\n",
    "df_test['LABEL'] = df_test['LABEL'].map({1: 1, 2: 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Experiment name: api_experiment\n",
      "INFO:root:Model name: run\n",
      "INFO:root:Output path: results/api_experiment_run_9\n",
      "INFO:root:\n",
      "\n",
      "INFO:root:ludwig_version: '0.1.2'\n",
      "INFO:root:command: ('/Users/braden/repos/snorkel-tutorials/.env/lib/python3.7/site-packages/ipykernel_launcher.py '\n",
      " '-f '\n",
      " '/Users/braden/Library/Jupyter/runtime/kernel-afeb171d-e3e5-465f-a6a9-dd8412701efc.json')\n",
      "INFO:root:commit_hash: '6c5785f3c5ec'\n",
      "INFO:root:random_seed: 42\n",
      "INFO:root:model_definition: {   'combiner': {'type': 'concat'},\n",
      "    'input_features': [   {   'encoder': 'parallel_cnn',\n",
      "                              'level': 'word',\n",
      "                              'name': 'CONTENT',\n",
      "                              'tied_weights': None,\n",
      "                              'type': 'text'}],\n",
      "    'output_features': [   {   'dependencies': [],\n",
      "                               'loss': {   'confidence_penalty': 0,\n",
      "                                           'robust_lambda': 0,\n",
      "                                           'threshold': 0.5,\n",
      "                                           'weight': 1},\n",
      "                               'name': 'LABEL',\n",
      "                               'reduce_dependencies': 'sum',\n",
      "                               'reduce_input': 'sum',\n",
      "                               'threshold': 0.5,\n",
      "                               'type': 'binary',\n",
      "                               'weight': 1}],\n",
      "    'preprocessing': {   'bag': {   'fill_value': '',\n",
      "                                    'format': 'space',\n",
      "                                    'lowercase': False,\n",
      "                                    'missing_value_strategy': 'fill_with_const',\n",
      "                                    'most_common': 10000},\n",
      "                         'binary': {   'fill_value': 0,\n",
      "                                       'missing_value_strategy': 'fill_with_const'},\n",
      "                         'category': {   'fill_value': '<UNK>',\n",
      "                                         'lowercase': False,\n",
      "                                         'missing_value_strategy': 'fill_with_const',\n",
      "                                         'most_common': 10000},\n",
      "                         'force_split': False,\n",
      "                         'image': {   'in_memory': True,\n",
      "                                      'missing_value_strategy': 'backfill',\n",
      "                                      'resize_method': 'crop_or_pad'},\n",
      "                         'numerical': {   'fill_value': 0,\n",
      "                                          'missing_value_strategy': 'fill_with_const'},\n",
      "                         'sequence': {   'fill_value': '',\n",
      "                                         'format': 'space',\n",
      "                                         'lowercase': False,\n",
      "                                         'missing_value_strategy': 'fill_with_const',\n",
      "                                         'most_common': 20000,\n",
      "                                         'padding': 'right',\n",
      "                                         'padding_symbol': '<PAD>',\n",
      "                                         'sequence_length_limit': 256,\n",
      "                                         'unknown_symbol': '<UNK>'},\n",
      "                         'set': {   'fill_value': '',\n",
      "                                    'format': 'space',\n",
      "                                    'lowercase': False,\n",
      "                                    'missing_value_strategy': 'fill_with_const',\n",
      "                                    'most_common': 10000},\n",
      "                         'split_probabilities': (0.7, 0.1, 0.2),\n",
      "                         'stratify': None,\n",
      "                         'text': {   'char_format': 'characters',\n",
      "                                     'char_most_common': 70,\n",
      "                                     'char_sequence_length_limit': 1024,\n",
      "                                     'fill_value': '',\n",
      "                                     'lowercase': True,\n",
      "                                     'missing_value_strategy': 'fill_with_const',\n",
      "                                     'padding': 'right',\n",
      "                                     'padding_symbol': '<PAD>',\n",
      "                                     'unknown_symbol': '<UNK>',\n",
      "                                     'word_format': 'space_punct',\n",
      "                                     'word_most_common': 20000,\n",
      "                                     'word_sequence_length_limit': 256},\n",
      "                         'timeseries': {   'fill_value': '',\n",
      "                                           'format': 'space',\n",
      "                                           'missing_value_strategy': 'fill_with_const',\n",
      "                                           'padding': 'right',\n",
      "                                           'padding_value': 0,\n",
      "                                           'timeseries_length_limit': 256}},\n",
      "    'training': {   'batch_size': 128,\n",
      "                    'bucketing_field': None,\n",
      "                    'decay': False,\n",
      "                    'decay_rate': 0.96,\n",
      "                    'decay_steps': 10000,\n",
      "                    'dropout_rate': 0.0,\n",
      "                    'early_stop': 5,\n",
      "                    'epochs': 8,\n",
      "                    'eval_batch_size': 0,\n",
      "                    'gradient_clipping': None,\n",
      "                    'increase_batch_size_on_plateau': 0,\n",
      "                    'increase_batch_size_on_plateau_max': 512,\n",
      "                    'increase_batch_size_on_plateau_patience': 5,\n",
      "                    'increase_batch_size_on_plateau_rate': 2,\n",
      "                    'learning_rate': 0.001,\n",
      "                    'learning_rate_warmup_epochs': 5,\n",
      "                    'optimizer': {   'beta1': 0.9,\n",
      "                                     'beta2': 0.999,\n",
      "                                     'epsilon': 1e-08,\n",
      "                                     'type': 'adam'},\n",
      "                    'reduce_learning_rate_on_plateau': 0,\n",
      "                    'reduce_learning_rate_on_plateau_patience': 5,\n",
      "                    'reduce_learning_rate_on_plateau_rate': 0.5,\n",
      "                    'regularization_lambda': 0,\n",
      "                    'regularizer': 'l2',\n",
      "                    'staircase': False,\n",
      "                    'validation_field': 'combined',\n",
      "                    'validation_measure': 'loss'}}\n",
      "INFO:root:\n",
      "\n",
      "INFO:root:Using training dataframe\n",
      "INFO:root:Building dataset (it may take a while)\n",
      "/Users/braden/repos/snorkel-tutorials/.env/lib/python3.7/site-packages/ludwig/features/binary_feature.py:62: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  np.bool_).as_matrix()\n",
      "INFO:root:Training set: 1586\n",
      "INFO:root:Validation set: 185\n",
      "INFO:root:Test set: 185\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/braden/repos/snorkel-tutorials/.env/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/braden/repos/snorkel-tutorials/.env/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/braden/repos/snorkel-tutorials/.env/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/braden/repos/snorkel-tutorials/.env/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/braden/repos/snorkel-tutorials/.env/lib/python3.7/site-packages/tensorflow/python/ops/math_grad.py:102: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Deprecated in favor of operator or tf.math.divide.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/braden/repos/snorkel-tutorials/.env/lib/python3.7/site-packages/tensorflow/python/ops/math_grad.py:102: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Deprecated in favor of operator or tf.math.divide.\n",
      "INFO:root:\n",
      "INFO:root:╒══════════╕\n",
      "INFO:root:│ TRAINING │\n",
      "INFO:root:╘══════════╛\n",
      "INFO:root:\n",
      "INFO:root:\n",
      "Epoch 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 13/13 [00:34<00:00,  2.23s/it]\n",
      "Evaluation train: 100%|██████████| 13/13 [00:09<00:00,  1.61it/s]\n",
      "Evaluation vali : 100%|██████████| 2/2 [00:01<00:00,  1.35it/s]\n",
      "Evaluation test : 100%|██████████| 2/2 [00:01<00:00,  1.49it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Took 46.8563s\n",
      "INFO:root:╒═════════╤════════╤════════════╕\n",
      "│ LABEL   │   loss │   accuracy │\n",
      "╞═════════╪════════╪════════════╡\n",
      "│ train   │ 0.5706 │     0.6557 │\n",
      "├─────────┼────────┼────────────┤\n",
      "│ vali    │ 0.7006 │     0.6270 │\n",
      "├─────────┼────────┼────────────┤\n",
      "│ test    │ 0.7303 │     0.6108 │\n",
      "╘═════════╧════════╧════════════╛\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Validation loss on combined improved, model saved\n",
      "INFO:root:\n",
      "INFO:root:\n",
      "Epoch 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 13/13 [00:32<00:00,  2.16s/it]\n",
      "Evaluation train: 100%|██████████| 13/13 [00:09<00:00,  1.56it/s]\n",
      "Evaluation vali : 100%|██████████| 2/2 [00:01<00:00,  1.29it/s]\n",
      "Evaluation test : 100%|██████████| 2/2 [00:01<00:00,  1.30it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Took 45.1110s\n",
      "INFO:root:╒═════════╤════════╤════════════╕\n",
      "│ LABEL   │   loss │   accuracy │\n",
      "╞═════════╪════════╪════════════╡\n",
      "│ train   │ 0.1351 │     0.9603 │\n",
      "├─────────┼────────┼────────────┤\n",
      "│ vali    │ 0.2492 │     0.8541 │\n",
      "├─────────┼────────┼────────────┤\n",
      "│ test    │ 0.2068 │     0.9081 │\n",
      "╘═════════╧════════╧════════════╛\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Validation loss on combined improved, model saved\n",
      "INFO:root:\n",
      "INFO:root:\n",
      "Epoch 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 13/13 [00:33<00:00,  2.20s/it]\n",
      "Evaluation train: 100%|██████████| 13/13 [00:09<00:00,  1.59it/s]\n",
      "Evaluation vali : 100%|██████████| 2/2 [00:01<00:00,  1.36it/s]\n",
      "Evaluation test : 100%|██████████| 2/2 [00:01<00:00,  1.35it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Took 45.7109s\n",
      "INFO:root:╒═════════╤════════╤════════════╕\n",
      "│ LABEL   │   loss │   accuracy │\n",
      "╞═════════╪════════╪════════════╡\n",
      "│ train   │ 0.0692 │     0.9741 │\n",
      "├─────────┼────────┼────────────┤\n",
      "│ vali    │ 0.2752 │     0.8919 │\n",
      "├─────────┼────────┼────────────┤\n",
      "│ test    │ 0.2104 │     0.9027 │\n",
      "╘═════════╧════════╧════════════╛\n",
      "INFO:root:Last improvement of loss on combined happened 1 epoch ago\n",
      "INFO:root:\n",
      "INFO:root:\n",
      "Epoch 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training: 100%|██████████| 13/13 [00:33<00:00,  2.17s/it]\n",
      "Evaluation train: 100%|██████████| 13/13 [00:09<00:00,  1.56it/s]\n",
      "Evaluation vali : 100%|██████████| 2/2 [00:01<00:00,  1.29it/s]\n",
      "Evaluation test : 100%|██████████| 2/2 [00:01<00:00,  1.24it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Took 45.6346s\n",
      "INFO:root:╒═════════╤════════╤════════════╕\n",
      "│ LABEL   │   loss │   accuracy │\n",
      "╞═════════╪════════╪════════════╡\n",
      "│ train   │ 0.0219 │     0.9956 │\n",
      "├─────────┼────────┼────────────┤\n",
      "│ vali    │ 0.2425 │     0.8865 │\n",
      "├─────────┼────────┼────────────┤\n",
      "│ test    │ 0.1634 │     0.9135 │\n",
      "╘═════════╧════════╧════════════╛\n",
      "INFO:root:Validation loss on combined improved, model saved\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:\n",
      "INFO:root:\n",
      "Epoch 5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 13/13 [00:32<00:00,  2.18s/it]\n",
      "Evaluation train: 100%|██████████| 13/13 [00:09<00:00,  1.54it/s]\n",
      "Evaluation vali : 100%|██████████| 2/2 [00:01<00:00,  1.36it/s]\n",
      "Evaluation test : 100%|██████████| 2/2 [00:01<00:00,  1.39it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Took 45.1020s\n",
      "INFO:root:╒═════════╤════════╤════════════╕\n",
      "│ LABEL   │   loss │   accuracy │\n",
      "╞═════════╪════════╪════════════╡\n",
      "│ train   │ 0.0087 │     1.0000 │\n",
      "├─────────┼────────┼────────────┤\n",
      "│ vali    │ 0.2531 │     0.9243 │\n",
      "├─────────┼────────┼────────────┤\n",
      "│ test    │ 0.1621 │     0.9243 │\n",
      "╘═════════╧════════╧════════════╛\n",
      "INFO:root:Last improvement of loss on combined happened 1 epoch ago\n",
      "INFO:root:\n",
      "INFO:root:\n",
      "Epoch 6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training: 100%|██████████| 13/13 [00:33<00:00,  2.28s/it]\n",
      "Evaluation train: 100%|██████████| 13/13 [00:10<00:00,  1.40it/s]\n",
      "Evaluation vali : 100%|██████████| 2/2 [00:01<00:00,  1.25it/s]\n",
      "Evaluation test : 100%|██████████| 2/2 [00:01<00:00,  1.21it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Took 46.7262s\n",
      "INFO:root:╒═════════╤════════╤════════════╕\n",
      "│ LABEL   │   loss │   accuracy │\n",
      "╞═════════╪════════╪════════════╡\n",
      "│ train   │ 0.0075 │     0.9994 │\n",
      "├─────────┼────────┼────────────┤\n",
      "│ vali    │ 0.2395 │     0.8649 │\n",
      "├─────────┼────────┼────────────┤\n",
      "│ test    │ 0.1447 │     0.9351 │\n",
      "╘═════════╧════════╧════════════╛\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Validation loss on combined improved, model saved\n",
      "INFO:root:\n",
      "INFO:root:\n",
      "Epoch 7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 13/13 [00:35<00:00,  2.33s/it]\n",
      "Evaluation train: 100%|██████████| 13/13 [00:10<00:00,  1.48it/s]\n",
      "Evaluation vali : 100%|██████████| 2/2 [00:01<00:00,  1.34it/s]\n",
      "Evaluation test : 100%|██████████| 2/2 [00:01<00:00,  1.41it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Took 48.6529s\n",
      "INFO:root:╒═════════╤════════╤════════════╕\n",
      "│ LABEL   │   loss │   accuracy │\n",
      "╞═════════╪════════╪════════════╡\n",
      "│ train   │ 0.0233 │     0.9968 │\n",
      "├─────────┼────────┼────────────┤\n",
      "│ vali    │ 0.3105 │     0.8378 │\n",
      "├─────────┼────────┼────────────┤\n",
      "│ test    │ 0.2095 │     0.8919 │\n",
      "╘═════════╧════════╧════════════╛\n",
      "INFO:root:Last improvement of loss on combined happened 1 epoch ago\n",
      "INFO:root:\n",
      "INFO:root:\n",
      "Epoch 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training: 100%|██████████| 13/13 [00:31<00:00,  2.11s/it]\n",
      "Evaluation train: 100%|██████████| 13/13 [00:09<00:00,  1.62it/s]\n",
      "Evaluation vali : 100%|██████████| 2/2 [00:01<00:00,  1.30it/s]\n",
      "Evaluation test : 100%|██████████| 2/2 [00:01<00:00,  1.30it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Took 43.8777s\n",
      "INFO:root:╒═════════╤════════╤════════════╕\n",
      "│ LABEL   │   loss │   accuracy │\n",
      "╞═════════╪════════╪════════════╡\n",
      "│ train   │ 0.0144 │     0.9987 │\n",
      "├─────────┼────────┼────────────┤\n",
      "│ vali    │ 0.3127 │     0.8378 │\n",
      "├─────────┼────────┼────────────┤\n",
      "│ test    │ 0.1978 │     0.8973 │\n",
      "╘═════════╧════════╧════════════╛\n",
      "INFO:root:Last improvement of loss on combined happened 2 epochs ago\n",
      "INFO:root:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Best validation model epoch:\n",
      "INFO:root:Best validation model loss on validation set combined: 0.23945783666662268\n",
      "INFO:root:Best validation model loss on test set combined: 0.14474767220986856\n",
      "INFO:root:\n",
      "Finished: api_experiment_run\n",
      "INFO:root:Saved to: results/api_experiment_run_9\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'train': OrderedDict([('LABEL',\n",
       "               OrderedDict([('loss',\n",
       "                             [0.5705828516360039,\n",
       "                              0.13507230946275053,\n",
       "                              0.06917764898507021,\n",
       "                              0.021943298312935223,\n",
       "                              0.008681294521197093,\n",
       "                              0.007493617912709788,\n",
       "                              0.0233009406477025,\n",
       "                              0.014446346129174491]),\n",
       "                            ('accuracy',\n",
       "                             [0.6557377049180327,\n",
       "                              0.9602774274905422,\n",
       "                              0.9741488020176545,\n",
       "                              0.9955863808322825,\n",
       "                              1.0,\n",
       "                              0.9993694829760403,\n",
       "                              0.9968474148802018,\n",
       "                              0.9987389659520807])])),\n",
       "              ('combined',\n",
       "               {'loss': [0.5705828516360039,\n",
       "                 0.13507230946275053,\n",
       "                 0.06917764898507021,\n",
       "                 0.021943298312935223,\n",
       "                 0.008681294521197093,\n",
       "                 0.007493617912709788,\n",
       "                 0.0233009406477025,\n",
       "                 0.014446346129174491],\n",
       "                'accuracy': [0.6557377049180327,\n",
       "                 0.9602774274905422,\n",
       "                 0.9741488020176545,\n",
       "                 0.9955863808322825,\n",
       "                 1.0,\n",
       "                 0.9993694829760403,\n",
       "                 0.9968474148802018,\n",
       "                 0.9987389659520807]})]),\n",
       " 'validation': OrderedDict([('LABEL',\n",
       "               OrderedDict([('loss',\n",
       "                             [0.7006066399651605,\n",
       "                              0.24917083946434226,\n",
       "                              0.27524916159140095,\n",
       "                              0.24246012713458087,\n",
       "                              0.25308072889173355,\n",
       "                              0.23945783666662268,\n",
       "                              0.3105366577973237,\n",
       "                              0.3126916421426309]),\n",
       "                            ('accuracy',\n",
       "                             [0.6270270270270271,\n",
       "                              0.8540540540540541,\n",
       "                              0.8918918918918919,\n",
       "                              0.8864864864864865,\n",
       "                              0.9243243243243243,\n",
       "                              0.8648648648648649,\n",
       "                              0.8378378378378378,\n",
       "                              0.8378378378378378])])),\n",
       "              ('combined',\n",
       "               {'loss': [0.7006066399651605,\n",
       "                 0.24917083946434226,\n",
       "                 0.27524916159140095,\n",
       "                 0.24246012713458087,\n",
       "                 0.25308072889173355,\n",
       "                 0.23945783666662268,\n",
       "                 0.3105366577973237,\n",
       "                 0.3126916421426309],\n",
       "                'accuracy': [0.6270270270270271,\n",
       "                 0.8540540540540541,\n",
       "                 0.8918918918918919,\n",
       "                 0.8864864864864865,\n",
       "                 0.9243243243243243,\n",
       "                 0.8648648648648649,\n",
       "                 0.8378378378378378,\n",
       "                 0.8378378378378378]})]),\n",
       " 'test': OrderedDict([('LABEL',\n",
       "               OrderedDict([('loss',\n",
       "                             [0.7303368027145798,\n",
       "                              0.20681812698776658,\n",
       "                              0.21036290864686708,\n",
       "                              0.16335967295878642,\n",
       "                              0.16206577919624948,\n",
       "                              0.14474767220986856,\n",
       "                              0.20945691289128485,\n",
       "                              0.19777869662723024]),\n",
       "                            ('accuracy',\n",
       "                             [0.6108108108108108,\n",
       "                              0.9081081081081082,\n",
       "                              0.9027027027027027,\n",
       "                              0.9135135135135135,\n",
       "                              0.9243243243243243,\n",
       "                              0.9351351351351351,\n",
       "                              0.8918918918918919,\n",
       "                              0.8972972972972973])])),\n",
       "              ('combined',\n",
       "               {'loss': [0.7303368027145798,\n",
       "                 0.20681812698776658,\n",
       "                 0.21036290864686708,\n",
       "                 0.16335967295878642,\n",
       "                 0.16206577919624948,\n",
       "                 0.14474767220986856,\n",
       "                 0.20945691289128485,\n",
       "                 0.19777869662723024],\n",
       "                'accuracy': [0.6108108108108108,\n",
       "                 0.9081081081081082,\n",
       "                 0.9027027027027027,\n",
       "                 0.9135135135135135,\n",
       "                 0.9243243243243243,\n",
       "                 0.9351351351351351,\n",
       "                 0.8918918918918919,\n",
       "                 0.8972972972972973]})])}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ludwig.api import LudwigModel\n",
    "\n",
    "model_definition = {\n",
    "    \"input_features\": [{\"name\": \"CONTENT\", \"type\": \"text\"}], \n",
    "    \"output_features\": [{\"name\": \"LABEL\", \"type\": \"binary\"}],\n",
    "    \"training\": {\"epochs\": 5},\n",
    "}\n",
    "model = LudwigModel(model_definition)\n",
    "\n",
    "train_stats = model.train(\n",
    "    data_train_df=df_train, \n",
    "    data_validation_df=df_valid, \n",
    "    data_test_df=df_test, \n",
    "    logging_level=20,\n",
    ")\n",
    "train_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "snorkel_tutorials_env",
   "language": "python",
   "name": "snorkel_tutorials_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
