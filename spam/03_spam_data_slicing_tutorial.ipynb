{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ✂️ _Spam_ — Data Slicing Tutorial\n",
    "\n",
    "In real-world applications, _some model outcomes are often more important than others_, e.g. vulnerable cyclist detections in an autonomous driving task, or, in our running **spam** application, potentially malicious link redirects to external websites.\n",
    "\n",
    "Traditional machine learning systems optimize for overall quality, which may be too coarse-grained: models that achieve high overall performance might produce unacceptable failure rates on critical slices of the data — data subsets that might correspond to vulnerable cyclist detection in an autonomous driving task, or in our running spam detection application, external links to potentially malicious websites.\n",
    "\n",
    "In this tutorial, we introduce _Slicing Functions (SFs)_ as a programming interface to:\n",
    "1. **Monitor** application-critical data slices\n",
    "2. **Address model performance** on slices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we'll set up our notebook for reproducibility and proper logging."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import os\n",
    "import pandas as pd\n",
    "from snorkel.analysis.utils import set_seed\n",
    "\n",
    "# For reproducibility\n",
    "os.environ[\"PYTHONHASHSEED\"] = \"0\"\n",
    "set_seed(111)\n",
    "\n",
    "# Make sure we're running from the spam/ directory\n",
    "if os.path.basename(os.getcwd()) == \"snorkel-tutorials\":\n",
    "    os.chdir(\"spam\")\n",
    "\n",
    "# To visualize logs\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.WARNING)\n",
    "\n",
    "# Show full columns for viewing data\n",
    "pd.set_option(\"display.max_colwidth\", -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Note:_ this tutorial differs from labeling tutorial because we use ground truth labels in the train split for demo purposes.\n",
    "In practice, data slicing is agnostic to the _training labels_ used as inputs — you can use Snorkel-generated labels as inputs to this pipeline!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "from utils import load_spam_dataset\n",
    "\n",
    "df_train, df_valid, df_test = load_spam_dataset(\n",
    "    load_train_labels=True, include_dev=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Train a discriminative model\n",
    "\n",
    "To start, we'll initialize a discriminative model using our [`SnorkelClassifier`](https://snorkel.readthedocs.io/en/redux/source/snorkel.classification.html).\n",
    "We'll assume that you are familiar with Snorkel's the data/model/training abstraction — if not, we'd recommend you check out our [MTL Tutorial](https://github.com/snorkel-team/snorkel-tutorials/blob/master/mtl/multitask_tutorial.ipynb)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Featurize Data\n",
    "\n",
    "As a first step, we'll featurize the data—as you saw in the introductory Spam tutorial, we'll extract simple bag of words features and store them as numpy arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from snorkel.classification.data import DictDataset, DictDataLoader\n",
    "\n",
    "vectorizer = CountVectorizer(ngram_range=(1, 1))\n",
    "\n",
    "\n",
    "def df_to_torch_example(vectorizer, df, fit_train=False):\n",
    "    words = [row.text for i, row in df.iterrows()]\n",
    "\n",
    "    if fit_train:\n",
    "        feats = vectorizer.fit_transform(words)\n",
    "    else:\n",
    "        feats = vectorizer.transform(words)\n",
    "    X = feats.todense()\n",
    "    Y = df[\"label\"].values\n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, Y_train = df_to_torch_example(vectorizer, df_train, fit_train=True)\n",
    "X_valid, Y_valid = df_to_torch_example(vectorizer, df_valid, fit_train=False)\n",
    "X_test, Y_test = df_to_torch_example(vectorizer, df_test, fit_train=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create DataLoaders\n",
    "\n",
    "Next, we'll use the extracted Tensors to initialize a `DictDataLoader` — as a quick recap, this is a Snorkel-specific class that inherits from the common PyTorch class and supports multiple data fields in the `X_dict` and labels in the `Y_dict`.\n",
    "\n",
    "In this task, we'd like to store the `bow_features` in our `X_dict`, and we have one set of labels (for now) correpsonding to the `spam_task`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "\n",
    "\n",
    "def create_dict_dataloader(X, Y, split, **kwargs):\n",
    "    ds = DictDataset(\n",
    "        name=\"spam_dataset\",\n",
    "        split=split,\n",
    "        X_dict={\"bow_features\": torch.FloatTensor(X)},\n",
    "        Y_dict={\"spam_task\": torch.LongTensor(Y)},\n",
    "    )\n",
    "    return DictDataLoader(ds, **kwargs)\n",
    "\n",
    "\n",
    "dl_train = create_dict_dataloader(\n",
    "    X_train, Y_train, split=\"train\", batch_size=BATCH_SIZE, shuffle=True\n",
    ")\n",
    "dl_valid = create_dict_dataloader(\n",
    "    X_valid, Y_valid, split=\"valid\", batch_size=BATCH_SIZE, shuffle=False\n",
    ")\n",
    "dl_test = create_dict_dataloader(\n",
    "    X_test, Y_test, split=\"test\", batch_size=BATCH_SIZE, shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can inspect our datasets to confirm that they have the appropriate fields."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DictDataset(name=spam_dataset, X_keys=['bow_features'], Y_keys=['spam_task'])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dl_valid.dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define `SnorkelClassifier`\n",
    "\n",
    "We'll define a simple Multi-Layer Perceptron (MLP) architecture to learn from the `bow_features`.\n",
    "\n",
    "_Note: the following might feel like extra steps to define what is a very simple architecture, but this will lend us additional flexibility later in the pipeline!_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To start, we define a `module_pool` with all the [PyTorch](https://pytorch.org) modules that we'll want to include in our network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "bow_dim = X_train.shape[1]\n",
    "module_pool = nn.ModuleDict(\n",
    "    {\n",
    "        \"mlp\": nn.Sequential(nn.Linear(bow_dim, bow_dim), nn.ReLU()),\n",
    "        \"prediction_head\": nn.Linear(bow_dim, 2),\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we specify the desired `task_flow` through each module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from snorkel.classification.task import Operation\n",
    "\n",
    "task_flow = [\n",
    "    Operation(name=\"input_op\", module_name=\"mlp\", inputs=[(\"_input_\", \"bow_features\")]),\n",
    "    Operation(name=\"head_op\", module_name=\"prediction_head\", inputs=[(\"input_op\", 0)]),\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With these pieces, we're ready to define a [`Task`](https://snorkel.readthedocs.io/en/redux/source/snorkel.classification.html#module-snorkel.classification.task) in Snorkel for spam classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "from snorkel.classification.task import Task, ce_loss, softmax\n",
    "from snorkel.classification.scorer import Scorer\n",
    "\n",
    "spam_task = Task(\n",
    "    name=\"spam_task\",\n",
    "    module_pool=module_pool,\n",
    "    task_flow=task_flow,\n",
    "    loss_func=partial(ce_loss, \"head_op\"),\n",
    "    output_func=partial(softmax, \"head_op\"),\n",
    "    scorer=Scorer(metrics=[\"accuracy\", \"f1\"]),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll initialize a [`SnorkelClassifier`](https://snorkel.readthedocs.io/en/redux/source/snorkel.classification.html) with the `spam_task` we've created, initialize a corresponding [`Trainer`](https://snorkel.readthedocs.io/en/redux/source/snorkel.classification.training.html#module-snorkel.classification.training.trainer), and `fit` to our dataloaders!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from snorkel.classification.snorkel_classifier import SnorkelClassifier\n",
    "from snorkel.classification.training import Trainer\n",
    "\n",
    "model = SnorkelClassifier([spam_task])\n",
    "trainer = Trainer(n_epochs=5, lr=1e-4, progress_bar=True)\n",
    "# trainer.fit(model, [dl_train, dl_valid])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How well does our model do?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>dataset</th>\n",
       "      <th>split</th>\n",
       "      <th>metric</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>spam_task</td>\n",
       "      <td>spam_dataset</td>\n",
       "      <td>train</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.471627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>spam_task</td>\n",
       "      <td>spam_dataset</td>\n",
       "      <td>train</td>\n",
       "      <td>f1</td>\n",
       "      <td>0.093074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam_task</td>\n",
       "      <td>spam_dataset</td>\n",
       "      <td>valid</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.550000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>spam_task</td>\n",
       "      <td>spam_dataset</td>\n",
       "      <td>valid</td>\n",
       "      <td>f1</td>\n",
       "      <td>0.129032</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       label       dataset  split    metric     score\n",
       "0  spam_task  spam_dataset  train  accuracy  0.471627\n",
       "1  spam_task  spam_dataset  train  f1        0.093074\n",
       "2  spam_task  spam_dataset  valid  accuracy  0.550000\n",
       "3  spam_task  spam_dataset  valid  f1        0.129032"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score([dl_train, dl_valid], as_dataframe=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Perform error analysis\n",
    "\n",
    "In overall metrics (`f1`, `accuracy`) our model appears to perform well!\n",
    "\n",
    "However, we emphasize here that more often than not, we're interested in performance for application-critical subsets, or _slices_.\n",
    "\n",
    "Let's perform an [`error_analysis`](https://snorkel.readthedocs.io/en/redux/source/snorkel.analysis.html#module-snorkel.analysis.error_analysis) to see where our model makes mistakes.\n",
    "We'll collect the predictions from the model and visualize examples in specific error buckets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from snorkel.analysis.error_analysis import get_label_buckets\n",
    "from snorkel.analysis.utils import probs_to_preds\n",
    "\n",
    "outputs = model.predict(dl_valid, return_preds=True)\n",
    "error_buckets = get_label_buckets(\n",
    "    outputs[\"golds\"][\"spam_task\"], outputs[\"preds\"][\"spam_task\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For application purposes, we might care especially about false negatives (true label was `1`, but model predicted `0`) — for the spam task, external links might point to malware, and we don't want to expose our users to these risks!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>You guys should check out this EXTRAORDINARY website called ZONEPA.COM . You can make money online and start working from home today as I am! I am making over $3,000+ per month at ZONEPA.COM ! Visit Zonepa.com and check it out! How does the mother approve the axiomatic insurance? The fear appoints the roll. When does the space prepare the historical shame?</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>Check out  these Irish guys cover  of Avicii&amp;#39;s  Wake Me Up!  Just search...  &amp;quot;wake me up Fiddle Me Silly&amp;quot; Worth a listen  for the gorgeous fiddle player!</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>if you want to win money at hopme click here &lt;a href=\"https://www.paidverts.com/ref/sihaam01\"&gt;https://www.paidverts.com/ref/sihaam01&lt;/a&gt; it&amp;#39;s work 100/100﻿</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>Hey Youtubers and All Music lover&amp;#39;s, Guess most of you all skip these comments, but for you who is still reading this, thanks ! I dont have any money for advertisiments, no chance of getting heard, nothing. All that&amp;#39;s left is spam, sorry. Im 17, Rapper/Singer from Estonia. Please listen my new cover on my account. You wont regret it. Give me just a chance, please. Take half a second of your life and thumb this comment up. It will maybe change my life, for real. Thank you Wafence</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242</th>\n",
       "      <td>**CHECK OUT MY NEW MIXTAPE**** **CHECK OUT MY NEW MIXTAPE**** **CHECK OUT MY NEW MIXTAPE*** ***CHECK OUT MY NEW MIXTAPE******CHECK OUT MY NEW MIXTAPE**** **CHECK OUT MY NEW MIXTAPE**** **CHECK OUT MY NEW MIXTAPE*** ***CHECK OUT MY NEW MIXTAPE******CHECK OUT MY NEW MIXTAPE**** **CHECK OUT MY NEW MIXTAPE**** **CHECK OUT MY NEW MIXTAPE*** ***CHECK OUT MY NEW MIXTAPE******CHECK OUT MY NEW MIXTAPE**** **CHECK OUT MY NEW MIXTAPE**** **CHECK OUT MY NEW MIXTAPE*** ***CHECK OUT MY NEW MIXTAPE****</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             text  \\\n",
       "70   You guys should check out this EXTRAORDINARY website called ZONEPA.COM . You can make money online and start working from home today as I am! I am making over $3,000+ per month at ZONEPA.COM ! Visit Zonepa.com and check it out! How does the mother approve the axiomatic insurance? The fear appoints the roll. When does the space prepare the historical shame?                                                                                                                                         \n",
       "156  Check out  these Irish guys cover  of Avicii&#39;s  Wake Me Up!  Just search...  &quot;wake me up Fiddle Me Silly&quot; Worth a listen  for the gorgeous fiddle player!                                                                                                                                                                                                                                                                                                                                        \n",
       "73   if you want to win money at hopme click here <a href=\"https://www.paidverts.com/ref/sihaam01\">https://www.paidverts.com/ref/sihaam01</a> it&#39;s work 100/100﻿                                                                                                                                                                                                                                                                                                                                                \n",
       "130  Hey Youtubers and All Music lover&#39;s, Guess most of you all skip these comments, but for you who is still reading this, thanks ! I dont have any money for advertisiments, no chance of getting heard, nothing. All that&#39;s left is spam, sorry. Im 17, Rapper/Singer from Estonia. Please listen my new cover on my account. You wont regret it. Give me just a chance, please. Take half a second of your life and thumb this comment up. It will maybe change my life, for real. Thank you Wafence    \n",
       "242  **CHECK OUT MY NEW MIXTAPE**** **CHECK OUT MY NEW MIXTAPE**** **CHECK OUT MY NEW MIXTAPE*** ***CHECK OUT MY NEW MIXTAPE******CHECK OUT MY NEW MIXTAPE**** **CHECK OUT MY NEW MIXTAPE**** **CHECK OUT MY NEW MIXTAPE*** ***CHECK OUT MY NEW MIXTAPE******CHECK OUT MY NEW MIXTAPE**** **CHECK OUT MY NEW MIXTAPE**** **CHECK OUT MY NEW MIXTAPE*** ***CHECK OUT MY NEW MIXTAPE******CHECK OUT MY NEW MIXTAPE**** **CHECK OUT MY NEW MIXTAPE**** **CHECK OUT MY NEW MIXTAPE*** ***CHECK OUT MY NEW MIXTAPE****   \n",
       "\n",
       "     label  \n",
       "70   1      \n",
       "156  1      \n",
       "73   1      \n",
       "130  1      \n",
       "242  1      "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_valid[[\"text\", \"label\"]].iloc[error_buckets[(1, 0)]].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We notice that we're mis-classifying particularly some comments with shortened urls (e.g. `bit.ly/...`) — these links could redirect us to potentially dangerous websites, and we don't want our users to click them!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Monitor data slices\n",
    "\n",
    "We leverage *slicing functions* (SFs) — an abstraction that shares syntax with *labeling functions*, which you should already be familiar with! (If not, please see the [intro tutorial](https://github.com/snorkel-team/snorkel-tutorials/blob/master/spam/01_spam_tutorial.ipynb).) A key difference: whereas labeling functions output labels, slicing functions output binary _masks_ indicating whether an example is in the slice or not."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following cells, we define a slicing function that identifies these shortened links the spam dataset.\n",
    "To do so, we write a regex that checks for the commonly-used `.ly` extension.\n",
    "\n",
    "You'll notice that the slicing function is noisily defined — SFs are often heuristics to quickly measure performance over important subsets of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from snorkel.slicing.sf import slicing_function\n",
    "\n",
    "\n",
    "@slicing_function()\n",
    "def short_link(x):\n",
    "    \"\"\"Spam comments post links to other channels.\"\"\"\n",
    "    return bool(re.search(r\"\\w+\\.ly\", x.text))\n",
    "\n",
    "\n",
    "sfs = [short_link]\n",
    "slice_names = [sf.name for sf in sfs]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For our $n$ examples and $k$ slices in each split, we apply the SF to our data to create an $n \\times k$ matrix. (So far, $k=1$)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1586/1586 [00:00<00:00, 40608.04it/s]\n",
      "100%|██████████| 120/120 [00:00<00:00, 30470.79it/s]\n",
      "100%|██████████| 250/250 [00:00<00:00, 37098.04it/s]\n"
     ]
    }
   ],
   "source": [
    "from snorkel.slicing.apply import PandasSFApplier\n",
    "\n",
    "applier = PandasSFApplier(sfs)\n",
    "S_train = applier.apply(df_train)\n",
    "S_valid = applier.apply(df_valid)\n",
    "S_test = applier.apply(df_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize slices with `PandasSlicer`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With a utility function from `snorkel.slicing.monitor`, we can visualize examples belonging to this slice in a `pandas.DataFrame`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 120/120 [00:00<00:00, 31151.60it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>280</th>\n",
       "      <td>Being paid to respond to fast paid surveys from home has enabled me to give up working and make more than 4500 bucks monthly.  To read more go to this web site bit.ly\\1bSefQe</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>Meet The Richest Online Marketer  NOW CLICK : bit.ly/make-money-without-adroid</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301</th>\n",
       "      <td>coby this USL and past :&lt;br /&gt;&lt;a href=\"http://adf.ly\"&gt;http://adf.ly&lt;/a&gt; /1HmVtX&lt;br /&gt;delete space after y﻿</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>350</th>\n",
       "      <td>adf.ly / KlD3Y</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Earn money for being online with 0 efforts!    bit.ly\\14gKvDo</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                               text  \\\n",
       "280  Being paid to respond to fast paid surveys from home has enabled me to give up working and make more than 4500 bucks monthly.  To read more go to this web site bit.ly\\1bSefQe   \n",
       "192  Meet The Richest Online Marketer  NOW CLICK : bit.ly/make-money-without-adroid                                                                                                   \n",
       "301  coby this USL and past :<br /><a href=\"http://adf.ly\">http://adf.ly</a> /1HmVtX<br />delete space after y﻿                                                                       \n",
       "350  adf.ly / KlD3Y                                                                                                                                                                   \n",
       "18   Earn money for being online with 0 efforts!    bit.ly\\14gKvDo                                                                                                                    \n",
       "\n",
       "     label  \n",
       "280  1      \n",
       "192  1      \n",
       "301  1      \n",
       "350  1      \n",
       "18   1      "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from snorkel.slicing.monitor import PandasSlicer\n",
    "\n",
    "pd_slicer = PandasSlicer(df_valid)\n",
    "short_link_df = pd_slicer.slice(short_link)\n",
    "short_link_df[[\"text\", \"label\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we add labels for this particularly slice to an existing dataloader.\n",
    "Specifically, `add_slice_labels` will add two sets of labels for each slice:\n",
    "* `spam_task_slice:{slice_name}_ind`: an indicator label, which corresponds to the outputs of the slicing functions.\n",
    "These indicate whether each example is in the slice (`label=1`)or not (`label=0`).\n",
    "* `spam_task_slice:{slice_name}_pred`: a _masked_ set of the original task labels (in this case, labeled `spam_task`) for each slice. Examples that are masked (with `label=-1`) will not contribute to loss or scoring."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from snorkel.slicing.utils import add_slice_labels\n",
    "\n",
    "slice_names = [sf.name for sf in sfs]\n",
    "add_slice_labels(dl_train, spam_task, S_train, slice_names)\n",
    "add_slice_labels(dl_valid, spam_task, S_valid, slice_names)\n",
    "add_slice_labels(dl_test, spam_task, S_test, slice_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DictDataset(name=spam_dataset, X_keys=['bow_features'], Y_keys=['spam_task', 'spam_task_slice:short_link_ind', 'spam_task_slice:short_link_pred', 'spam_task_slice:base_ind', 'spam_task_slice:base_pred'])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dl_valid.dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With our updated dataloader, we want to evaluate on model on the defined slice. In the `SnorkelClassifier`, we can call `score` with an additional argument, `remap_labels` to specify that the slice's prediction labels, `spam_task_slice:short_link_pred` should be mapped to the `spam_task` for evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Ignoring extra labels in dataloader (valid): {'spam_task_slice:short_link_ind', 'spam_task_slice:base_ind', 'spam_task_slice:base_pred'}\n",
      "/home/ubuntu/snorkel-tutorials/.env/lib/python3.6/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "WARNING:root:Ignoring extra labels in dataloader (test): {'spam_task_slice:short_link_ind', 'spam_task_slice:base_ind', 'spam_task_slice:base_pred'}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>dataset</th>\n",
       "      <th>split</th>\n",
       "      <th>metric</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>spam_task</td>\n",
       "      <td>spam_dataset</td>\n",
       "      <td>valid</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.550000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>spam_task</td>\n",
       "      <td>spam_dataset</td>\n",
       "      <td>valid</td>\n",
       "      <td>f1</td>\n",
       "      <td>0.129032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam_task_slice:short_link_pred</td>\n",
       "      <td>spam_dataset</td>\n",
       "      <td>valid</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>spam_task_slice:short_link_pred</td>\n",
       "      <td>spam_dataset</td>\n",
       "      <td>valid</td>\n",
       "      <td>f1</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>spam_task</td>\n",
       "      <td>spam_dataset</td>\n",
       "      <td>test</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.524000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>spam_task</td>\n",
       "      <td>spam_dataset</td>\n",
       "      <td>test</td>\n",
       "      <td>f1</td>\n",
       "      <td>0.016529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>spam_task_slice:short_link_pred</td>\n",
       "      <td>spam_dataset</td>\n",
       "      <td>test</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>spam_task_slice:short_link_pred</td>\n",
       "      <td>spam_dataset</td>\n",
       "      <td>test</td>\n",
       "      <td>f1</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             label       dataset  split    metric     score\n",
       "0  spam_task                        spam_dataset  valid  accuracy  0.550000\n",
       "1  spam_task                        spam_dataset  valid  f1        0.129032\n",
       "2  spam_task_slice:short_link_pred  spam_dataset  valid  accuracy  0.000000\n",
       "3  spam_task_slice:short_link_pred  spam_dataset  valid  f1        0.000000\n",
       "4  spam_task                        spam_dataset  test   accuracy  0.524000\n",
       "5  spam_task                        spam_dataset  test   f1        0.016529\n",
       "6  spam_task_slice:short_link_pred  spam_dataset  test   accuracy  0.000000\n",
       "7  spam_task_slice:short_link_pred  spam_dataset  test   f1        0.000000"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(\n",
    "    dataloaders=[dl_valid, dl_test],\n",
    "    remap_labels={\"spam_task_slice:short_link_pred\": \"spam_task\"},\n",
    "    as_dataframe=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Monitor slices with `SliceScorer`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you're using a model other than `SnorkelClassifier`, you can still evaluate on slices using the more general `SliceScorer` class.\n",
    "\n",
    "We define a `LogisticRegression` model from sklearn and show how we might visualize these slice-specific scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.928"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "sklearn_model = LogisticRegression(C=0.001, solver=\"liblinear\")\n",
    "sklearn_model.fit(X=X_train, y=Y_train)\n",
    "sklearn_model.score(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>overall</th>\n",
       "      <td>0.928000</td>\n",
       "      <td>0.925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>short_link</th>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            accuracy     f1\n",
       "overall     0.928000  0.925\n",
       "short_link  0.333333  0.500"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from snorkel.analysis.utils import preds_to_probs\n",
    "from snorkel.slicing.monitor import SliceScorer\n",
    "\n",
    "\n",
    "preds_test = sklearn_model.predict(X_test)\n",
    "\n",
    "scorer = Scorer(metrics=[\"accuracy\", \"f1\"])\n",
    "scorer = SliceScorer(scorer, slice_names)\n",
    "scorer.score(\n",
    "    S_matrix=S_test,\n",
    "    golds=Y_test,\n",
    "    preds=preds_test,\n",
    "    probs=preds_to_probs(preds_test, 2),\n",
    "    as_dataframe=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Address slice performance\n",
    "\n",
    "In classification tasks, we might attempt to increase slice performance with techniques like _oversampling_ (i.e. with PyTorch's [`WeightedRandomSampler`](https://pytorch.org/docs/stable/data.html#torch.utils.data.WeightedRandomSampler)).\n",
    "This would shift the training distribution to over-represent certain minority populations.\n",
    "Intuitively, we'd like to show more `short_link` examples to the model so that the representation is better suited to handle these examples!\n",
    "\n",
    "A technique like upsampling might work with a small number of slices, but with a large number of slices, it could quickly become intractable to tune upsampling weights per slice.\n",
    "In the following section, we show how we might handle numerous slices with a modeling approach using `SnorkelClassifier`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write additional slicing functions (SFs)\n",
    "\n",
    "We'll take inspiration from the labeling tutorial to write a few additional `SlicingFunctions`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from snorkel.slicing.sf import SlicingFunction, slicing_function, nlp_slicing_function\n",
    "from snorkel.preprocess import preprocessor\n",
    "\n",
    "\n",
    "def keyword_lookup(x, keywords):\n",
    "    return any(word in x.text.lower() for word in keywords)\n",
    "\n",
    "\n",
    "def make_keyword_sf(keywords):\n",
    "    return SlicingFunction(\n",
    "        name=f\"keyword_{keywords[0]}\",\n",
    "        f=keyword_lookup,\n",
    "        resources=dict(keywords=keywords),\n",
    "    )\n",
    "\n",
    "\n",
    "\"\"\"Spam comments ask users to subscribe to their channels.\"\"\"\n",
    "keyword_subscribe = make_keyword_sf(keywords=[\"subscribe\"])\n",
    "\n",
    "\"\"\"Spam comments make requests rather than commenting.\"\"\"\n",
    "keyword_please = make_keyword_sf(keywords=[\"please\", \"plz\"])\n",
    "\n",
    "\n",
    "@nlp_slicing_function()\n",
    "def has_person_nlp(x):\n",
    "    \"\"\"Ham comments mention specific people and are short.\"\"\"\n",
    "    return len(x.doc) < 20 and any([ent.label_ == \"PERSON\" for ent in x.doc.ents])\n",
    "\n",
    "\n",
    "@slicing_function()\n",
    "def regex_check_out(x):\n",
    "    return bool(re.search(r\"check.*out\", x.text, flags=re.I))\n",
    "\n",
    "\n",
    "@slicing_function()\n",
    "def short_comment(x):\n",
    "    \"\"\"Ham comments are often short, such as 'cool video!'\"\"\"\n",
    "    return len(x.text.split()) < 5\n",
    "\n",
    "\n",
    "@slicing_function(pre=[spacy])\n",
    "def has_person(x):\n",
    "    \"\"\"Ham comments mention specific people and are short.\"\"\"\n",
    "    return len(x.doc) < 20 and any([ent.label_ == \"PERSON\" for ent in x.doc.ents])\n",
    "\n",
    "\n",
    "from textblob import TextBlob\n",
    "\n",
    "\n",
    "@preprocessor(memoize=True)\n",
    "def textblob_sentiment(x):\n",
    "    scores = TextBlob(x.text)\n",
    "    x.polarity = scores.sentiment.polarity\n",
    "    x.subjectivity = scores.sentiment.subjectivity\n",
    "    return x\n",
    "\n",
    "\n",
    "@slicing_function(pre=[textblob_sentiment])\n",
    "def textblob_polarity(x):\n",
    "    return x.polarity > 0.9\n",
    "\n",
    "\n",
    "extra_sfs = [\n",
    "    keyword_subscribe,\n",
    "    keyword_please,\n",
    "    regex_check_out,\n",
    "    short_comment,\n",
    "    has_person_nlp,\n",
    "    textblob_polarity,\n",
    "]\n",
    "\n",
    "sfs = [short_link] + extra_sfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1586/1586 [00:14<00:00, 107.07it/s]\n",
      "100%|██████████| 120/120 [00:01<00:00, 104.08it/s]\n",
      "100%|██████████| 250/250 [00:02<00:00, 100.32it/s]\n"
     ]
    }
   ],
   "source": [
    "applier = PandasSFApplier(sfs)\n",
    "S_train = applier.apply(df_train)\n",
    "S_valid = applier.apply(df_valid)\n",
    "S_test = applier.apply(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "slice_names = [sf.name for sf in sfs]\n",
    "add_slice_labels(dl_train, spam_task, S_train, slice_names)\n",
    "add_slice_labels(dl_valid, spam_task, S_valid, slice_names)\n",
    "add_slice_labels(dl_test, spam_task, S_test, slice_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like we saw above, we'd like to visualize examples in the slice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 120/120 [00:00<00:00, 22599.64it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Love this song !!!!!!</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>309</th>\n",
       "      <td>One of the best song of all the time﻿</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>She is perfect</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>310</th>\n",
       "      <td>Best world cup offical song﻿</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>352</th>\n",
       "      <td>I remember this :D</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      text  label\n",
       "16   Love this song !!!!!!                  0    \n",
       "309  One of the best song of all the time﻿  0    \n",
       "164  She is perfect                         0    \n",
       "310  Best world cup offical song﻿           0    \n",
       "352  I remember this :D                     0    "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd_slicer = PandasSlicer(df_valid)\n",
    "polarity_df = pd_slicer.slice(textblob_polarity)\n",
    "polarity_df[[\"text\", \"label\"]].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Representation learning with slices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To cope with scale, we will attempt to learn and combine many slice-specific representations with an attention mechanism (for more, please see our technical report — coming soon!).\n",
    "Using the helper, `convert_to_slice_tasks`, we have now have a list of slice tasks that appropriate constructs the `task_flow` to do just that!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Task(name=spam_task_slice:short_link_ind),\n",
       " Task(name=spam_task_slice:keyword_subscribe_ind),\n",
       " Task(name=spam_task_slice:keyword_please_ind),\n",
       " Task(name=spam_task_slice:regex_check_out_ind),\n",
       " Task(name=spam_task_slice:short_comment_ind),\n",
       " Task(name=spam_task_slice:has_person_nlp_ind),\n",
       " Task(name=spam_task_slice:textblob_polarity_ind),\n",
       " Task(name=spam_task_slice:base_ind),\n",
       " Task(name=spam_task_slice:short_link_pred),\n",
       " Task(name=spam_task_slice:keyword_subscribe_pred),\n",
       " Task(name=spam_task_slice:keyword_please_pred),\n",
       " Task(name=spam_task_slice:regex_check_out_pred),\n",
       " Task(name=spam_task_slice:short_comment_pred),\n",
       " Task(name=spam_task_slice:has_person_nlp_pred),\n",
       " Task(name=spam_task_slice:textblob_polarity_pred),\n",
       " Task(name=spam_task_slice:base_pred),\n",
       " Task(name=spam_task)]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from snorkel.slicing.utils import convert_to_slice_tasks\n",
    "\n",
    "slice_tasks = convert_to_slice_tasks(spam_task, slice_names)\n",
    "slice_tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "slice_model = SnorkelClassifier(slice_tasks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We train this model, and note that we can monitor slice-specific performance during training.\n",
    "This is a powerful way to track especially critical subsets of the data.\n",
    "\n",
    "_Note: This model includes more parameters (corresponding to additional slices) — we only train for 1 epoch here for demonstration purposes._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0::  98%|█████████▊| 49/50 [01:13<00:01,  1.49s/it, model/all/train/loss=0.532, model/all/train/lr=0.0001]/home/ubuntu/snorkel-tutorials/.env/lib/python3.6/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "Epoch 0:: 100%|██████████| 50/50 [01:15<00:00,  1.60s/it, model/all/train/loss=0.531, model/all/train/lr=0.0001, spam_task/spam_dataset/valid/accuracy=0.883, spam_task/spam_dataset/valid/f1=0.86, spam_task_slice:short_link_ind/spam_dataset/valid/f1=0, spam_task_slice:short_link_pred/spam_dataset/valid/accuracy=0, spam_task_slice:short_link_pred/spam_dataset/valid/f1=0, spam_task_slice:base_ind/spam_dataset/valid/f1=1, spam_task_slice:base_pred/spam_dataset/valid/accuracy=0.883, spam_task_slice:base_pred/spam_dataset/valid/f1=0.857, spam_task_slice:keyword_subscribe_ind/spam_dataset/valid/f1=0, spam_task_slice:keyword_subscribe_pred/spam_dataset/valid/accuracy=1, spam_task_slice:keyword_subscribe_pred/spam_dataset/valid/f1=1, spam_task_slice:keyword_please_ind/spam_dataset/valid/f1=0, spam_task_slice:keyword_please_pred/spam_dataset/valid/accuracy=1, spam_task_slice:keyword_please_pred/spam_dataset/valid/f1=1, spam_task_slice:regex_check_out_ind/spam_dataset/valid/f1=0, spam_task_slice:regex_check_out_pred/spam_dataset/valid/accuracy=1, spam_task_slice:regex_check_out_pred/spam_dataset/valid/f1=1, spam_task_slice:short_comment_ind/spam_dataset/valid/f1=0, spam_task_slice:short_comment_pred/spam_dataset/valid/accuracy=0.947, spam_task_slice:short_comment_pred/spam_dataset/valid/f1=0.5, spam_task_slice:has_person_nlp_ind/spam_dataset/valid/f1=0, spam_task_slice:has_person_nlp_pred/spam_dataset/valid/accuracy=1, spam_task_slice:has_person_nlp_pred/spam_dataset/valid/f1=1, spam_task_slice:textblob_polarity_ind/spam_dataset/valid/f1=0, spam_task_slice:textblob_polarity_pred/spam_dataset/valid/accuracy=0.917, spam_task_slice:textblob_polarity_pred/spam_dataset/valid/f1=0]\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(n_epochs=1, lr=1e-4, progress_bar=True)\n",
    "trainer.fit(slice_model, [dl_train, dl_valid])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At inference time, the primary task head (`spam_task`) will be making all final predictions.\n",
    "We'd like to evaluate all the slice heads on the original task head.\n",
    "To do this, we use our `remap_labels` API, as we did earlier.\n",
    "Note that this time, we map each `ind` head to `None` — it doesn't make sense to evaluate these labels on the base task head."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_dict = dl_valid.dataset.Y_dict\n",
    "eval_mapping = {label: \"spam_task\" for label in Y_dict.keys() if \"pred\" in label}\n",
    "eval_mapping.update({label: None for label in Y_dict.keys() if \"ind\" in label})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Note: in this toy dataset, we might not see significant gains because slices are defined for demo purposes. \n",
    "The dataset's slices contain only a few examples — they are not reliable evaluation metrics. For a demonstration of data slicing deployed in state-of-the-art models, please see our [SuperGLUE](https://github.com/HazyResearch/snorkel-superglue) tutorials._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Ignoring extra labels in dataloader (valid): {'spam_task_slice:has_person_nlp_ind', 'spam_task_slice:base_ind', 'spam_task_slice:keyword_please_ind', 'spam_task_slice:keyword_subscribe_ind', 'spam_task_slice:short_comment_ind', 'spam_task_slice:textblob_polarity_ind', 'spam_task_slice:short_link_ind', 'spam_task_slice:regex_check_out_ind'}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>dataset</th>\n",
       "      <th>split</th>\n",
       "      <th>metric</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>spam_task</td>\n",
       "      <td>spam_dataset</td>\n",
       "      <td>valid</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.883333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>spam_task</td>\n",
       "      <td>spam_dataset</td>\n",
       "      <td>valid</td>\n",
       "      <td>f1</td>\n",
       "      <td>0.860000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam_task_slice:short_link_pred</td>\n",
       "      <td>spam_dataset</td>\n",
       "      <td>valid</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>spam_task_slice:short_link_pred</td>\n",
       "      <td>spam_dataset</td>\n",
       "      <td>valid</td>\n",
       "      <td>f1</td>\n",
       "      <td>0.571429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>spam_task_slice:base_pred</td>\n",
       "      <td>spam_dataset</td>\n",
       "      <td>valid</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.883333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>spam_task_slice:base_pred</td>\n",
       "      <td>spam_dataset</td>\n",
       "      <td>valid</td>\n",
       "      <td>f1</td>\n",
       "      <td>0.860000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>spam_task_slice:keyword_subscribe_pred</td>\n",
       "      <td>spam_dataset</td>\n",
       "      <td>valid</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.900000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>spam_task_slice:keyword_subscribe_pred</td>\n",
       "      <td>spam_dataset</td>\n",
       "      <td>valid</td>\n",
       "      <td>f1</td>\n",
       "      <td>0.947368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>spam_task_slice:keyword_please_pred</td>\n",
       "      <td>spam_dataset</td>\n",
       "      <td>valid</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.888889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>spam_task_slice:keyword_please_pred</td>\n",
       "      <td>spam_dataset</td>\n",
       "      <td>valid</td>\n",
       "      <td>f1</td>\n",
       "      <td>0.941176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>spam_task_slice:regex_check_out_pred</td>\n",
       "      <td>spam_dataset</td>\n",
       "      <td>valid</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>spam_task_slice:regex_check_out_pred</td>\n",
       "      <td>spam_dataset</td>\n",
       "      <td>valid</td>\n",
       "      <td>f1</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>spam_task_slice:short_comment_pred</td>\n",
       "      <td>spam_dataset</td>\n",
       "      <td>valid</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.947368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>spam_task_slice:short_comment_pred</td>\n",
       "      <td>spam_dataset</td>\n",
       "      <td>valid</td>\n",
       "      <td>f1</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>spam_task_slice:has_person_nlp_pred</td>\n",
       "      <td>spam_dataset</td>\n",
       "      <td>valid</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>spam_task_slice:has_person_nlp_pred</td>\n",
       "      <td>spam_dataset</td>\n",
       "      <td>valid</td>\n",
       "      <td>f1</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>spam_task_slice:textblob_polarity_pred</td>\n",
       "      <td>spam_dataset</td>\n",
       "      <td>valid</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>spam_task_slice:textblob_polarity_pred</td>\n",
       "      <td>spam_dataset</td>\n",
       "      <td>valid</td>\n",
       "      <td>f1</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     label       dataset  split    metric  \\\n",
       "0   spam_task                               spam_dataset  valid  accuracy   \n",
       "1   spam_task                               spam_dataset  valid  f1         \n",
       "2   spam_task_slice:short_link_pred         spam_dataset  valid  accuracy   \n",
       "3   spam_task_slice:short_link_pred         spam_dataset  valid  f1         \n",
       "4   spam_task_slice:base_pred               spam_dataset  valid  accuracy   \n",
       "5   spam_task_slice:base_pred               spam_dataset  valid  f1         \n",
       "6   spam_task_slice:keyword_subscribe_pred  spam_dataset  valid  accuracy   \n",
       "7   spam_task_slice:keyword_subscribe_pred  spam_dataset  valid  f1         \n",
       "8   spam_task_slice:keyword_please_pred     spam_dataset  valid  accuracy   \n",
       "9   spam_task_slice:keyword_please_pred     spam_dataset  valid  f1         \n",
       "10  spam_task_slice:regex_check_out_pred    spam_dataset  valid  accuracy   \n",
       "11  spam_task_slice:regex_check_out_pred    spam_dataset  valid  f1         \n",
       "12  spam_task_slice:short_comment_pred      spam_dataset  valid  accuracy   \n",
       "13  spam_task_slice:short_comment_pred      spam_dataset  valid  f1         \n",
       "14  spam_task_slice:has_person_nlp_pred     spam_dataset  valid  accuracy   \n",
       "15  spam_task_slice:has_person_nlp_pred     spam_dataset  valid  f1         \n",
       "16  spam_task_slice:textblob_polarity_pred  spam_dataset  valid  accuracy   \n",
       "17  spam_task_slice:textblob_polarity_pred  spam_dataset  valid  f1         \n",
       "\n",
       "       score  \n",
       "0   0.883333  \n",
       "1   0.860000  \n",
       "2   0.400000  \n",
       "3   0.571429  \n",
       "4   0.883333  \n",
       "5   0.860000  \n",
       "6   0.900000  \n",
       "7   0.947368  \n",
       "8   0.888889  \n",
       "9   0.941176  \n",
       "10  1.000000  \n",
       "11  1.000000  \n",
       "12  0.947368  \n",
       "13  0.500000  \n",
       "14  1.000000  \n",
       "15  1.000000  \n",
       "16  1.000000  \n",
       "17  1.000000  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "slice_model.score([dl_valid], remap_labels=eval_mapping, as_dataframe=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You've just defined slicing functions to monitor specific slices + improved slice-specific performance!\n",
    "For more on the technical details of our modeling approach—our technical report is coming soon!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "title,-all",
   "encoding": "# -*- coding: utf-8 -*-",
   "formats": "ipynb,py:percent",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
