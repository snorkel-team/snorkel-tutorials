{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ✂️ Snorkel Intro Tutorial: _Data Slicing_\n",
    "\n",
    "In real-world applications, some model outcomes are often more important than others — e.g. vulnerable cyclist detections in an autonomous driving task, or, in our running **spam** application, potentially malicious link redirects to external websites.\n",
    "\n",
    "Traditional machine learning systems optimize for overall quality, which may be too coarse-grained.\n",
    "Models that achieve high overall performance might produce unacceptable failure rates on critical slices of the data — data subsets that might correspond to vulnerable cyclist detection in an autonomous driving task, or in our running spam detection application, external links to potentially malicious websites.\n",
    "\n",
    "In this tutorial, we:\n",
    "1. **Introduce _Slicing Functions (SFs)_** as a programming interface\n",
    "1. **Monitor** application-critical data subsets\n",
    "2. **Improve model performance** on slices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we'll set up our notebook for reproducibility and proper logging."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import os\n",
    "import pandas as pd\n",
    "from snorkel.utils import set_seed\n",
    "\n",
    "# For reproducibility\n",
    "os.environ[\"PYTHONHASHSEED\"] = \"0\"\n",
    "set_seed(111)\n",
    "\n",
    "# Make sure we're running from the spam/ directory\n",
    "if os.path.basename(os.getcwd()) == \"snorkel-tutorials\":\n",
    "    os.chdir(\"spam\")\n",
    "\n",
    "# To visualize logs\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.WARNING)\n",
    "\n",
    "# Show full columns for viewing data\n",
    "pd.set_option(\"display.max_colwidth\", -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Note:_ this tutorial differs from the labeling tutorial in that we use ground truth labels in the train split for demo purposes.\n",
    "SFs are intended to be used *after the training set has already been labeled* by LFs (or by hand) in the training data pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "from utils import load_spam_dataset\n",
    "\n",
    "df_train, df_valid, df_test = load_spam_dataset(load_train_labels=True, split_dev=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Write slicing functions\n",
    "\n",
    "We leverage *slicing functions* (SFs), which output binary _masks_ indicating whether an example is in the slice or not.\n",
    "Each slice represents some noisily-defined subset of the data (corresponding to an SF) that we'd like to programmatically monitor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following cells, we use the [`@slicing_function()`](https://snorkel.readthedocs.io/en/master/packages/_autosummary/slicing/snorkel.slicing.slicing_function.html#snorkel.slicing.slicing_function) decorator to initialize an SF that identifies shortened links the spam dataset.\n",
    "These links could redirect us to potentially dangerous websites, and we don't want our users to click them!\n",
    "To select the subset of shortened links in our dataset, we write a regex that checks for the commonly-used `.ly` extension.\n",
    "\n",
    "You'll notice that the `short_link` SF is a heuristic, like the other programmatic ops we've defined, and may not fully cover the slice of interest.\n",
    "That's okay — in last section, we'll show how a model can handle this in Snorkel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from snorkel.slicing import slicing_function\n",
    "\n",
    "\n",
    "@slicing_function()\n",
    "def short_link(x):\n",
    "    \"\"\"Returns whether text matches common pattern for shortened \".ly\" links.\"\"\"\n",
    "    return bool(re.search(r\"\\w+\\.ly\", x.text))\n",
    "\n",
    "\n",
    "sfs = [short_link]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize slices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With a utility function, [`slice_dataframe`](https://snorkel.readthedocs.io/en/master/packages/_autosummary/slicing/snorkel.slicing.slice_dataframe.html#snorkel.slicing.slice_dataframe), we can visualize examples belonging to this slice in a `pandas.DataFrame`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from snorkel.slicing import slice_dataframe\n",
    "\n",
    "short_link_df = slice_dataframe(df_valid, short_link)\n",
    "short_link_df[[\"text\", \"label\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Monitor slice performance with [`SliceScorer`](https://snorkel.readthedocs.io/en/master/packages/_autosummary/slicing/snorkel.slicing.SliceScorer.html#snorkel.slicing.SliceScorer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we'll demonstrate how we might monitor slice performance on the `short_link` slice — this approach is compatible with _any modeling framework_."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train a simple classifier\n",
    "First, we featurize the data — as you saw in the introductory Spam tutorial, we can extract simple bag-of-words features and store them as numpy arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from utils import df_to_features\n",
    "\n",
    "vectorizer = CountVectorizer(ngram_range=(1, 1))\n",
    "X_train, Y_train = df_to_features(vectorizer, df_train, \"train\")\n",
    "X_valid, Y_valid = df_to_features(vectorizer, df_valid, \"valid\")\n",
    "X_test, Y_test = df_to_features(vectorizer, df_test, \"test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define a `LogisticRegression` model from `sklearn` and show how we might visualize these slice-specific scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "sklearn_model = LogisticRegression(C=0.001, solver=\"liblinear\")\n",
    "sklearn_model.fit(X=X_train, y=Y_train)\n",
    "sklearn_model.score(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from snorkel.utils import preds_to_probs\n",
    "\n",
    "preds_test = sklearn_model.predict(X_test)\n",
    "probs_test = preds_to_probs(preds_test, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Leverage `S` matrix in [`SliceScorer`](https://snorkel.readthedocs.io/en/redux/packages/_autosummary/slicing/snorkel.slicing.SliceScorer.html#snorkel.slicing.SliceScorer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We apply our list of `sfs` to the data using an SF applier.\n",
    "For our data format, we leverage the [`PandasSFApplier`](https://snorkel.readthedocs.io/en/master/packages/_autosummary/slicing/snorkel.slicing.PandasSFApplier.html#snorkel.slicing.PandasSFApplier).\n",
    "The output of the `applier` is a $S \\in \\mathbb{R}^{n \\times k}$ matrix, which indicates whether each of $n$ examples is in each of $k$ slices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from snorkel.slicing import PandasSFApplier\n",
    "\n",
    "applier = PandasSFApplier(sfs)\n",
    "S_test = applier.apply(df_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we initialize the [`SliceScorer`](https://snorkel.readthedocs.io/en/redux/packages/_autosummary/slicing/snorkel.slicing.SliceScorer.html#snorkel.slicing.SliceScorer) using 1) an existing [`Scorer`](https://snorkel.readthedocs.io/en/redux/packages/_autosummary/slicing/snorkel.slicing.SliceScorer.html) and 2) desired `slice_names` to see slice-specific performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from snorkel.analysis import Scorer\n",
    "from snorkel.slicing import SliceScorer\n",
    "\n",
    "scorer = Scorer(metrics=[\"accuracy\", \"f1\"])\n",
    "slice_names = [sf.name for sf in sfs]\n",
    "slice_scorer = SliceScorer(scorer, slice_names)\n",
    "slice_scorer.score(\n",
    "    S=S_test, golds=Y_test, preds=preds_test, probs=probs_test, as_dataframe=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Despite high overall performance, the `short_link` slice performs poorly here!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write additional slicing functions (SFs)\n",
    "\n",
    "Slices are dynamic — as monitoring needs grow or change with new data distributions or application needs, an ML pipeline might require dozens, or even hundreds, of slices.\n",
    "\n",
    "We'll take inspiration from the labeling tutorial to write additional slicing functions.\n",
    "We demonstrate how the same powerful preprocessors and utilities available for labeling functions can be leveraged for slicing functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from snorkel.slicing import SlicingFunction, slicing_function\n",
    "from snorkel.preprocess import preprocessor\n",
    "\n",
    "\n",
    "# Keyword-based SFs\n",
    "def keyword_lookup(x, keywords):\n",
    "    return any(word in x.text.lower() for word in keywords)\n",
    "\n",
    "\n",
    "def make_keyword_sf(keywords):\n",
    "    return SlicingFunction(\n",
    "        name=f\"keyword_{keywords[0]}\",\n",
    "        f=keyword_lookup,\n",
    "        resources=dict(keywords=keywords),\n",
    "    )\n",
    "\n",
    "\n",
    "keyword_subscribe = make_keyword_sf(keywords=[\"subscribe\"])\n",
    "keyword_please = make_keyword_sf(keywords=[\"please\", \"plz\"])\n",
    "\n",
    "\n",
    "# Regex-based SF\n",
    "@slicing_function()\n",
    "def regex_check_out(x):\n",
    "    return bool(re.search(r\"check.*out\", x.text, flags=re.I))\n",
    "\n",
    "\n",
    "# Heuristic-based SF\n",
    "@slicing_function()\n",
    "def short_comment(x):\n",
    "    \"\"\"Ham comments are often short, such as 'cool video!'\"\"\"\n",
    "    return len(x.text.split()) < 5\n",
    "\n",
    "\n",
    "# Leverage preprocessor in SF\n",
    "from textblob import TextBlob\n",
    "\n",
    "\n",
    "@preprocessor(memoize=True)\n",
    "def textblob_sentiment(x):\n",
    "    scores = TextBlob(x.text)\n",
    "    x.polarity = scores.sentiment.polarity\n",
    "    return x\n",
    "\n",
    "\n",
    "@slicing_function(pre=[textblob_sentiment])\n",
    "def textblob_polarity(x):\n",
    "    return x.polarity > 0.9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, we'd like to visualize examples in a particular slice. This time, we'll inspect the `textblob_polarity` slice.\n",
    "\n",
    "Most examples with high-polarity sentiments are strong opinions about the video — hence, they are usually relevant to the video, and the corresponding labels are $0$.\n",
    "We define a slice here for *product and marketing reasons*, it's important to make sure that we don't misclassify very positive comments from good users."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "polarity_df = slice_dataframe(df_valid, textblob_polarity)\n",
    "polarity_df[[\"text\", \"label\"]].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can evaluate performance on _all SFs_ using the model-agnostic `SliceScorer`.\n",
    "Like we did above, we first collect all `sfs` and `slice_names`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extra_sfs = [\n",
    "    keyword_subscribe,\n",
    "    keyword_please,\n",
    "    regex_check_out,\n",
    "    short_comment,\n",
    "    textblob_polarity,\n",
    "]\n",
    "\n",
    "sfs = [short_link] + extra_sfs\n",
    "slice_names = [sf.name for sf in sfs]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see how the `sklearn` model we learned before performs on these new slices!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "applier = PandasSFApplier(sfs)\n",
    "S_test = applier.apply(df_test)\n",
    "\n",
    "slice_scorer = SliceScorer(scorer, slice_names)\n",
    "slice_scorer.score(\n",
    "    S=S_test, golds=Y_test, preds=preds_test, probs=probs_test, as_dataframe=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like they do well — we'll want to monitor these to make sure performance changes on one don't hurt another."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Improve slice performance\n",
    "\n",
    "In the following section, we demonstrate a modeling approach that we call _Slice-based Learning,_ which improves performance with slice-specific representation learning.\n",
    "Intuitively, we'd like to model to learn *representations that are better suited to handle examples in this slice*.\n",
    "In our approach, we model each slice as a separate \"expert task\" in the style of [multi-task learning](https://github.com/snorkel-team/snorkel-tutorials/blob/master/multitask/multitask_tutorial.ipynb).\n",
    "\n",
    "In other approaches, one might attempt to increase slice performance with techniques like _oversampling_ (i.e. with PyTorch's [`WeightedRandomSampler`](https://pytorch.org/docs/stable/data.html#torch.utils.data.WeightedRandomSampler)), effectively shifting the training distribution towards certain populations.\n",
    "\n",
    "This might work with small number of slices, but with hundreds or thousands or production slices at scale, it could quickly become intractable to tune upsampling weights per slice."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up modeling pipeline with `BinarySlicingClassifier`\n",
    "\n",
    "Snorkel supports performance monitoring on slices using discriminative models from [`snorkel.slicing`](https://snorkel.readthedocs.io/en/master/packages/slicing.html).\n",
    "To demonstrate this functionality, we'll first set up a the datasets + modeling pipeline in the PyTorch-based [`snorkel.classification`](https://snorkel.readthedocs.io/en/master/packages/classification.html) package."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we initialize a [`DictDataLoader`](https://snorkel.readthedocs.io/en/master/packages/_autosummary/classification/snorkel.classification.DictDataLoader.html) for each split.\n",
    "This class in [`snorkel.classification`](https://snorkel.readthedocs.io/en/master/packages/classification.html) that provides extra flexibility with a dictionaries of data fields (`X_dict`) and labels (`Y_dict`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import create_dict_dataloader\n",
    "\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "\n",
    "train_dl = create_dict_dataloader(\n",
    "    X_train, Y_train, \"train\", batch_size=BATCH_SIZE, shuffle=True\n",
    ")\n",
    "valid_dl = create_dict_dataloader(\n",
    "    X_valid, Y_valid, \"valid\", batch_size=BATCH_SIZE, shuffle=False\n",
    ")\n",
    "test_dl = create_dict_dataloader(\n",
    "    X_test, Y_test, \"test\", batch_size=BATCH_SIZE, shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll now initialize a `BinarySlicingClassifier`:\n",
    "* `base_architecture`: We define a simple Multi-Layer Perceptron (MLP) in Pytorch to serve as the primary representation architecture. We note that the `BinarySlicingClassifier` is **agnostic to the base architecture** — you might leverage a Transformer model for text, or a ResNet for images.\n",
    "* `head_dim`: identifies the final output feature dimension of the `base_architecture`\n",
    "* `input_data_key`: corresponds to the desired input field from the `X_dict`\n",
    "* `task_name`: corresponds to the corresponding input field from the `Y_dict`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from snorkel.slicing import SlicingClassifier\n",
    "from utils import get_pytorch_mlp\n",
    "\n",
    "\n",
    "# Define model architecture\n",
    "bow_dim = X_train.shape[1]\n",
    "mlp = get_pytorch_mlp(hidden_dim=bow_dim, num_layers=2)\n",
    "\n",
    "# Init slice model\n",
    "slice_model = SlicingClassifier(\n",
    "    base_architecture=mlp,\n",
    "    head_dim=bow_dim,\n",
    "    input_data_key=\"bow_features\",\n",
    "    task_name=\"spam_task\",\n",
    "    slice_names=[sf.name for sf in sfs],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Monitor slice performance _during training_\n",
    "\n",
    "Using Snorkel's [`Trainer`](https://snorkel.readthedocs.io/en/redux/packages/_autosummary/classification/snorkel.classification.Trainer.html), we fit to `train_dl`, and validate on `valid_dl`.\n",
    "\n",
    "We note that we can monitor slice-specific performance during training — this is a powerful way to track especially critical subsets of the data.\n",
    "If logging in `Tensorboard` (i.e. [`snorkel.classification.TensorboardWritier`](https://snorkel.readthedocs.io/en/redux/packages/_autosummary/classification/snorkel.classification.TensorBoardWriter.html)), we would visualize individual loss curves and validation metrics to debug convegence for specific slices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from snorkel.classification import Trainer\n",
    "\n",
    "# For demonstration purposes, we set n_epochs=2\n",
    "trainer = Trainer(lr=1e-4, n_epochs=2)\n",
    "trainer.fit(slice_model, [train_dl, valid_dl])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Representation learning with slices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To cope with scale, we will attempt to learn and combine many slice-specific representations with an attention mechanism.\n",
    "(For details about this approach, please see our technical report — coming soon!)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we'll generate the remaining `S` matrixes with the new set of slicing functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "applier = PandasSFApplier(sfs)\n",
    "S_train = applier.apply(df_train)\n",
    "S_valid = applier.apply(df_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now highlight the slice-aware capabilities of `SlicingClassifier`.\n",
    "At a high-level, this model adds additional capacity corresponding to each slice through additional _slice-specific tasks_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slice_model = SlicingClassifier(\n",
    "    base_architecture=mlp,\n",
    "    head_dim=bow_dim,\n",
    "    input_data_key=\"bow_features\",\n",
    "    task_name=\"spam_task\",\n",
    "    slice_names=slice_names,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to train using slice information, we'd like to initialize a **slice-aware dataloader**.\n",
    "To do this, we can use [`slice_model.make_slice_dataloader`]() to add slice labels to an existing dataloader.\n",
    "\n",
    "Under the hood, this method leverages slice metadata to add slice labels to the appropriate fields such that it's compatible with the initialized [`SliceClassifier`](https://snorkel.readthedocs.io/en/master/packages/_autosummary/slicing/snorkel.slicing.BinarySlicingClassifier.html#snorkel.slicing.BinarySlicingClassifier)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl_slice = slice_model.make_slice_dataloader(\n",
    "    train_dl.dataset, S_train, shuffle=True, batch_size=BATCH_SIZE\n",
    ")\n",
    "valid_dl_slice = slice_model.make_slice_dataloader(\n",
    "    valid_dl.dataset, S_valid, shuffle=False, batch_size=BATCH_SIZE\n",
    ")\n",
    "test_dl_slice = slice_model.make_slice_dataloader(\n",
    "    test_dl.dataset, S_test, shuffle=False, batch_size=BATCH_SIZE\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We train a single model initialized with all slice tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from snorkel.classification import Trainer\n",
    "\n",
    "# For demonstration purposes, we set n_epochs=2\n",
    "trainer = Trainer(n_epochs=2, lr=1e-4, progress_bar=True)\n",
    "trainer.fit(slice_model, [train_dl_slice, valid_dl_slice])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At inference time, the primary task head (`spam_task`) will make all final predictions.\n",
    "We'd like to evaluate all the slice heads on the original task head.\n",
    "\n",
    "*NOTE:* we use the [`score_slices`](https://snorkel.readthedocs.io/en/master/packages/_autosummary/slicing/snorkel.slicing.BinarySlicingClassifier.html#snorkel.slicing.BinarySlicingClassifier.score_slices) method in `SlicingClassifier` — it remaps all slice-related labels, denoted `spam_task_slice:{slice_name}_pred`, to be evaluated on the `spam_task`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slice_model.score_slices([valid_dl_slice, test_dl_slice], as_dataframe=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Note: in this toy dataset, we see high variance in slice performance, because our dataset is so small that (i) there are few examples the train split, giving little signal to learn over, and (ii) there are few examples in the test split, making our evaluation metrics very noisy.\n",
    "For a demonstration of data slicing deployed in state-of-the-art models, please see our [SuperGLUE](https://github.com/HazyResearch/snorkel-superglue/tree/master/tutorials) tutorials.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Recap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This tutorial walked through the process authoring slices, monitoring model performance on specific slices, and improving model performance using slice information.\n",
    "This programming abstraction provides a mechanism to heuristically identify critical data subsets.\n",
    "For more technical details about _Slice-based Learning,_ stay tuned — our technical report is coming soon!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "encoding": "# -*- coding: utf-8 -*-",
   "formats": "ipynb,py:percent",
   "notebook_metadata_filter": "-all",
   "text_representation": {
    "extension": ".py",
    "format_name": "percent"
   }
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
