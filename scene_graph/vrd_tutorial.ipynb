{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visual Relationship Detection\n",
    "\n",
    "In this tutorial, we focus on the task of classifying visual relationships. For a given image, there might be many such relationships, defined formally as a `subject <predictate> object` (e.g. `person <riding> bike`).\n",
    "\n",
    "These are relationships among a pair of objects in images (e.g. \"man riding bicycle\"), where \"man\" and \"bicycle\" are the subject and object, respectively, and \"riding\" is the relationship predicate.\n",
    "\n",
    "![Visual Relationships](https://cs.stanford.edu/people/ranjaykrishna/vrd/dataset.png)\n",
    "\n",
    "For the purpose of this tutorial, we operate over the [Visual Relationship Detection (VRD) dataset](https://cs.stanford.edu/people/ranjaykrishna/vrd/) and focus on action relationships. We define our three class classification task as **identifying whether a pair of bounding boxes represents a particular relationship.**\n",
    "\n",
    "In the examples of the relationships shown below, the red box represents the _subject_ while the green box represents the _object_. The _predicate_ (e.g. kick) denotes what relationship connects the subject and the object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "if os.path.basename(os.getcwd()) == \"scene_graph\":\n",
    "    os.chdir(\"..\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Load Dataset\n",
    "We load the VRD dataset and filter images with at least one action predicate in it, since these are more difficult to classify than geometric relationships like `above` or `next to`. We load the train, valid, and test sets as Pandas DataFrame objects with the following fields:\n",
    "- `label`: The relationship between the objects. 0: `RIDE`, 1: `CARRY`, 2: `OTHER` action predicates\n",
    "- `object_bbox`: coordinates of the bounding box for the object `[ymin, ymax, xmin, xmax]`\n",
    "- `object_category`: category of the object\n",
    "- `source_img`: filename for the corresponding image the relationship is in\n",
    "- `subject_bbox`: coordinates of the bounding box for the object `[ymin, ymax, xmin, xmax]`\n",
    "- `subject_category`: category of the subject\n",
    "\n",
    "Note that the training DataFrame will have a labels field with all -1s. This denotes the lack of labels for that particular dataset. In this tutorial, we will assign probabilistic labels to the training set by writing labeling functions over attributes of the subject and objects!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Relationships:  26\n",
      "Dev Relationships:  26\n",
      "Test Relationships:  26\n"
     ]
    }
   ],
   "source": [
    "from scene_graph.utils import load_vrd_data\n",
    "\n",
    "train_df, valid_df, test_df = load_vrd_data()\n",
    "\n",
    "print(\"Train Relationships: \", len(train_df))\n",
    "print(\"Dev Relationships: \", len(valid_df))\n",
    "print(\"Test Relationships: \", len(test_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Writing Labeling Functions\n",
    "We now write labeling functions to detect what relationship exists between pairs of bounding boxes. To do so, we can encode various intuitions into the labeling functions. _Categorical_ intution: knowledge about the categories of subjects and objects usually involved in these relationships (e.g., `person` is usually the subject for predicates like `ride` and `carry`), and _spatial_ intuition: knowledge about the relative positions of the subject and objects (e.g., subject is usually higher than the object for the predicate `ride`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "RIDE = 0\n",
    "CARRY = 1\n",
    "OTHER = 2\n",
    "ABSTAIN = -1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We begin with labeling functions that encode categorical intuition: we use knowledge about common subject-object category pairs that are common for `RIDE` and `CARRY` and also knowledge about what subjects or objects are unlikely to be involved in the two relationships."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from snorkel.labeling.lf import labeling_function\n",
    "\n",
    "# Category-based LFs\n",
    "@labeling_function()\n",
    "def LF_ride_object(x):\n",
    "    if x.subject_category == \"person\":\n",
    "        if x.object_category in [\"bike\", \"snowboard\", \"motorcycle\", \"horse\"]:\n",
    "            return RIDE\n",
    "    return ABSTAIN\n",
    "\n",
    "\n",
    "@labeling_function()\n",
    "def LF_ride_rare_object(x):\n",
    "    if x.subject_category == \"person\":\n",
    "        if x.object_category in [\"bus\", \"truck\", \"elephant\"]:\n",
    "            return RIDE\n",
    "    return ABSTAIN\n",
    "\n",
    "\n",
    "@labeling_function()\n",
    "def LF_carry_object(x):\n",
    "    if x.subject_category == \"person\":\n",
    "        if x.object_category in [\"bag\", \"surfboard\", \"skis\"]:\n",
    "            return CARRY\n",
    "    return ABSTAIN\n",
    "\n",
    "\n",
    "@labeling_function()\n",
    "def LF_carry_subject(x):\n",
    "    if x.object_category == \"person\":\n",
    "        if x.subject_category in [\"chair\", \"bike\", \"snowboard\", \"motorcycle\", \"horse\"]:\n",
    "            return CARRY\n",
    "    return ABSTAIN\n",
    "\n",
    "\n",
    "@labeling_function()\n",
    "def LF_person(x):\n",
    "    if x.subject_category != \"person\":\n",
    "        return OTHER\n",
    "    return ABSTAIN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now encode our spatial intuition, which includes measuring the distance between the bounding boxes and comparing their relative areas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distance-based LFs\n",
    "@labeling_function()\n",
    "def LF_ydist(x):\n",
    "    if x.subject_bbox[3] < x.object_bbox[3]:\n",
    "        return OTHER\n",
    "    return ABSTAIN\n",
    "\n",
    "\n",
    "@labeling_function()\n",
    "def LF_dist(x):\n",
    "    if np.linalg.norm(np.array(x.subject_bbox) - np.array(x.object_bbox)) <= 1000:\n",
    "        return OTHER\n",
    "    return ABSTAIN\n",
    "\n",
    "\n",
    "# Size-based LF\n",
    "@labeling_function()\n",
    "def LF_area(x):\n",
    "    subject_area = (x.subject_bbox[1] - x.subject_bbox[0]) * (\n",
    "        x.subject_bbox[3] - x.subject_bbox[2]\n",
    "    )\n",
    "    object_area = (x.object_bbox[1] - x.object_bbox[0]) * (\n",
    "        x.object_bbox[3] - x.object_bbox[2]\n",
    "    )\n",
    "\n",
    "    if subject_area / object_area <= 0.5:\n",
    "        return OTHER\n",
    "    return ABSTAIN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the labeling functions have varying empirical accuracies and coverages. Due to class imbalance in our chosen relationships, labeling functions that label the `OTHER` class have higher coverage than labeling functions for `RIDE` or `CARRY`. This reflects the distribution of classes in the dataset as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/26 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "100%|██████████| 26/26 [00:00<00:00, 2529.80it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\r",
      "  0%|          | 0/26 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "100%|██████████| 26/26 [00:00<00:00, 3207.69it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from snorkel.labeling.apply import PandasLFApplier\n",
    "\n",
    "lfs = [\n",
    "    LF_ride_object,\n",
    "    LF_ride_rare_object,\n",
    "    LF_carry_object,\n",
    "    LF_carry_subject,\n",
    "    LF_person,\n",
    "    LF_ydist,\n",
    "    LF_dist,\n",
    "    LF_area,\n",
    "]\n",
    "\n",
    "applier = PandasLFApplier(lfs)\n",
    "L_train = applier.apply(train_df)\n",
    "L_valid = applier.apply(valid_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/snorkel-tutorials/.tox/scene_graph/lib/python3.6/site-packages/snorkel/labeling/analysis.py:288: RuntimeWarning: invalid value encountered in true_divide\n",
      "  return np.nan_to_num(0.5 * (X.sum(axis=0) / (self.L != -1).sum(axis=0) + 1))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>j</th>\n",
       "      <th>Polarity</th>\n",
       "      <th>Coverage</th>\n",
       "      <th>Overlaps</th>\n",
       "      <th>Conflicts</th>\n",
       "      <th>Correct</th>\n",
       "      <th>Incorrect</th>\n",
       "      <th>Emp. Acc.</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LF_ride_object</th>\n",
       "      <td>0</td>\n",
       "      <td>[0]</td>\n",
       "      <td>0.230769</td>\n",
       "      <td>0.230769</td>\n",
       "      <td>0.230769</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.833333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_ride_rare_object</th>\n",
       "      <td>1</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_carry_object</th>\n",
       "      <td>2</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_carry_subject</th>\n",
       "      <td>3</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_person</th>\n",
       "      <td>4</td>\n",
       "      <td>[2]</td>\n",
       "      <td>0.307692</td>\n",
       "      <td>0.307692</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>0.625000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_ydist</th>\n",
       "      <td>5</td>\n",
       "      <td>[2]</td>\n",
       "      <td>0.576923</td>\n",
       "      <td>0.576923</td>\n",
       "      <td>0.307692</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>0.466667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_dist</th>\n",
       "      <td>6</td>\n",
       "      <td>[2]</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.846154</td>\n",
       "      <td>0.346154</td>\n",
       "      <td>13</td>\n",
       "      <td>6</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_area</th>\n",
       "      <td>7</td>\n",
       "      <td>[2]</td>\n",
       "      <td>0.346154</td>\n",
       "      <td>0.346154</td>\n",
       "      <td>0.153846</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>0.555556</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     j Polarity  Coverage  Overlaps  Conflicts  Correct  \\\n",
       "LF_ride_object       0      [0]  0.230769  0.230769   0.230769        5   \n",
       "LF_ride_rare_object  1       []  0.000000  0.000000   0.000000        0   \n",
       "LF_carry_object      2      [1]  0.076923  0.076923   0.076923        2   \n",
       "LF_carry_subject     3      [1]  0.038462  0.038462   0.038462        1   \n",
       "LF_person            4      [2]  0.307692  0.307692   0.038462        5   \n",
       "LF_ydist             5      [2]  0.576923  0.576923   0.307692        7   \n",
       "LF_dist              6      [2]  1.000000  0.846154   0.346154       13   \n",
       "LF_area              7      [2]  0.346154  0.346154   0.153846        5   \n",
       "\n",
       "                     Incorrect  Emp. Acc.  \n",
       "LF_ride_object               1   0.833333  \n",
       "LF_ride_rare_object          0   0.000000  \n",
       "LF_carry_object              0   1.000000  \n",
       "LF_carry_subject             0   1.000000  \n",
       "LF_person                    3   0.625000  \n",
       "LF_ydist                     8   0.466667  \n",
       "LF_dist                      6   0.500000  \n",
       "LF_area                      4   0.555556  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from snorkel.labeling.analysis import LFAnalysis\n",
    "\n",
    "Y_valid = valid_df.label.values\n",
    "LFAnalysis(L_valid, lfs).lf_summary(Y_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Train Label Model\n",
    "We now train a multi-class `LabelModel` to assign training labels to the unalabeled training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing O...\n",
      "Estimating \\mu...\n",
      "[0 epochs]: TRAIN:[loss=1.612]\n",
      "[10 epochs]: TRAIN:[loss=0.474]\n",
      "[20 epochs]: TRAIN:[loss=0.248]\n",
      "[30 epochs]: TRAIN:[loss=0.092]\n",
      "[40 epochs]: TRAIN:[loss=0.084]\n",
      "[50 epochs]: TRAIN:[loss=0.062]\n",
      "[60 epochs]: TRAIN:[loss=0.049]\n",
      "[70 epochs]: TRAIN:[loss=0.042]\n",
      "[80 epochs]: TRAIN:[loss=0.033]\n",
      "[90 epochs]: TRAIN:[loss=0.026]\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "from snorkel.labeling.model import LabelModel\n",
    "\n",
    "label_model = LabelModel(cardinality=3, verbose=True)\n",
    "label_model.fit(L_train, seed=123, lr=0.01, log_freq=10, n_epochs=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use [F1](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.f1_score.html) Micro average for the multiclass setting, which calculates metrics globally by counting the total true positives, false negatives and false positives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'f1_micro': 0.5769230769230769}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_model.score(L_valid, Y_valid, metrics=[\"f1_micro\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Train a Classifier\n",
    "You can then use these training labels to train any standard discriminative model, such as [an off-the-shelf ResNet](https://github.com/KaimingHe/deep-residual-networks), which should learn to generalize beyond the LF's we've developed!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create DataLoaders for Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from snorkel.classification.data import DictDataLoader\n",
    "from scene_graph.model import FlatConcat, SceneGraphDataset, WordEmb, init_fc\n",
    "\n",
    "# change to \"scene_graph/data/VRD/sg_dataset/sg_train_images\" for full set\n",
    "TRAIN_DIR = \"scene_graph/data/VRD/sg_dataset/samples\"\n",
    "train_df[\"labels\"] = label_model.predict(L_train)\n",
    "\n",
    "train_dl = DictDataLoader(\n",
    "    SceneGraphDataset(\"train_dataset\", \"train\", TRAIN_DIR, train_df),\n",
    "    batch_size=16,\n",
    "    shuffle=True,\n",
    ")\n",
    "\n",
    "valid_dl = DictDataLoader(\n",
    "    SceneGraphDataset(\"valid_dataset\", \"valid\", TRAIN_DIR, valid_df),\n",
    "    batch_size=16,\n",
    "    shuffle=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.models as models\n",
    "import torch.nn as nn\n",
    "\n",
    "from functools import partial\n",
    "from snorkel.classification.scorer import Scorer\n",
    "from snorkel.classification.task import ce_loss, softmax\n",
    "from snorkel.classification.task import Task\n",
    "\n",
    "\n",
    "# initialize pretrained feature extractor\n",
    "cnn = models.resnet18(pretrained=True)\n",
    "\n",
    "# freeze the resnet weights\n",
    "for param in cnn.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# define input features\n",
    "in_features = cnn.fc.in_features\n",
    "feature_extractor = nn.Sequential(*list(cnn.children())[:-1])\n",
    "\n",
    "# initialize FC layer: maps 3 sets of image features to class logits\n",
    "WEMB_SIZE = 100\n",
    "fc = nn.Linear(in_features * 3 + 2 * WEMB_SIZE, 3)\n",
    "init_fc(fc)\n",
    "\n",
    "# define layers\n",
    "module_pool = nn.ModuleDict(\n",
    "    {\n",
    "        \"feat_extractor\": feature_extractor,\n",
    "        \"prediction_head\": fc,\n",
    "        \"feat_concat\": FlatConcat(),\n",
    "        \"word_emb\": WordEmb(),\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scene_graph.model import get_task_flow\n",
    "\n",
    "# define task flow through modules\n",
    "task_flow = get_task_flow()\n",
    "pred_cls_task = Task(\n",
    "    name=\"scene_graph_task\",\n",
    "    module_pool=module_pool,\n",
    "    task_flow=task_flow,\n",
    "    loss_func=partial(ce_loss, \"head_op\"),\n",
    "    output_func=partial(softmax, \"head_op\"),\n",
    "    scorer=Scorer(metrics=[\"f1_micro\"]),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train and Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 0::   0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/snorkel-tutorials/scene_graph/model.py:134: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  return self.word_embs.loc[word].as_matrix()\n",
      "\r",
      "Epoch 0::   0%|          | 0/2 [00:01<?, ?it/s, model/all/train/loss=1.25, model/all/train/lr=0.001]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 0::  50%|█████     | 1/2 [00:01<00:01,  1.34s/it, model/all/train/loss=1.25, model/all/train/lr=0.001]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 0::  50%|█████     | 1/2 [00:02<00:01,  1.34s/it, model/all/train/loss=1.07, model/all/train/lr=0.001]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 0:: 100%|██████████| 2/2 [00:02<00:00,  1.23s/it, model/all/train/loss=1.07, model/all/train/lr=0.001]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from snorkel.classification.snorkel_classifier import SnorkelClassifier\n",
    "from snorkel.classification.training import Trainer\n",
    "\n",
    "model = SnorkelClassifier([pred_cls_task])\n",
    "trainer = Trainer(\n",
    "    n_epochs=1,\n",
    "    lr=1e-3,\n",
    "    checkpointing=True,\n",
    "    checkpointer_config={\"checkpoint_dir\": \"checkpoint\"},\n",
    ")\n",
    "trainer.fit(model, [train_dl])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'scene_graph_task/valid_dataset/valid/f1_micro': 0.6153846153846154}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score([valid_dl])"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
